{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Estimating the Effect of Schooling on Wages: Intrumental Variables Application\n",
    "\n",
    "### Summary of Contents:\n",
    "1. [Introduction](#intro)\n",
    "2. [NLSYM Dataset](#data)\n",
    "3. [A Gentle Start: The Naive Approach](#naive)\n",
    "4. [Using Instrumental Variables: 2SLS](#2sls)\n",
    "5. [Bonus: Deep Instrumental Variables](#deepiv)\n",
    "\n",
    "\n",
    "**Important:** This notebook is an end-to-end solution for this problem. If you are looking for notebook with some room for experimentation, look for the same file name without the \"Complete\" suffix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction <a class=\"anchor\" id=\"intro\"></a>\n",
    "\n",
    "To measure true causal effects of a treatment $T$ on an outcome $Y$ from observational data, we need to record all features $X$ that might influence both $T$ and $Y$. These $X$'s are called confounders. \n",
    "\n",
    "When some confounders are not recorded in the data, we might get biased estimates of the treatment effect. Here is an example:\n",
    "* Children of high-income parents might attain higher levels of education (e.g. college) since they can afford it\n",
    "* Children of high-income parents might also obtain better paying jobs due to parents' connections and knowledge\n",
    "* At first sight, it might appear as if education has an effect on income, when in fact this could be fully explained by family background\n",
    "\n",
    "There are several reasons for not recording all possible confounders, such as incomplete data or a confounder that is difficult to quantify (e.g. parental involvement). However, not all is lost! In cases such as these, we can use instrumental variables $Z$, features that affect the outcome only through their effect on the treatment. \n",
    "\n",
    "In this notebook, we use a real-world problem to show how treatment effects can be extracted with the help of instrumental variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. NLSYM Dataset <a class=\"anchor\" id=\"data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **causal impact of schooling on wages** had been studied at length. Although it is generally agreed that there is a positive impact, it is difficult to measure this effect precisely. The core problem is that education levels are not assigned at random in the population and we cannot record all possible confounders. (Think about the value parents assign to education. How would you quantify how valuable parents think their children's education is?). \n",
    "\n",
    "<img src=\"https://straubroland.files.wordpress.com/2010/12/education_technology-resized-600.png\" width=400px/>\n",
    "\n",
    "To get around this issue, we can use **proximity to a 4-year college** as an instrumental variable. Having a college nearby can allow individuals (especially low-income ones) to complete more years of education. Hence, if there was a positive treatment effect, we would expect these individuals to have higher wages on average. Note that college proximity is a valid IV since it does not affect wages directly.  \n",
    "\n",
    "We use data from the National Longitudinal Survey of Young Men (NLSYM, 1966) to estimate the average treatment effect (ATE) of education on wages (see also [Card, 1999](https://www.nber.org/papers/w4483)). The NLSYM data contains entries from men ages 14-24 that were interviewed in 1966 and again in 1976. \n",
    "\n",
    "The dataset contains the following variables:\n",
    "* $Y$ (outcome): wages (log)\n",
    "* $T$ (treatment): years of schooling\n",
    "* $Z$ (IV): proximity to a 4-year college (binary)\n",
    "* $X$ (heterogeneity): e.g. parental education\n",
    "* $W$ (controls): e.g. family composition, location, etc.\n",
    "\n",
    "The world can then be modelled as:\n",
    "$$\n",
    "\\begin{align}\n",
    "Y & = \\theta(X) \\cdot T + f(W) + \\epsilon\\\\\n",
    "T & = g(Z, W) + \\eta\n",
    "\\end{align}\n",
    "$$\n",
    "where $\\epsilon, \\eta$ are uncorrelated error terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python imports\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from econml.dml import LinearDMLCateEstimator\n",
    "from sklearn.linear_model import LassoCV\n",
    "from econml.inference import BootstrapInference\n",
    "\n",
    "# EconML imports\n",
    "from econml.dml import DMLCateEstimator\n",
    "from econml.two_stage_least_squares import NonparametricTwoStageLeastSquares\n",
    "from econml.deepiv import DeepIVEstimator\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\r\n",
      "Deep IV Examples.ipynb\r\n",
      "Double Machine Learning Examples.ipynb\r\n",
      "Hands-on Part I -- Estimating Price Elasticity of Orange Juice Demand - Complete.ipynb\r\n",
      "Hands-on Part I -- Estimating Price Elasticity of Orange Juice Demand.ipynb\r\n",
      "Hands-on Part II -- Estimating the Effect of Schooling on Wages - Complete.ipynb\r\n",
      "Hands-on Part II -- Estimating the Effect of Schooling on Wages.ipynb\r\n",
      "Metalearners Examples.ipynb\r\n",
      "oj_large.csv\r\n",
      "Orthogonal Random Forest Examples.ipynb\r\n",
      "Our_Model.ipynb\r\n",
      "README.md\r\n",
      "requirements.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing\n",
    "df = pd.read_csv(\"data/card.csv\", dtype=float)\n",
    "# Filter out individuals with low education levels (outliers)\n",
    "data_filter = df['educ'].values >= 6\n",
    "# Define some variables\n",
    "T = df['educ'].values[data_filter]\n",
    "Z = df['nearc4'].values[data_filter]\n",
    "Y = df['lwage'].values[data_filter]\n",
    "\n",
    "# Impute missing values with mean, add dummy columns\n",
    "# Filter outliers (interviewees with less than 6 years of education)\n",
    "X_df = df[['exper', 'expersq']].copy()\n",
    "X_df['fatheduc'] = df['fatheduc'].fillna(value=df['fatheduc'].mean())\n",
    "X_df['fatheduc_nan'] = df['fatheduc'].isnull() * 1\n",
    "X_df['motheduc'] = df['motheduc'].fillna(value=df['motheduc'].mean())\n",
    "X_df['motheduc_nan'] = df['motheduc'].isnull() * 1\n",
    "X_df[['momdad14', 'sinmom14', 'reg661', 'reg662',\n",
    "        'reg663', 'reg664', 'reg665', 'reg666', 'reg667', 'reg668', 'reg669', 'south66']] = df[['momdad14', 'sinmom14', \n",
    "        'reg661', 'reg662','reg663', 'reg664', 'reg665', 'reg666', 'reg667', 'reg668', 'reg669', 'south66']]\n",
    "X_df[['black', 'smsa', 'south', 'smsa66']] = df[['black', 'smsa', 'south', 'smsa66']]\n",
    "columns_to_scale = ['fatheduc', 'motheduc', 'exper', 'expersq']\n",
    "# Scale continuous variables\n",
    "scaler = StandardScaler()\n",
    "X_df[columns_to_scale] = scaler.fit_transform(X_df[columns_to_scale])\n",
    "X = X_df.values[data_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exper</th>\n",
       "      <th>expersq</th>\n",
       "      <th>fatheduc</th>\n",
       "      <th>fatheduc_nan</th>\n",
       "      <th>motheduc</th>\n",
       "      <th>motheduc_nan</th>\n",
       "      <th>momdad14</th>\n",
       "      <th>sinmom14</th>\n",
       "      <th>reg661</th>\n",
       "      <th>reg662</th>\n",
       "      <th>...</th>\n",
       "      <th>reg665</th>\n",
       "      <th>reg666</th>\n",
       "      <th>reg667</th>\n",
       "      <th>reg668</th>\n",
       "      <th>reg669</th>\n",
       "      <th>south66</th>\n",
       "      <th>black</th>\n",
       "      <th>smsa</th>\n",
       "      <th>south</th>\n",
       "      <th>smsa66</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.725159</td>\n",
       "      <td>1.896133</td>\n",
       "      <td>5.439188e-16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.034739</td>\n",
       "      <td>-0.172321</td>\n",
       "      <td>-6.134540e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.786159</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.725159</td>\n",
       "      <td>1.896133</td>\n",
       "      <td>1.223740e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.553046</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.276228</td>\n",
       "      <td>0.052254</td>\n",
       "      <td>3.051432e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.553046</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.725159</td>\n",
       "      <td>1.896133</td>\n",
       "      <td>-6.134540e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.120960</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      exper   expersq      fatheduc  fatheduc_nan  motheduc  motheduc_nan  \\\n",
       "0  1.725159  1.896133  5.439188e-16             1  0.000000             1   \n",
       "1  0.034739 -0.172321 -6.134540e-01             0 -0.786159             0   \n",
       "2  1.725159  1.896133  1.223740e+00             0  0.553046             0   \n",
       "3  0.276228  0.052254  3.051432e-01             0  0.553046             0   \n",
       "4  1.725159  1.896133 -6.134540e-01             0 -1.120960             0   \n",
       "\n",
       "   momdad14  sinmom14  reg661  reg662  ...  reg665  reg666  reg667  reg668  \\\n",
       "0       1.0       0.0     1.0     0.0  ...     0.0     0.0     0.0     0.0   \n",
       "1       1.0       0.0     1.0     0.0  ...     0.0     0.0     0.0     0.0   \n",
       "2       1.0       0.0     1.0     0.0  ...     0.0     0.0     0.0     0.0   \n",
       "3       1.0       0.0     0.0     1.0  ...     0.0     0.0     0.0     0.0   \n",
       "4       1.0       0.0     0.0     1.0  ...     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   reg669  south66  black  smsa  south  smsa66  \n",
       "0     0.0      0.0    1.0   1.0    0.0     1.0  \n",
       "1     0.0      0.0    0.0   1.0    0.0     1.0  \n",
       "2     0.0      0.0    0.0   1.0    0.0     1.0  \n",
       "3     0.0      0.0    0.0   1.0    0.0     1.0  \n",
       "4     0.0      0.0    0.0   1.0    0.0     1.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore data\n",
    "X_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. A Gentle Start: The Naive Approach <a class=\"anchor\" id=\"naive\"></a>\n",
    "\n",
    "Let's assume we know nothing about instrumental variables and we want to measure the treatment effect of schooling on wages. We can apply an IV-free method like Double Machine Learning (DML) to do this and extract a treatment effect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dml_est = DMLCateEstimator(model_y=RandomForestRegressor(n_estimators=100), \n",
    "#                            model_t=RandomForestRegressor(n_estimators=100))\n",
    "\n",
    "\n",
    "dml_est = LinearDMLCateEstimator(model_y=LassoCV(), model_t=LassoCV())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.07136824549658627, tolerance: 0.020362262857373824\n",
      "  tol, rng, random, positive)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0887298738739446, tolerance: 0.020362262857373824\n",
      "  tol, rng, random, positive)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09885769984089166, tolerance: 0.020362262857373824\n",
      "  tol, rng, random, positive)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.10138165850787573, tolerance: 0.020362262857373824\n",
      "  tol, rng, random, positive)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09032105998926454, tolerance: 0.020362262857373824\n",
      "  tol, rng, random, positive)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06287329086276827, tolerance: 0.020362262857373824\n",
      "  tol, rng, random, positive)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1715049235833277, tolerance: 0.020362262857373824\n",
      "  tol, rng, random, positive)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.022150054259768126, tolerance: 0.018886407816158215\n",
      "  tol, rng, random, positive)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1071038246188607, tolerance: 0.018886407816158215\n",
      "  tol, rng, random, positive)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.02556190202707853, tolerance: 0.018886407816158215\n",
      "  tol, rng, random, positive)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.094528254625601, tolerance: 0.018886407816158215\n",
      "  tol, rng, random, positive)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.36828407768081206, tolerance: 0.018886407816158215\n",
      "  tol, rng, random, positive)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5368470539851842, tolerance: 0.018886407816158215\n",
      "  tol, rng, random, positive)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7035056951227432, tolerance: 0.018886407816158215\n",
      "  tol, rng, random, positive)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08167858365087, tolerance: 0.02006073124866469\n",
      "  tol, rng, random, positive)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09819887344913525, tolerance: 0.02006073124866469\n",
      "  tol, rng, random, positive)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.10984247760862331, tolerance: 0.02006073124866469\n",
      "  tol, rng, random, positive)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06095506575707077, tolerance: 0.02006073124866469\n",
      "  tol, rng, random, positive)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0896810570922213, tolerance: 0.02006073124866469\n",
      "  tol, rng, random, positive)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.10943891593370836, tolerance: 0.02006073124866469\n",
      "  tol, rng, random, positive)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09535341779755413, tolerance: 0.02006073124866469\n",
      "  tol, rng, random, positive)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.12055261766766989, tolerance: 0.02006073124866469\n",
      "  tol, rng, random, positive)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.12474746084679111, tolerance: 0.02006073124866469\n",
      "  tol, rng, random, positive)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.12817254835974268, tolerance: 0.02006073124866469\n",
      "  tol, rng, random, positive)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.12404438765013026, tolerance: 0.02006073124866469\n",
      "  tol, rng, random, positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1050646031898026, tolerance: 0.02006073124866469\n",
      "  tol, rng, random, positive)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06923505177313416, tolerance: 0.02006073124866469\n",
      "  tol, rng, random, positive)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06160867201320741, tolerance: 0.02006073124866469\n",
      "  tol, rng, random, positive)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0387287080163361, tolerance: 0.018744036879555226\n",
      "  tol, rng, random, positive)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0366488470134243, tolerance: 0.018744036879555226\n",
      "  tol, rng, random, positive)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03741474643926779, tolerance: 0.018744036879555226\n",
      "  tol, rng, random, positive)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03720006381907126, tolerance: 0.018744036879555226\n",
      "  tol, rng, random, positive)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/econml/utilities.py:961: UserWarning: Co-variance matrix is undertermined. Inference will be invalid!\n",
      "  warnings.warn(\"Co-variance matrix is undertermined. Inference will be invalid!\")\n"
     ]
    }
   ],
   "source": [
    "dml_est.fit(Y, T, X)\n",
    "dml_ate = dml_est.effect(X).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average treatment effect: 0.069\n"
     ]
    }
   ],
   "source": [
    "print(\"Average treatment effect: {0:.3f}\".format(dml_ate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This treatment effect is smaller than other values obtained in literature via IV. Why could that be? \n",
    "\n",
    "Because DML (like all IV-free methods) assumes that the residual errors are uncorrelated (i.e. $Y - \\hat{Y}$ is uncorrelated with $T - \\hat{T}$). Let's test this assumption:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data in 2 parts for cross-fitting \n",
    "# We do this to avoid over-fitting\n",
    "T_res, Y_res = np.zeros(T.shape[0]), np.zeros(Y.shape[0])\n",
    "kf = KFold(n_splits=2, shuffle=True)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    T_res[test_index] = T[test_index] - \\\n",
    "    RandomForestRegressor(n_estimators=100).fit(X[train_index], T[train_index]).predict(X[test_index])\n",
    "    Y_res[test_index] = Y[test_index] - \\\n",
    "    RandomForestRegressor(n_estimators=100).fit(X[train_index], Y[train_index]).predict(X[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO2df5RU53nfv88MF5jFMYMiaksjIWTXQTFGsIZIuLQ5RnGMLSy0ActYkdok7YnanDiNiM62KFYN0lHLNltXcmufJqrjJjlW5ZWEskZCCYoLbVq1yAbvrvHakEiyBBopMTEMttgBZmef/jFzhzt33vfe9/6YuXdmns85HHZnZ+59Z+be533e532e70PMDEEQBKH3ySQ9AEEQBKEziMEXBEHoE8TgC4Ig9Ali8AVBEPoEMfiCIAh9wrykB+DFlVdeycuXL096GIIgCF3D0aNH/46Zl6r+lmqDv3z5chw5ciTpYQiCIHQNRPS67m8S0hEEQegTxOALgiD0CWLwBUEQ+gQx+IIgCH2CGHxBEIQ+IdVZOoIgAOMTRYweOIE3S2Vcnc9heNMKDA0Wkh6W0IWIwReEFDM+UcT9zxxDuVIFABRLZdz/zDEAEKMvBEYMviCkmNEDJxrG3qZcqWL0wImOGHxZXfQWscTwiegrRPRDIvqu5u8fJqJzRDRZ//e5OM4rCL3Om6VyoMfjxF5dFEtlMC6vLsYnim0/t9Ae4tq0/SMAH/N5zv9m5jX1fw/FdF5B6GmuzucCPR4nXqsLoTuJxeAz818COBPHsQRBuMzwphXIWdmmx3JWFsObVrT93EmuLoT20Mm0zA8R0RQR/RkRrdQ9iYjuIaIjRHTk9OnTHRyeIKSPocEC9mxdhUI+BwJQyOewZ+uqjsTRk1xdCO2B4uppS0TLATzHzB9Q/O2dAOaY+W0iuhXAF5j5fX7HXLduHYt4miAkgztDCKitLjo14QjhIKKjzLxO9beOePjM/GNmfrv+8/MALCK6shPnFgQhHEmuLoT20JG0TCJ6N4C/ZWYmoptQm2h+1IlzC0IvEDQ9Mq50yqHBghj4HiIWg09ETwD4MIAriegNALsAWADAzL8P4JMAfoOIZgGUAXya44olCUKPE7T4Soq1BB2xGHxmvtPn718E8MU4ziUI/UbQ4quki7WE9CLiaYKQcoKmR0o6paBDDL4gpJyg6ZGSTinoEIMvRGJ8oogNIwdx/c792DBysGvL7tP8PoIWXyVZrCWkGxFPE0LTK5uDaX8f9hhMs26CPl/oH2IrvGoHUniVbjaMHERRERcu5HN4cectCYwoHL3yPgQBSEHhldCb9MrmYK+8D0HwQwy+EJpe2RzslfchCH6IwRdC0yubg73yPgTBD9m0FULTTZuDXlID3fQ+BCEKsmkr9Dyi+ij0E7JpK/Q10rlJEGqIwRd6HsnCEYQaYvCFnkeycAShhhh8IXHaLWsgWTiCUEOydIRE6YSsgWThCEINMfhConRKu106NwmCGHwhYWRDNV7seoNiqYwsEarMKMiKRqgjBl9IlKvzOaVwWSc3VOPq/5o07vBYtV5jkzb1z0583r3yncaNbNoKiZL0hqptJIulMhiXjWOa9PBNUYXHbMqVKu4dm0xc6z/q522ywd9L32nciIcvJErSG6rd2v9V5cGahMHa4e0H8aajfN6mG/zd+p12AjH4QuIkuaHajXsIOsOXH7Bwdqbi+/o4jV/QLKson7epIe/G77RTSEhH6Gu6sShLZ/iY0RIe0xGX8QsqWxHl8zY15N34nXYKMfhCT+MX8016DyEMOsN3rlzBnq2rUKgbtiyR9hhxGb+g3vTGG5YGetyJqSHvxu+0U8Ri8InoK0T0QyL6rubvRET/iYheJqLvENEH4zivIHhhsnk3NFjAtrWFhnHMEmHb2nTn7HsZvqHBAl7ceQteG9mMV/bcike3r2mr8QvqTR86fjrQ405MDfnQYKEx8RFqrSpFGbVGXDH8PwLwRQB/ovn7xwG8r/7vZgD/pf6/0MMklRrnzEV34475jk8UsfdosZHCWGXG3qNFrLvuCqNNxCRy3oc3rVDKPauM+NBgAUdeP4MnXjqFKnPsE9rwphUYfmoKlbnLMutWhrQTSpT4epANfim0UxOLwWfmvySi5R5PuR3An3BNfP8wEeWJ6CpmfiuO8wvpoxOSCSbnVeE0LkEyOpwTWH7AwtsXZhuGrpM570EMX5QJzRh35EgfSYpcdyGGPBqdytIpADjl+P2N+mMtBp+I7gFwDwAsW7asI4MT4iep1DivXHQbp3Ex9TjdE4lXNozqfca92jE1fKbfQ9jxjR44gUq1uYlSpcra7znI6kSIn9SlZTLzYwAeA2odrxIejhCSpFLj/I7vNi6mHqfJRKIbR1KrHfc4oo4vSO6/7nGv1YlUx7afThn8IoBrHb9fU39M6FGSkkzQnReAMr5u6nEGnaic7zPJQiCT70E3vnvHJnHv2CSWDFjYfONV2Hu0aJz7H/R7TnJSNKFXJqNOpWXuA/BP6tk66wGck/h9b5NUapzqvFaWkM9ZeLNUxuiBEy1ZOiYZHUEMmPt9JlkIZPI9+I3j7EwFXz180jj33+t71mVO7d43ndo2lL0k1RCLh09ETwD4MIAriegNALsAWADAzL8P4HkAtwJ4GcAMgF+L47xCevHbWGyXx2QfY/e+aZTKNc+zUuXGz8VSGTvGJnHk9TN4eGhV4zV+51atBFSoVhFJCsSZbPB6rYr8OFeu4JHtayJLK+g+1zRUx/aSVENcWTp3+vydAfxmHOcSugedIe3E8v3i7Jz2bwzg8cMnA2WqOA2nzjhmiZSTmur5VlafuqgiygTp/B7s4+wYm2wcx3QyU7E4ZwXKnIkSGkuKqCu0NIWDUrdp2+uk6ctPinZ7TCYbrFx/XpDz2c998NlpZdy6ytyYuAB4G1FNOoLq+nAfK+wEqZto92xdhT1bV3lOZjrOX5rF+ETReByLc1ZjteXGylBTPn8S2Tuqzz/KCi1texNi8DtI2r78uAg6ibU7pm16nKDnM8nxL1eq2PHkJAjAnEeOWWWuNXVRd30stDKxTJBem7MFx+TiLqTywisFU3VdeKg9AATkcxbOlSuJOEO6z3/b2kLThjVgPhmlLRwkBr+DJPXlt3NVEWYS03lM+QELG0YORh6naUx6cc4KdFzT1ExmrQPfxJulctN3k6lX6zrxim8XS+VAn5fXBOf09kfvWN20B5Ih78lLdVzddeH1+VWqjEUL5mFy10f1J4sJ1T2huz8PHT/dWAEFvTbTptwpBr+DJPHlt3tVEWYSU8WMsxnC2ZlKI1QSZZymMWk7HGG/D7+bOe7vKT9gKTtUmUJAY2JTfV5uo+Ynn2x/by/uvMVz5eHm6nyu5VznL84qr4usYlJz0glDGHQyerNUDl3hm4aObk7E4HeQJL78dq8qwkxi7g1QIqCqcCHDjlOVmXL2/EXMVJo3citVxoPPTuPti7ONatFiqYzhp6eajmMTJZvFTc7KghlGK4Z8zsLF2bmm5xJaVxF2eObBZ6dxsVJter/FUhlWhmBlqaUy1onqe1NlPjnfx8YblrYYUB1VZuXYbTphCHX3hG4yijKmtFUWizxyB0kiN73dq4qw2uNDg4XG5+Hl2IYdp60a+YORzXhx5y0oV9RZO2dnKkppgAefnW557sYblnrJxARiz9ZVOKfZvHSSs7LYvWVlS62A11rg7EylZXIDavsGi+bPa8gnq2BAKSM9NFjA7i0rkXeEwTJUM5RPvHQqUIaPbuydMoS6a6rKHPv9mTblTvHwO0gS7fzavaqI4sGYxMQzRJ5ZIKb7E0G9c3fowxYhi0Pro1CXMdZlxWSJMMeMxTkLRMC9Y5NNapzLfzr8SqNUrmDRgtptr/O0deEh9/dsL8qChqJslgxYGJg/r+MZa7proeCI5cc5pjQJvonB7zCd/vLbvaSMIr9r4r07Ux1V6pXuUIKzqMo5GeSsaIvZoFo6OuzPfnyiiJlLs8q/b1tbwHNTbzWFT5xqnFHDSvbrGXqj7w6nhXn/fpu9pZkKJj7XukGrS02NyxB73RNpMs7tQAx+j9PuVUUU+V1Tr1sXy1cZIbuoCkBTKp0qxOFF3pXBE1cIbM/WWnWvapMwn7PwidVXtaQAthMv39z5noO+/5yVNVYtdRr4xTkL5y8p9lQYjVTRqIkHSay00wJxyOVYJ1i3bh0fOXIk6WEIHmwYOahdHr+48xbP15rktdsQgB+MbG567b1jk4HHa4KVIYzesRoAPFMmg5Ilwuc/tVobyrFj63FtDEeFUEtdPVeuBH7/+Xo4yisr6O71y7DuuitCV/maXGP9CBEdZeZ1qr+Jhy9EIs4ORotzFn58oaIMAzj3HOyJoh1kibD9ppqwa5SUSRV2eCrNujFOGGiElYK+/1K5AitDyGZImYEF1FZgz029FXo1465j6CdPPSxi8AUlUTdDg3Ywso24yjY49xzGJ4q478mpWAywCjskFcUQeeGX/nf+4qxWeiANeKVUuqnMsaen71VUZoK7jqFXKtfbiaRlCi0EkYONK9VUtylobwKPHjiB5Tv3Y8fYZNuMvU25Um2r0a0yw8o2J3haWcLGG5bivGIj142VARbNz/o+rx0woGyMruNcubYxG1c6q42ujiEtksppRQy+0IKuMOW+J6dw/c79TXnaceUZe+VGP374ZFNmSRgGrEzkTJ24WDJgtbyRSpXx31866VkU1XjuHHD+Umc2dVWovnP3JreNvdKLmgacz1kt15iujiFtobE0ISGdLidqDDNI2zpVo24gnmwHr4ydOPz5+fOynpLJnYQdGSdODPXKEmXJQM2wO0NxowdOoFSutIR7rAxh5tIsrt+5H4tzlm+Vr318Z3N44HLxmSpLK02yBd2AZOl0Maosl5yVbaT++RniIFkyKlQl//b5gxr9B8aP4av1dMpexlaD7PRdFyT2rsPKEkY/udqzGMs+T96VXgnUJoB3LJynzdyxM7HcTsjGG5bi0PHTyh64uvOrGtH0C5Kl06PoQi+79003GWLdZlbUYiJVnDus/s2h46dDj6ObSHJD9u71ywJNqhveewVe+1FZ6zTo6iDs9FL3e63MMc7OVLSb1nnX6gEwE/9raDLh8qRmIianc4J6OetHPPwu5vqd+wN5be685aCvDwIBnt6Zm3aORbgs17DQyuDi7JxR+Mjt0buJ+zuz6x+c5zOt8/B7ntdq2GvFEnbFmiReHn46drGEUASNVbpj81FinTkriwGPTVA7u+er9Q1X+/fhp6Yw+NALLZu/EnetEXc2i02VGQygXJkDc83b9zuX3dxkfKKIDSMH2/6dVeYY945NNp3DtM5D97xiqYzrd+7HfU9O+Wb0eCnL9gpi8LsYXUqkvbHmxn2Dql5vQj5nYdvagnFXJCf2st6d7qkai5WJx/zFcZR2GWI3nVjlMICvHj5plLVkf0fOSXvH2CQeGD8W+voxPef4RNFYjdVr8mHoC8dM5CN6KetHDH4Xo0uJ3HXbSqPceOfrg3Bxdg7PTb1llELohzPm734vo3es9m6JZ0gcRrRT4aY43q8pJvpCWSJlnP6rh0/i3rFJLLQyteKqmMdmXxemdR5hJx/nRKHrgBa0M1qakU3bLsdL3c9k88n5etNMmagVkm7sVn3Dm1a0aKO0Sy8nraRtS82vyM3OuDHRznHjJbsAXPasF8y73NN3yYCFXbe1pmi6ZTpMPkb3xKGbbDs5CbcbMfg9ShiZ14eHVmHddVcoOxu1G3dWhZ0tIXQHYa6Xn1owD4sWzNPWX7ilEwDggqHqqS4TyN68VjlBJc1kpXu8G4nF4BPRxwB8AUAWwJeZecT1918FMArArs3/IjN/OY5zC/GmktkTxZoHX+i40XdukEWpDxC6g3PlCiZ3fVRbD1Kaaa1X0KX9uo+hMvZ+WUdp6z/bDiLH8IkoC+BLAD4O4P0A7iSi9yueOsbMa+r/xNjHRBDdmyDs3tK6DxAXWY81crFUVmZUCL2HbUjt/Rt3soEuLKPaRDWqKfGJ8yTRgrTTxLFpexOAl5n5VWa+BOBrAG6P4biCAe1KJXNv6HoZ6aDM+cSF2y2OJnQOcv1v4zakQ4MFDMw3CzioPG6TTJrKHHveF2nrP9sO4gjpFACccvz+BoCbFc/bRkQ/D+CvAOxg5lOK54CI7gFwDwAsW7YshuH1NnGnkvmFh3QFLqZkCHjnQivVEsBCfDhlDvzCjibXrM7jNu2eZp9Dd51Li8N4eBbAE8x8kYj+OYA/BqBsVcPMjwF4DKhV2nZofF1LnHFHkzL24U0rImXOzDGMJICF3uHNUtnIkOquZa+NVhtVn1rdOUyu814ljpBOEcC1jt+vweXNWQAAM/+ImS/Wf/0ygLUxnLdj6CoN00CccUeT8NDQYEFb2GVKHPn7Qvfg53zY95eth+OEUAvx+SUjuMMxSwYsZeHezKVZ7N43HSgMmub7PyhxePjfAvA+IroeNUP/aQC/7HwCEV3FzG/Vf90C4PsxnLcjpN0biLMhs2l4aNdtK/suP14IBwGezof7/mJcVrz0E0Nz415FjE8UW1KMveoEVNd/2u//oEQ2+Mw8S0SfAXAAtbTMrzDzNBE9BOAIM+8D8C+JaAuAWQBnAPxq1PN2Ci+vNy1feBxxRy+vJT9gYcPIwaYJZcmAFajIph0UDOO2QrwsGbAwMH+eUXN3hrdh1CluqvLow9x3P7lgHj5UrUS64f4PQiwxfGZ+HsDzrsc+5/j5fgD3x3GuTpOEvkacefWmkrDDT01ps9bOzlQaxr1YKtcErt57Bb598lyi6ZNi7DtPzso2Vbpev3O/5/MJtetLd/36Ndsxfb4b2zM3zfjShUF7TV9HKm19iLopGtR4x7mEND3W6IETgYXQXnzlDHJWpuHp2x5ZhtSdmzJUkw3w8wiF9KJqKuKXHcNAwxtW3QteG7W6Ru8m+OXlO1cpXvdlrxVj9ZzBj7uBgWr333RTNIzxjnMJqTvWg89ON31GYT3lcmUOAOHR7WuaNMWHn55q7nTkqHD08wiFdEJAi84RULs/doxNetY0vVkqa++FDy5brLz+1r9nScsKMkgygpcH7l6leBHl/k8jPaWW2Y6q0yjFGGGKouJcQupec3am0vQZRSmpUmXxjH5ydbPqpaOcvVs9o27E/l51GStBcH9vdubKjrFJWFnvY2eItJkxh189q3zNaz8qRyqC0l1nWaJAx+m1Yqye8vDbtcESdlM0jPEOsoT0W82Yeu9RAyx2kwl3AYtqvGfPX1QcQYgLO7PFDonYYRhA3/Tb5JjDm1Y0rjd3O8FLPmm2VWZtoV3UWL0OnWcexlj3UjFWT3n4adtgMW3eYDM+UcT5i61ZBaolpMlqJqhGeD6C7rffisoer4kGuxAe23zahtTuMgaE14y3j2lfb87HoqJbGyzOWb7Xt1d+fK955nHRUz1tTftfdoogPTJ1ioE6/W/de83nLCxacHkzauMNS/HES6d8N0qdn5GdtROmo5X7WH7jFTqDfV2E9fDzbUjDtTK1VYj7MrMyhHcsnKc8X5Aetf1K3/S0TZvaXRAvQ5dVMDB/nvL5ulVLqdwcn997tOhr7N2fUZisHSd2Q5PxiWJTFaWQHKVyJfRKlxGssYkXznth/ryMMqNr/ryMVoPevo76of9sO+ipGH6cVadxjsnk/EHDUabx+XKlqk1xA9SpdnGEwOxQwhzg2dVI6Bzt8NJVOOP7TefPWU0rv+WajK3zl6raojo7rz9t4dtuoacMPtC9GyxB831NxaKAWjw3Z2V9l7/2plxc5jnKKkGIn7cDVJ1GYaGVqafsXsbKEHZvWWl8DF26JwO478kpLM6pFVe9khuKpXLLZnY32ooo9JzB71aC5vvaF+p9T075hmwIwLa1BRw6frpp5XPk9TON12fqbpluS1XntQndQ9gJOOh37zb2A1YG/27rjS3OhddKYGiwoNVrqjLj/KVZWBlqek9eyQ3uTljdrokTFjH4bca0ECxoOMo+rknVKgM4dPx003La3bDcyxbkFB6b0D9EnehnKnO4d2wSowdONAzy/c8cUx7XuRLw0kqyC/v8PHavittu1sQJixj8NhK00tYrf905EWy8YSn2Hi0G0rFxxzafeEnZf0aJGPv+Ji6hPPv6XzAvo7x2iYDROy4X6ZmELe1wpc458ovpxx3zj7vSP27E4LeROArBVJPG44dPBve66PImWT5niZ6NYAxzfCG9cqWqNeDMwJHXzzQZzG1rC75pxV73lF9yQ5yV390gpdxTaZlJ4y4E0V1oQbwKnXxsUJz3i7QXFIJwrlzBXes702708cMnW9KK77z5Wl/5Bt095VVs5peyHbTxSTekioqHHxOq2V3nFQXxKoJMDrKxKrQDBpr2e9p9LiflShXPTb3le2Hr7inn3liQLJ0w3no3pIqKwY+IM+XLjbtrDxC8EEy3JHUfV4y9kBRBrr2clcWCeZlAq0y/5/rdU2FStcOEY7tBSllCOhFw6tnoYCCSnoeueviu9cuajhunsY+mqyh0O0E1lbyuPSvTev3v3rIysnqnTbs0csJ462mr9FchHn4E/JosANF1fPzSNe0VRlzkrGwjZ1/kEPqTT6y+KnAWmA47weuR7WsAXL6OF+csXJqtNsT0lgxY2HzjVRj75qmm3HorQ5hlhm7P9s1SuXH9x2n0w3jraaz0d9NT4mmd5vqd+z29m3aLOUUVOXNji2SVZiodK8MX0kc7woNWlgBGizF/x8J5KM1UGunGY9861dI8p+IjvwzEf691szibl3iaePgR8Er56kTp9u5907HKFzhFssTY9y/tcAFVRrsyx029klXpxpUqe2pB2TizYdwetuoxv/uyG7z1MIiHH4GkvQCd+JQg9BpuLSjT56lWFt3iqYdFPPw20W4vQFVh69TDEYR+wF4t2/dCRuPxZ4laJgXVyqIfJRVsxMNPKbqGKHHgFp0SBCc5K4sM1WSKO40qjVml6jr89FSoWL/zPD8Y2Rx9wCmk7Q1QiOhjRHSCiF4mop2Kvy8gorH6318iouVxnLeXMckACktYY3/3+mWhWuQJ3cOi+TUDm4SxzxAwMP/y9ZXPWfrQi0I3OUg6qdcKOWiFbTcROaRDRFkAXwLwiwDeAPAtItrHzN9zPO2fATjLzH+fiD4N4N8D2B713L1MkOq8vEMbfMDKoDLHgbwdEwr5HB4eWoV1113RWFqrdM+F7mbmUhVHXj+TSCHfHDevKi7O1q4td2jz/MXZFqelMsf48YVKy+pVFcMnABtvWKocQzfo4UQhjhj+TQBeZuZXAYCIvgbgdgBOg387gN31n58G8EUiIk5zPClhTDtaqfL8nTdIHB+ws3jEWbU4PlHE7zw56SmtLHQXnZRR8KNcqeLBZ6dxoTLXZIB1zDGQzdQcoHPlSlPfB2cGEAPYe7SIddddYSSn3Esx/zhCOgUATq3dN+qPKZ/DzLMAzgH4adXBiOgeIjpCREdOnz4dw/C6E5PqPF0V39BgAS/uvAU/GNmMQsTN3UJdsXD0wImWJe7ogRNi7PuMqNdTUM7OVAKFNitVxqIF8/CDkc14cectGBqsFRGqNHpUBYvdoIcThdRl6TDzYwAeA2qbtgkPJzRhdbGdr/NaVpvm+etaxZlAaNUkt3vVPvjstOTq9xlEtVCIuxo2bbiNs58RH58oYve+aU/Nnl7JiovDwy8CuNbx+zX1x5TPIaJ5ABYD+FEM504lTo0dW+b1/meO+W7+uF+nuqVyVhZ316Vqd4xN+m4qDQ0WQod1rs7nlEtcZ8GM0D8wA2PfPKVtg+nGVC2HAGx47xW+Esim5AeaN291xvrqfK5Rre5l7NOmhxOFOAz+twC8j4iuJ6L5AD4NYJ/rOfsA/Er9508CONjL8fuwuti6zJwMoSE+tW1tAXuPFgNNJmGW4VaWMLxphejpCE1U5hhVA++eAPyD917h+5xCPodHtq/B47/+ISyaH0/A4e0Ls033g5eo2eiBE56rlXaJsyVFZINfj8l/BsABAN8H8CQzTxPRQ0S0pf60PwTw00T0MoDfAdCSutlL6JaQxVLZ0yPXvW6Oa+JTL+68BYeOnw48mQxvWhFYAbNSZYweOIGYRA2FlBO3bC4DOPzqWe3fC/lcU5wdqDVaiYPKHDfdD0ODBezZukqpWusVmyegaXy9QCxTKjM/D+B512Ofc/x8AcAdcZyrG/DKsCmWyhh+egoAmrJdRg+c8Ay92FkCYTaVhgYLeOrISbz4yhmzN+AYq9AfMJrTe+PAS/9GFSIxzUwzwX0/6DTxvc7ZK3F7J6nbtO02VJuzfs2XK1XGvWOTGD1wwrghuX0B6y5QBrBh5KB2I/e1H4nxFvQwgPMXZ0MZ/aA5+0sGLAwNFpTSIXHJMpsa6+FNK5SKs3ZIs9cQaYU6YbJqvMTTgMtt1bwwvVnsfHs/yQWdMJSflLMghOXu9cuUSpeAWiph29oCnpt6q2ViCdOLgQDMc8kquO9Bv3vanaWzZMDCrttWRgrlhM3SiwMRT/MhbHWd1+asHfvzU7Q0McLuwif73KqbwhnPd17EGYK2iYQghMWuwNYVa9kd30y8+HKlikPHTzcKCR8YP6adSJyMfnK1UhLZ7552G+XdW6IZeZs0V+uKwUf46jqTeHrYuGiWCHPMSu/AjkfqvHY7V965TE1x2rSQMkyliIHLsfiCJtTorgTfMHLQ89jOe8cp5eEVZ1fF51Xncd7T7TTKaa7WlZ62CF9d55XfaxOmf2fOyuLzn1rdksVgen4gvECa0N8sGbAaGS1+3L1+WePaNO3nGvSesqvGH92+JlC/WL97OmzqtAlprtYVgw8zw63C5CIfGixg9I7VgXLhTfN+w6RbCoIXZ2cqGD1wwvfayucsPH74JDaMHMQD48caBjRLtVfp8te97ikvA+6VWqnC755up1EOa086gYR00CofAJhV15k2QPELwTgp1JeoblSbQEDnFQ2F3oLqezvOzVU7vOHV19gOUxZL5ab4fZW5ce8EycQx2SjVpVaq8LunwzQpNyWsPekEYvARrXNVkIvQL89Yd1Go4o3DT02Z164LggYrQ6jOtebMlytVLJiXCRTPd772wWenAbRunP7Qhs4AAB2wSURBVO49Wmxk4rQzg8Xvnm6nUU5zP1xJywxBFGE090Vme1ZeYmgbRg5GLkhZUtcXEQ2c/iNKQdXd65cFSpN0skSzQlBJeidBkqmT7UTSMmPEdHff62IKepFFiSs6b67xiSLuHZsMfSyh+7h7/TI8PLQqdMP7vUeL2LN1VSjFVZ1zEdfmZVSDbbo676WJQTz8gOi8bbdh1RVkeV0ougsriofv7t1513/9f4ElFoTuxI74XZ3P4ez5i5gJ2Z3MTjiIS/Ygn7OwaME8TwPqZ2R1q+W76hNcXIS9l5Ok7T1texVVb0uT3f0Hn50OnPLlJamsygYy/eLcm1CP//qHkLPka+8HbIntYqmMSpVDC+G9WSorr0GgZryDXE9WhnD+0qxW7XV8oojBh17AvWOTnoqwqrRKBvD44ZOx9qBtZ/qminb305U7X4POALu1tm1swzo+UQy1lPUr1nCnpC00uMkIzQqd9sUkfWj7j8oc450LzZt8O7GLm/ZsXdXYCwJqxn73lpXYs/VG4+b271g4r6Xfsn2d2/ec6v5xG1ndvcRArMa4kzn1YftoBEEMvgadAWZGS6MGp9CS18XmlfLld2E52xYOb1phtDx3ptkNPzWF4aenRAGzjymVK4F7I1iZZhGxC47rrlSuNPavnA6JnYvvppDPoeThDOn6Qdg4r90w91IYOplT34nVhBh8DbqLplSutCa/O373MqheKV+6C0i1oghzAVTmuMWzEvqLLPkrQLqdmcpcTdl1zYMvYMeTk56rUNsh+fynVmsLEr0MqJ+hJqDh7XoVhsVpjE0riOOgE6sJMfgadBdNlqhFtsDZcEHn3RC8NTqGN61Qtnhzd+8B0lGiLXQfVa5dp4vm68MvOqegVK5oxfdU2vO6qlgvA+pnqJ3hmqHBAu5av6zF6MdtjINW+EahE6sJScvUoCvM0C057Yte1/TBz7ceGiwoGynbk4nzAouzUYTQW2SJPBuPFEtlWBmC5ZIUjoLKIOlSHv1Sk72kvwG9uFq7i7g6kZHTiQpdMfgadBemTrnPvui9VAP90LV4c3tQqgvDWcAlk0F/YmUJo59cDcDbcFbmGIRaYVRppoKMzyThhcog+aVUmkwGpl2oOmWMO0EnKnTF4Hugu5i8ZuEos7SpvoffheFVZJPPWThXjnaTCyml/nWaGE5GbQP2ke1rsCNkMV6WqCW8EVV22L7ndPnvadCjaSftnsCk8EqBSdFHlL97nTeOIo/Bh17QpoY6O2dJ1W1v4pTp8CvaC1tUpbsuTQoTTemlCtdO4lV4JQbfRdKVdXFc5H7G/NHta4y6cQndi7PNn1d4hwA8sn2Nsq+rk3zOAhFQmql4Xpc6RVh3xbfQPkRLJwBRutVENdZxeTRDgwU8+Oy01ssffmoKR14/gwxJJ6xexdlqEwDue3JKGcKzi6p014s9IURVhE2DFrwgBr+FsLmwUWOXcbRcc04Yi3P6qsrKHOOJl06Jse9xnEV7gPfek64gimF+/QHRM00kjNNeIuXhE9EVRPQXRPTX9f+XaJ5XJaLJ+r99Uc7ZbsLmwkatktu9T62/c9+TU0a6Gu6ybD85XN2GLQF4bWRz4IpMIX1kiBrXDgBlPjlQi7vr5v6g10GUvPVOSAv0O1E9/J0A/gczjxDRzvrv/1rxvDIzr4l4ro4Q1kOJUiU3PlHUGmjbMPt5/H5l6W50+dr2xKb6HIT0YmVaCwLd186erauaNk5V+1VNx8z6V+aqCCs7PHNpNrXNv3uFqJW2twP44/rPfwxgKOLxEieshxKlSs50FeC1Yghafbv+PUs8qxTtz0FXOSyki9E7VntW0KquHV8noY0hP5U33279fCG6h/8uZn6r/vPfAHiX5nkLiegIgFkAI8w8rjsgEd0D4B4AWLZsWcThhSNMLqzpykDV4zNISlyxVMb4RFHZHDrIcb598lzT/UwAtq1tfd+Sq59+7LDLzCXv1ZjbcPpdL6oq77gIsiKVDd/48DX4RPQNAO9W/Omzzl+YmYlIZx2uY+YiEb0HwEEiOsbMr6ieyMyPAXgMqKVl+o0vLQwNFnDk9TN44qVTqDIjS9RiQFUbs84G0KaoQjte1bduskRKLfFDx083fn9g/BgeDzE2ob24v1PbqRg9cMLXIbdj+rajobs+nLTLuzY9bj8UW3US35AOM3+EmT+g+Pd1AH9LRFcBQP3/H2qOUaz//yqA/wlgMLZ3kBLGJ4rYe7TY8IirzNh7tOjbtCEM5UoVu/dNNz2mCkXdtX5Zi1AVQe+12zfh+EQRjx8+GXhFn6F6vnbA1/UD7/qp+ZHDY3ZHJ1W40cSAVpkb4RPT77dd3rVWHTZndUSorF+JGtLZB+BXAIzU//+6+wn1zJ0ZZr5IRFcC2ADg9yKeN3WY5O/H6S2VypXGZOKVxmaLSxVLZV+Pzr4JTbxFFXMMXJytlev3YxWv1+f74wtVfP5TqxvfjVc1tA4GtO37vEJ6qnoL0+/XbqATd3qkLgS6e8tKMfBtJOqm7QiAXySivwbwkfrvIKJ1RPTl+nN+FsARIpoCcAi1GP73Ip43dZhk6Zh6S0sGLN9mEkCtlaJfGputU17I53xv8vMXZz3bOJpQrlTx4LPTfbnZy6h5qCrKlSruHZtspNfq8t698EqR3HjDUuXjG957hVbW2JR2pEd2UnZYuIxIK8RE2ObmbtwyDmE0b1S6JbqSd9X5MwSc99kAFMKTs7JYaGUCefh+8h5e1x+g3qA1ieG7j+WlhyNFU+lAmph3AJPOOCqv5m5NTNb5mqDNp1UeuunqolypirFvM+VK1dPDt7LUcl1sW1vA6IET2iI8rxWm7tp07geYrMi8Vn6qNMsdY5NY3qZm3EI4RFpBQ1BvRSdZDNS8L+djQVUDg0ogMGoSyUsGLOy6bWWj01DUQqosEeaY296AhQAsrss42wU5QePdacerslWlvuonu+GlYWOis26y+vRyGlR7WM6eykFlQoT2IAZfQVhdG3f+fhz6OIC+qcmSAQsXKnPam/TsTAXDT081nc9505+/OOsrweBkjrmheNhOpU1GrRmMbTA233gV9h4t9nzVr70idF8bJgkBfnUgqmvT7Yjs2bpKu8Hvlx7pt+8jFbPpQEI6CuLqHh/XcXRL8l23rWyEiHRUqpf77TobTb+48xbs3rKy5bhe2B7e+EQRQfZklwxY2s1MHU7vcO/RIj64bHHPbwTrrg2ThIAgm6A6zRoAeHHnLXhtZDMe2b4m0IaqSchQKmaTRzx8BXF1j4+ivOleftvel3tJbhIbtVPrnNW9h46fxpulMvIDlpHnbGUJG29YGjidMGdlsfnGq3Do+OlAqwkn5UoVL75yJtRruw3d/otqhZcfaJ5End2iRg+cwI6xSYweONGyajBZMQStNjcJGUrFbPKIh68gru7xfsexl9XOjTg/7+uR7TUNuh1jkxh86AUMPzXlG0+n+nHs43318MnG76bGe/vPXYu9R4uez8/nLOVm496jxb7os2tlKPAGuxvVNTO8aQWsbOuB374w2zLhmyhOxuXQOHGuMAB46jQJySEevoK4usd7HUcX319oZTzDQM7XmBrrqIm3+ZyFQ8dPe3pvBGBy10dbHt8wclD5Op1aZ7eQs7LYtrbQWCk5N+nDFp15XWOzip17ldaNifferiYlzlWBpGimEzH4CuLqHu9uJm1r2IweOIHzF9VSsDqj+mapHFiaYcmAFTm7JQNg95aVvo2udcZC59lXmZGzsl27EVuuVHHo+GllxlUYg69qCA5c9th1c6M7XKf7vJ2Px+XQeNHuZtxCOMTga4jrglV1GwoT3rg6nzNecjsLZPyaWPtBGcLufdOeqwSdsRifKAYScOs24tyErHLz5rqN3yRvh+tQ/1/3eRPQUFmNy6ERug8x+B0giGeez1m4ODun9L7slYIXbuMbNf++Oseem606WWXAW5MnreEcVSMRHbpVTdiVlSpt12tSURl33cgZiLQpK/QGsmnbAYJIwe7eslKbXqdKz7Sy1FCo1FXquo/n1SgjKAy0qILaeL3v+YpNSKDm+ZtWfrYDU2MPQBsC2XXbytCbt+7UTN2kkiUKvDcjaZGCaOl0AF1YZcmAhYH58wItq+PYDDOpqgyKswrXHlOYcNLd65fh4aFVeGD8WKheATZEiCwa5sWSAQsTn2vdpLYZnyhi975p7erIa9OagEaBm+q7snV1dCs+3bHzOQuLFgS73oTuw0tLR0I6HUDXnGTzjVdp5W51xLEUd28mx4Gq9+7wphWBNzD3f+ctrLvuCuw9Gk17pZ3G3i5686JRAfv0FCrV5sFYGcLoHau1n7/Tq/eLt6smAzsV1vm4lSGcv3S5slrkDvoT8fDbiNMbr6VbzjX93U8BMey5gnhvUTd1ddiaMDvGJgOHHoKqODppV7pnob5p7vXZqppyq2L59urA7irmljAIck3ovnfTsfgpYArdh5eHLwa/TZiGTeK44byW/X6Gw1Q22YmpQe502qUdNjd9PwQoJ2IVr9VDLDrGJ4oYfmrKaA+AADyyfY1y1XdXPaQVN7rv2Rk+EnoDkUdOANPMHNONNFVVrv34fU9OhdbsCVNsw4CvrG4SaZdX53OB3g8DWGhlffWETDaQd++bDpTdo1OXdPYVjpO4qseF7kYMfpswNeQmN5yuXP6B8WO4/5ljvj1qvVBl/hBqnZJ0hs5elfxgZDM+/6nVSmG3uMMqlkHay/CmFTUZggApMqWZCvZsXeUp7nbnzdf6H8dQJ8hOm40ib6Cb/L0w6dcg9D5i8NuEiSE3veF05fJPvHQqsliVrvn5t0+eUxptVVOXbWsLjckhS4RtawueCp5hUGnJOMnnrMaG9ugdq5sM+JIBCwOW+lK39eIXLVDnL+SsTCwhFnfabFiP20QrR0UcLQXDTDRCupAsnTahysyxMoR3LJyH0kwl0Maqzuvz8qKDeG/uzB8v/Ru3kRifKGLv0WJjLFVm7D1aVGaKhGntZzPjE2e/NFvF4EMvND5bZzPs8Yki7ntqquU1VoYauka6jesLBvF9wLvYSrVP4ydv8MD4MTzx0ilUmZElwp03X4uHh1YZaeXoiJLhFVdvByFZxOC3iTjL13UaKV4ZKbrqVxN0E8wcc4s4lmpcts6MStIZ8NaasbLUksaowr1xPFOZa0wKbmP04LPTqCri6/Pn1bx++7kqTGPcu25bifuemmo5jz2puPG6Ptw1CFXmxu/tULo0IcpEI6QHMfhtxKTLkMnNovMGP7hsMf7vK2eU2Rd7jxax7rorYp1gnLLOfhlIb5bKWo9SV5Bkp3Ka5O77TQlOY6TzvM9fqnqeK0PA+YuzuH7nft/vy378wWenG+fL56ymlYbqNaq/PfHSKeXzn3jpVNuULv1IaqIR4kVi+CEJGs8MG3sF1PHXbWsL+PbJc1rDF6azlo3fBp9JBpKXAVJ12nK294sr/h/VGM1xbTPW9PsaGixg4nMfxWsjm/HayGZM7vpoqAlXt2qrMiu18a2sehURJ5Ll0xuIwQ9BGOMdtd2huz2hnz49EN7g6Tb4ALNCLb/9A/fx8zkLC60MdoxNYsPIQWy8YannJq1pW0auj1e3YRuUKJNoELxSXQGYK6YFxMuJkSyf3iDSnUBEdxDRNBHNEZEy0b/+vI8R0QkiepmIdkY5ZxoIY7zjXhKbvC6K9+WeYAA0JjkvTLM/7OM/sn0NLs7O4ezMZU9679Ei5mlSK+2NY9MeucVSGZUqR+5E5Txeu9Glgd5587UYPXCiJd/fboQSBT8nRrfKHD1wQrJ2uoioMfzvAtgK4A90TyCiLIAvAfhFAG8A+BYR7WPm70U8d2KEMd5xx169ml0A3t5XGBkGvzBOWJkI3eSpY64e7ggiplmZ4ybhsEwE+QVbVx5on568nQaqytK5fud+5Wuihq+C9rmVrJ3uJJKHz8zfZ2Y/1+ImAC8z86vMfAnA1wDcHuW8SRMmnhn3klhXMAV4e9lh9xK8DEqYnG6boB7z4pyF+5851rIRm89ZeHT7mpZeqjalcqVhnO+8+dpAxVlOGLWN2bD7MaY8PLQKr+y5Fa+NbMYre25tTALtiqUHdWKihiiFZOhEDL8AwJl28Eb9sa4ljPGOo/DF73iPbF+D1+ohGN1xw96oXrrsdvvFMAYviO59zsqCSL0CWLRgnmdBE4CmkNH2m65tKc56dPsaow3jszOVxIxdu2LpQScSydrpTnxDOkT0DQDvVvzps8z89bgHRET3ALgHAJYtWxb34WMhbI593F2Gwhwv7I2q65ylkkUOMibT0IpTfVOFPX6TDl/lShX7v/MWFi2Yh3Pl1iK4sL0COmHs2tWeMGif26TSQ4Vo+Bp8Zv5IxHMUATh3oa6pP6Y732MAHgNqapkRz902urVFXNgb1W1oVHHwMIU4BZ+9CKAWqrI3jv005N3j1F1AZ2cqjbCQarKyz+Mu8MpZWSyYl1HWEXTK2LXj2gs6kXSiEboQP50ovPoWgPcR0fWoGfpPA/jlDpxXUBDlRnUamrg2D008cqchNRm/c5ymev/Oycq9OamqFm6nsYujq1kYgkwk0gi9O4lk8InolwD8ZwBLAewnoklm3kREVwP4MjPfysyzRPQZAAcAZAF8hZmnI49cCIxtSMqVakOWoRDyRo2ypHcbtG1rC3hu6i2l1+wuKorDE9XxZqmsNLa6fgXtMHZe2S/tOmdYunWV289IA5SQJOWFhSVKk5Q4j6d73ba1BYx981RLjvndPg1B/L6H8Ylii9wBoJYzXjJg4UJlLrbPKAy6FUk+Z+HibLJjE7oD6XgVM3EbT9NzOg3bxhuW4tDx08YTjs6QROm4FWbS041DJwSnao7uPL/X96D7u0qDyCs23+42gM7PMejdKC0KBTfSxDxmOq0cqFrmO9UUTTJk2pFGp1vSe00EQaWevbKA/L4H3d/dxp5QUxd93PGZOmln9o1pK0wdkgYpBEEMfgh0N1mxVA6lhumHiVhZuVLF7n3TWkOri7nnB8wkCkzxq8AMI/VsU65Ucd+TU9gxNulZaWx/D7q/q6RoDh0/nUiqocl369VHQNIghSCIeFoIdDcZAW2pvjT14krlivb8KpVFAHj7wmysFaJ+hV26wqE7b75WWyXrpMrceH+659vfQxDeLJUTEQjz+m6dBXq7btMrjAqCKWLwPdCpB+pkDdyeY1zVl4sNhcLcOM8/NFjAovmtC7o4hLec+IWOdBXHDw+tChy/ZqDF6Ku+B/ffVditDuOshjZB5zwU8rmGcJ0dOuv02ITeQ0I6GkzEoZzhE51HGUeMNYhQmNf5z2kabccZBzYJi+hi/yZFWG4YtQwWu2LW6/WF+ma3qvWi7Sl3OtVw4w1Lm/ZjnI+7kTRIISri4WvwC0245YN1GixxxFhLmo5NwOVl/xJNLN55/k40sYgSFlG91oSLs3N4ZPsaz+/BzmZ5eGhVqjzlQ8dPB3pcEKIgHr6GoFkt7Sw113muzpQ8XQqi8/wbb1iKxw+fbElHDDtGXTbOkdfPNEn7mvbXda+c8gMW3r4w25Kb78aZmRO0EjdpRIRM6CRi8DUEzdhoZ6m5lxFzGt3F9c5RpZlWQbDxiSL2Hi0q0xHjKLyyQ15HXj+DvUeLjYybKrO2v65uwnDKIuj60bpx7hEA6apI9UJEyIROIgZfQxiPvV2eo86IAc2aLqVyBTkri0e2r2kZhypEZacjhkEX8rI9e/fj7hoFPwkBXaNzHSZ7BGlERMiETiIGX0PaPEWVEdswctC4AKxTLRZ1ufTu5+smjN37pnH+oncYR6Vg2a0GMm3XmdDbiMH3IO2eYhAj3qkWi7oCKvd5dGP38+pt3Z0gshJpJ+3XmdA7iMHvYoIY8bhDB7rjbVtb8Ex79Bu7H3Fl1HSb+J0gxIEY/C4miBGPO3Tgdbx1113hex7d2HUSAkAtK6mdEsRHXj/TUysHQXAjapldTjd7qrrmIsNPTbXE8K0sYfSTq2N5bzqdHdXegFSzCt2GqGX2MN0c//UauzNLZ8mAhV23rYztfer2D3TSGN36+QqCGzH4QuqIMomZrHiC7B9IAZTQS4i0gtAz2LF5P8VSnfidCimAEnoJMfhCz+Cnf2SjUp68a/0ykR8Weh4J6Qg9Q5C6BHfYaHyiiP3feasxYeRzFnZviW/fQBDSgHj4Qs8QVg3UDgU500Evzs7FOjZBSANi8IWeIaw0s2koSBC6HQnpCD1D2OIy01BQN9c8CAIQ0eAT0R0AdgP4WQA3MbOySoqIXgPwEwBVALO6ogBBiEqYlE4TiQqTDmiCkHaihnS+C2ArgL80eO5GZl4jxl5IGyahIAn7CL1AJA+fmb8PABSl6aogJIxJKEg6Uwm9QKdi+AzgBSJiAH/AzI916LxCDCQZu+7Uuf1CQdKZSugFfEM6RPQNIvqu4t/tAc7zD5n5gwA+DuA3iejnPc53DxEdIaIjp09LI+ekMa1e7bVzu4nSnF0Q0oKvwWfmjzDzBxT/vm56EmYu1v//IYA/BXCTx3MfY+Z1zLxu6dKlpqcQ2kSSses0xc1V1bmipCl0G20P6RDRIgAZZv5J/eePAnio3ecV4iHJ2HXa4ubdrEwqCEDELB0i+iUiegPAhwDsJ6ID9cevJqLn6097F4D/Q0RTAL4JYD8z/3mU8wqdI2z1arefWxB6kUgGn5n/lJmvYeYFzPwuZt5Uf/xNZr61/vOrzLy6/m8lM//bOAYudIYkY9cSNxeEeJFKW8GTuFsjdsu5BaEXkRaHgiAIPYRXi0MRTxMEQegTxOALgiD0CWLwBUEQ+gQx+IIgCH2CGHxBEIQ+IdVZOkR0GsDrEQ9zJYC/i2E4SdDNYwe6e/wy9mSQsUfnOmZW6tKk2uDHAREd6VYN/m4eO9Dd45exJ4OMvb1ISEcQBKFPEIMvCILQJ/SDwe/mZivdPHagu8cvY08GGXsb6fkYviAIglCjHzx8QRAEAWLwBUEQ+oa+MfhE9FtEdJyIpono95IeT1CI6D4iYiK6MumxmEJEo/XP/DtE9KdElE96TH4Q0ceI6AQRvUxEO5MejylEdC0RHSKi79Wv8d9OekxBIaIsEU0Q0XNJjyUIRJQnoqfr1/r3iehDSY9JR18YfCLaCOB2AKuZeSWA/5DwkAJBRNei1hryZNJjCchfAPgAM98I4K8A3J/weDwhoiyALwH4OID3A7iTiN6f7KiMmQVwHzO/H8B6AL/ZRWO3+W0A3096ECH4AoA/Z+YbAKxGit9DXxh8AL8BYISZLwKNZurdxCMA/hWArtphZ+YXmHm2/uthANckOR4DbgLwcr1L2yUAX0PNUUg9zPwWM3+7/vNPUDM6XdMphoiuAbAZwJeTHksQiGgxgJ8H8IcAwMyXmLmU7Kj09IvB/xkA/4iIXiKi/0VEP5f0gEwhotsBFJl5KumxROSfAvizpAfhQwHAKcfvb6CLjKYNES0HMAjgpWRHEohHUXNq5pIeSECuB3AawH+rh6O+TESLkh6Ujp5pcUhE3wDwbsWfPova+7wCtaXuzwF4kojewynJSfUZ+++iFs5JJV5jZ+av15/zWdRCDo93cmz9CBG9A8BeAPcy84+THo8JRPQJAD9k5qNE9OGkxxOQeQA+COC3mPklIvoCgJ0A/k2yw1LTMwafmT+i+xsR/QaAZ+oG/ptENIea0NHpTo3PC93YiWgVah7EFBEBtZDIt4noJmb+mw4OUYvX5w4ARPSrAD4B4BfSMsF6UARwreP3a+qPdQVEZKFm7B9n5meSHk8ANgDYQkS3AlgI4J1E9FVmvjvhcZnwBoA3mNleTT2NmsFPJf0S0hkHsBEAiOhnAMxHOlTtPGHmY8z895h5OTMvR+3i+mBajL0fRPQx1JbpW5h5JunxGPAtAO8jouuJaD6ATwPYl/CYjKCaR/CHAL7PzP8x6fEEgZnvZ+Zr6tf4pwEc7BJjj/q9eIqIVtQf+gUA30twSJ70jIfvw1cAfIWIvgvgEoBf6QJvsxf4IoAFAP6ivkI5zMz/Itkh6WHmWSL6DIADALIAvsLM0wkPy5QNAP4xgGNENFl/7HeZ+fkEx9Qv/BaAx+tOwqsAfi3h8WgRaQVBEIQ+oV9COoIgCH2PGHxBEIQ+QQy+IAhCnyAGXxAEoU8Qgy8IgtAniMEXBEHoE8TgC4Ig9An/H51wJxh25aKSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(T_res, Y_res)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation coefficient between T and Y errors: 0.31\n"
     ]
    }
   ],
   "source": [
    "corr_coeficient = pearsonr(T_res, Y_res)[0]\n",
    "print(\"Correlation coefficient between T and Y errors: {0:.2f}\".format(corr_coeficient))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation coefficient between the residuals is quite large, which means that there is some unobserved variables that affect both $T$ and $Y$. To get an accurate estimate in this case, we need to use IVs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Using Intrumental Variables: 2SLS <a class=\"anchor\" id=\"2sls\"></a>\n",
    "\n",
    "Two stage least square regression procedure (2SLS):\n",
    "1. Fit a model $T \\sim W, Z$\n",
    "2. Fit a linear model $Y \\sim \\hat{T}$ where $\\hat{T}$ is the prediction of the model in step 1.\n",
    "The coefficient from 2. above is the average treatment effect.\n",
    "\n",
    "If interested in heterogeneous treatment effects, fit a model $Y \\sim \\hat{T}\\otimes h(X)$, where $h(X)$ is a chosen featurization of the treatment effect. \n",
    "\n",
    "For more information, see the `econml` [documentation](https://econml.azurewebsites.net)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For average treatment effects, X is a column of 1s\n",
    "W = X\n",
    "Z = Z.reshape(-1, 1)\n",
    "T = T.reshape(-1, 1)\n",
    "X_ate = np.ones_like(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We apply 2SLS from the EconML library\n",
    "two_sls_est = NonparametricTwoStageLeastSquares(\n",
    "    t_featurizer=PolynomialFeatures(degree=1, include_bias=False),\n",
    "    x_featurizer=PolynomialFeatures(degree=1, include_bias=False),\n",
    "    z_featurizer=PolynomialFeatures(degree=1, include_bias=False),\n",
    "    dt_featurizer=None) # dt_featurizer only matters for marginal_effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_sls_est.fit(Y, T, X_ate, W, Z)\n",
    "two_sls_ate = two_sls_est.effect(np.ones((1,1)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average treatment effect: 0.142\n"
     ]
    }
   ],
   "source": [
    "print(\"Average treatment effect: {0:.3f}\".format(two_sls_ate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Bonus: Deep Instrumental Variables <a class=\"anchor\" id=\"deepiv\"></a>\n",
    "\n",
    "For very flexible, but fully non-parametric IV methods, you can use neural networks for the two models in 2SLS and a mixture of gaussians for the featurizer $h(X)$. In `econml`, this method is called DeepIV. \n",
    "\n",
    "The NLSYM dataset is small (on neural net scale) so applying DeepIV is a bit of a stretch. Nevertheless, we apply DeepIV the NLSYM data as an example. You should not read too much into the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# Define treatment model, T ~ X, Z\n",
    "treatment_model = keras.Sequential([keras.layers.Dense(64, activation='relu', input_shape=(X.shape[1] + 1,)),\n",
    "                                    keras.layers.Dropout(rate=0.17),\n",
    "                                    keras.layers.Dense(32, activation='relu'),\n",
    "                                    keras.layers.Dropout(rate=0.17),\n",
    "                                    keras.layers.Dense(1)])\n",
    "# Define outcome model, Y ~ T_hat, X\n",
    "response_model = keras.Sequential([keras.layers.Dense(64, activation='relu', input_shape=(X.shape[1] + 1,)),\n",
    "                                   keras.layers.Dropout(rate=0.17),\n",
    "                                   keras.layers.Dense(32, activation='relu'),\n",
    "                                   keras.layers.Dropout(rate=0.17),\n",
    "                                   keras.layers.Dense(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_fit_options = { \"epochs\": 30,\n",
    "                      \"validation_split\": 0.3,\n",
    "                      \"callbacks\": [keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)]}\n",
    "\n",
    "deepIvEst = DeepIVEstimator(n_components = 10, # number of gaussians in our mixture density network\n",
    "                            m = lambda z, x : treatment_model(keras.layers.concatenate([z,x])), # treatment model\n",
    "                            h = lambda t, x : response_model(keras.layers.concatenate([t,x])),  # response model\n",
    "                            n_samples = 1, # number of samples to use to estimate the response\n",
    "                            use_upper_bound_loss = False, # whether to use an approximation to the true loss\n",
    "                            n_gradient_samples = 1, # number of samples to use in second estimate of the response (to make loss estimate unbiased)\n",
    "                            optimizer='adam', # Keras optimizer to use for training - see https://keras.io/optimizers/ \n",
    "                            first_stage_options = keras_fit_options, # options for training treatment model\n",
    "                            second_stage_options = keras_fit_options) # options for training response model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2093 samples, validate on 898 samples\n",
      "Epoch 1/30\n",
      "2093/2093 [==============================] - 2s 999us/step - loss: 12.9197 - val_loss: 5.2148\n",
      "Epoch 2/30\n",
      "2093/2093 [==============================] - 0s 176us/step - loss: 5.2703 - val_loss: 4.5710\n",
      "Epoch 3/30\n",
      "2093/2093 [==============================] - 0s 165us/step - loss: 4.6385 - val_loss: 4.1145\n",
      "Epoch 4/30\n",
      "2093/2093 [==============================] - 0s 175us/step - loss: 4.1656 - val_loss: 3.7890\n",
      "Epoch 5/30\n",
      "2093/2093 [==============================] - 0s 132us/step - loss: 3.8190 - val_loss: 3.4813\n",
      "Epoch 6/30\n",
      "2093/2093 [==============================] - 0s 142us/step - loss: 3.5759 - val_loss: 3.3215\n",
      "Epoch 7/30\n",
      "2093/2093 [==============================] - 0s 144us/step - loss: 3.4377 - val_loss: 3.2289\n",
      "Epoch 8/30\n",
      "2093/2093 [==============================] - 0s 150us/step - loss: 3.3842 - val_loss: 3.1585\n",
      "Epoch 9/30\n",
      "2093/2093 [==============================] - 0s 117us/step - loss: 3.2949 - val_loss: 3.0972\n",
      "Epoch 10/30\n",
      "2093/2093 [==============================] - 0s 114us/step - loss: 3.2123 - val_loss: 3.0349\n",
      "Epoch 11/30\n",
      "2093/2093 [==============================] - 0s 105us/step - loss: 3.1475 - val_loss: 2.9645\n",
      "Epoch 12/30\n",
      "2093/2093 [==============================] - 0s 108us/step - loss: 3.0503 - val_loss: 2.8775\n",
      "Epoch 13/30\n",
      "2093/2093 [==============================] - 0s 99us/step - loss: 2.9629 - val_loss: 2.7634\n",
      "Epoch 14/30\n",
      "2093/2093 [==============================] - 0s 136us/step - loss: 2.8140 - val_loss: 2.5717\n",
      "Epoch 15/30\n",
      "2093/2093 [==============================] - 0s 125us/step - loss: 2.5700 - val_loss: 2.2171\n",
      "Epoch 16/30\n",
      "2093/2093 [==============================] - 0s 146us/step - loss: 2.0198 - val_loss: 1.3857\n",
      "Epoch 17/30\n",
      "2093/2093 [==============================] - 0s 143us/step - loss: 1.5607 - val_loss: 1.3050\n",
      "Epoch 18/30\n",
      "2093/2093 [==============================] - 0s 141us/step - loss: 1.5209 - val_loss: 1.3008\n",
      "Epoch 19/30\n",
      "2093/2093 [==============================] - 0s 135us/step - loss: 1.4866 - val_loss: 1.2904\n",
      "Epoch 20/30\n",
      "2093/2093 [==============================] - 0s 110us/step - loss: 1.5001 - val_loss: 1.3008\n",
      "Epoch 21/30\n",
      "2093/2093 [==============================] - 0s 113us/step - loss: 1.4630 - val_loss: 1.3068\n",
      "Train on 2093 samples, validate on 898 samples\n",
      "Epoch 1/30\n",
      "2093/2093 [==============================] - 4s 2ms/step - loss: 205.0209 - val_loss: 4.8451\n",
      "Epoch 2/30\n",
      "2093/2093 [==============================] - 1s 243us/step - loss: 79.8936 - val_loss: 198.2861\n",
      "Epoch 3/30\n",
      "2093/2093 [==============================] - 1s 272us/step - loss: 187.2711 - val_loss: 10.8439\n"
     ]
    }
   ],
   "source": [
    "deepIvEst.fit(Y, T, X, Z)\n",
    "deepIv_effect = deepIvEst.effect(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average treatment effect: 0.172\n"
     ]
    }
   ],
   "source": [
    "print(\"Average treatment effect: {0:.3f}\".format(deepIv_effect.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Heterogeneity of treatment effects\n",
    "plt.hist(deepIv_effect)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-phd_env] *",
   "language": "python",
   "name": "conda-env-.conda-phd_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
