{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/home/dtd/Documents/interpretable_machine_learning/Source Code/my_work/lib')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import dowhy.datasets\n",
    "import dowhy\n",
    "import propensity_score_estimator as pse\n",
    "import incremental_ps_score_estimator as ipse\n",
    "import math \n",
    "import timeit\n",
    "\n",
    "from dowhy import CausalModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_effect = 30\n",
    "data = dowhy.datasets.linear_dataset(beta=true_effect,\n",
    "        num_common_causes=5,\n",
    "        num_instruments = 0,\n",
    "        num_samples=10000,\n",
    "        treatment_is_binary=True)\n",
    "df_expr = data[\"df\"].copy()\n",
    "df_expr['v0'] = [1 if x == True else 0 for x in df_expr['v0']]\n",
    "\n",
    "D0, D1 = train_test_split(df_expr, train_size = 0.9, random_state = 1)\n",
    "D0 = D0.reset_index().drop(columns = ['index'])\n",
    "D1 = D1.reset_index().drop(columns = ['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment = data['treatment_name'][0]\n",
    "covariate = data['common_causes_names']\n",
    "outcome = data['outcome_name']\n",
    "n_splits = 5\n",
    "delta = np.linspace(0.5, 5, n_splits)\n",
    "\n",
    "# effect = ipse.proposed_estimation(df_expr, treatment, covariate, outcome, delta, n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipse.sample_estimator(D0, D1, treatment, covariate, outcome, delta[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(true_effect):\n",
    "    data = dowhy.datasets.linear_dataset(beta=true_effect,\n",
    "            num_common_causes=7,\n",
    "            num_instruments = 0,\n",
    "            num_samples=40000,\n",
    "            treatment_is_binary=True)\n",
    "    df_expr = data[\"df\"].copy()\n",
    "    df_expr['v0'] = [1 if x == True else 0 for x in df_expr['v0']]\n",
    "\n",
    "    D0, D1 = train_test_split(df_expr, train_size = 0.9, random_state = 1)\n",
    "    D0 = D0.reset_index().drop(columns = ['index'])\n",
    "    D1 = D1.reset_index().drop(columns = ['index'])\n",
    "    treatment = data['treatment_name'][0]\n",
    "    covariate = data['common_causes_names']\n",
    "    outcome = data['outcome_name']\n",
    "    n_splits = 5\n",
    "    delta = np.linspace(0.5, 5, n_splits)\n",
    "    e = ipse.proposed_estimation(df_expr, treatment, covariate, outcome, delta, n_splits)\n",
    "    return np.mean(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in np.linspace(10,50,25):\n",
    "#     print(\"True effect {}\".format(i))\n",
    "#     effect = evaluation(i)\n",
    "#     print(\"Causal effect {}\".format(effect))\n",
    "#     print(\"MAE {}\".format(abs(i - abs(effect))))\n",
    "#     print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_inc(true_effect, data):\n",
    "#     data = dowhy.datasets.linear_dataset(beta=true_effect,\n",
    "#             num_common_causes=7,\n",
    "#             num_instruments = 0,\n",
    "#             num_samples=40000,\n",
    "#             treatment_is_binary=True)\n",
    "    df_expr = data[\"df\"].copy()\n",
    "    df_expr['v0'] = [1 if x == True else 0 for x in df_expr['v0']]\n",
    "\n",
    "    rfc = RandomForestClassifier(max_depth=50, random_state=0)\n",
    "    rfc.fit(df_expr[data['common_causes_names']], df_expr[data['treatment_name'][0]])\n",
    "\n",
    "    features = data['common_causes_names'] + data['treatment_name']\n",
    "    rf = RandomForestRegressor(n_estimators = 100, random_state=0)\n",
    "    rf.fit(df_expr[features], df_expr['y'])\n",
    "    \n",
    "    treatment = data['treatment_name'][0]\n",
    "    covariate = data['common_causes_names']\n",
    "    outcome = data['outcome_name']\n",
    "    e = ipse.incremenal_ps_score_estimator(df_expr, treatment, covariate, rfc, rf, delta = 2)\n",
    "    \n",
    "    att, atc, est= pse.propensity_score_estimator_k_nearest_neighbor(df_expr, \n",
    "                                                                     treatment, \n",
    "                                                                     outcome, \n",
    "                                                                     'ps_1')\n",
    "    return np.mean(e), est \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True effect 10.0\n",
      "Causal effect of incremental 3.206856135761271 and 13.419461486152649\n",
      "MAE of incremental and nearest 6.793143864238729 and 3.419461486152649\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in np.linspace(10,50,25):\n",
    "    print(\"True effect {}\".format(i))\n",
    "    data = dowhy.datasets.linear_dataset(beta=10,\n",
    "                num_common_causes=7,\n",
    "                num_instruments = 0,\n",
    "                num_samples=40000,\n",
    "                treatment_is_binary=True)    \n",
    "   \n",
    "    effect, est = evaluation_inc(10, data)\n",
    "    print(\"Causal effect of incremental {} and {}\".format(effect, est))\n",
    "    print(\"MAE of incremental and nearest {} and {}\".format(abs(10 - abs(effect)),\n",
    "                                                     abs(10 - abs(est))\n",
    "                                                    ))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    if abs(10 - abs(effect)) > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment = data['treatment_name'][0]\n",
    "covariate = data['common_causes_names']\n",
    "outcome = data['outcome_name']\n",
    "    \n",
    "features = covariate.copy()\n",
    "\n",
    "features.append(treatment)\n",
    "\n",
    "df_expr = data[\"df\"].copy()\n",
    "df_expr['v0'] = [1 if x == True else 0 for x in df_expr['v0']]\n",
    "\n",
    "rfc = RandomForestClassifier(max_depth=50, random_state=0)\n",
    "rfc.fit(df_expr[data['common_causes_names']], df_expr[data['treatment_name'][0]])\n",
    "\n",
    "features = data['common_causes_names'] + data['treatment_name']\n",
    "rf = RandomForestRegressor(n_estimators = 100, random_state=0)\n",
    "rf.fit(df_expr[features], df_expr['y'])\n",
    "    \n",
    "    \n",
    "\n",
    "model_t = \n",
    "\n",
    "## Compute propensity_score\n",
    "df['ps_1'] = model_t.predict_proba(df[covariate])[:,1]\n",
    "df['ps_0'] = model_t.predict_proba(df[covariate])[:,0]\n",
    "\n",
    "## Compute incremental propensity score\n",
    "df['incre_ps_1'] = (delta * df['ps_1']) / (delta * df['ps_1'] + df['ps_0'])\n",
    "df['incre_ps_0'] = 1 - df['incre_ps_1']\n",
    "\n",
    "## Compute counterfactual outcome with no treatment\n",
    "df_pos = df.copy()\n",
    "df_pos['v0'] = 0\n",
    "df['treated_cf_outcome'] = model_y.predict(df_pos[features])\n",
    "\n",
    "## Compute counterfactual outcome with treatment\n",
    "df_control = df.copy()\n",
    "df_control['v0'] = 1\n",
    "df['control_cf_outcome'] = model_y.predict(df_control[features])\n",
    "\n",
    "df['incre_effect'] = df['incre_ps_1']*df['treated_cf_outcome'] + df['incre_ps_0']*df['control_cf_outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' (aaaaa)'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import regex as re\n",
    "filename = \"abstract{aaaaa} (aaaaa)\"\n",
    "re.sub(r'abstract\\{[^)]*\\}', '', filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''@article{lipton_mythos_2017,\n",
    "\ttitle = {The {Mythos} of {Model} {Interpretability}},\n",
    "\turl = {http://arxiv.org/abs/1606.03490},\n",
    "\tabstract{Supervised machine learning models boast remarkable predictive capabilities. But can you trust your model? Will it work in deployment? What else can it tell you about the world? We want models to be not only good, but interpretable. And yet the task of interpretation appears underspecified. Papers provide diverse and sometimes non-overlapping motivations for interpretability, and offer myriad notions of what attributes render models interpretable. Despite this ambiguity, many papers proclaim interpretability axiomatically, absent further explanation. In this paper, we seek to refine the discourse on interpretability. First, we examine the motivations underlying interest in interpretability, finding them to be diverse and occasionally discordant. Then, we address model properties and techniques thought to confer interpretability, identifying transparency to humans and post-hoc explanations as competing notions. Throughout, we discuss the feasibility and desirability of different notions, and question the oft-made assertions that linear models are interpretable and that deep neural networks are not.},\n",
    "\turldate = {2020-03-08},\n",
    "\tjournal = {arXiv:1606.03490 [cs, stat]},\n",
    "\tauthor = {Lipton, Zachary C.},\n",
    "\tmonth = mar,\n",
    "\tyear = {2017},\n",
    "\tnote = {arXiv: 1606.03490},\n",
    "\tkeywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing},\n",
    "\tannote = {Comment: presented at 2016 ICML Workshop on Human Interpretability in Machine Learning (WHI 2016), New York, NY},\n",
    "\tfile = {3236386.3241340.pdf:C\\:\\\\Users\\\\13762012\\\\Zotero\\\\storage\\\\3BK4MMPE\\\\3236386.3241340.pdf:application/pdf;arXiv.org Snapshot:C\\:\\\\Users\\\\13762012\\\\Zotero\\\\storage\\\\DUXP935F\\\\1606.html:text/html;arXiv Fulltext PDF:C\\:\\\\Users\\\\13762012\\\\Zotero\\\\storage\\\\ILE5E4PW\\\\Lipton - 2017 - The Mythos of Model Interpretability.pdf:application/pdf}\n",
    "}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@article{lipton_mythos_2017,\\n\\ttitle = {The {Mythos} of {Model} {Interpretability}},\\n\\turl = {http://arxiv.org/abs/1606.03490},\\n\\t,\\n\\turldate = {2020-03-08},\\n\\tjournal = {arXiv:1606.03490 [cs, stat]},\\n\\tauthor = {Lipton, Zachary C.},\\n\\tmonth = mar,\\n\\tyear = {2017},\\n\\tnote = {arXiv: 1606.03490},\\n\\tkeywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing},\\n\\tannote = {Comment: presented at 2016 ICML Workshop on Human Interpretability in Machine Learning (WHI 2016), New York, NY},\\n\\tfile = {3236386.3241340.pdf:C\\\\:\\\\Users\\\\13762012\\\\Zotero\\\\storage\\\\3BK4MMPE\\\\3236386.3241340.pdf:application/pdf;arXiv.org Snapshot:C\\\\:\\\\Users\\\\13762012\\\\Zotero\\\\storage\\\\DUXP935F\\\\1606.html:text/html;arXiv Fulltext PDF:C\\\\:\\\\Users\\\\13762012\\\\Zotero\\\\storage\\\\ILE5E4PW\\\\Lipton - 2017 - The Mythos of Model Interpretability.pdf:application/pdf}\\n}'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text = '''abstract{aaaa}'''\n",
    "# text = \"\"\"abstract{Supervised mac},assdsda urldate = {2020-03-08}, aaaaaaaaaaaaaaaaaaa, asdsd\"\"\"\n",
    "# text = \"\"\"\n",
    "# abstract{aaaa} url = {}\n",
    "# \"\"\"\n",
    "\n",
    "re.sub(r'abstract\\{[^}]*\\}', '', text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-phd_env] *",
   "language": "python",
   "name": "conda-env-.conda-phd_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
