{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "[MLENS] backend: threading\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(\n",
    "    1,\n",
    "    '/home/dtd/Documents/interpretable_machine_learning/Source Code/my_work/lib'\n",
    ")\n",
    "sys.path.insert(\n",
    "    1,\n",
    "    '/home/dtd/Documents/interpretable_machine_learning/Causal Inference/CEA')\n",
    "\n",
    "import data_load\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import dowhy.datasets\n",
    "import dowhy\n",
    "import propensity_score_estimator as pse\n",
    "import incremental_ps_score_estimator as ipse\n",
    "import math\n",
    "import timeit\n",
    "import evaluation as evl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from econml.drlearner import ForestDRLearner\n",
    "from econml.drlearner import LinearDRLearner\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from econml.metalearners import SLearner\n",
    "from econml.metalearners import XLearner\n",
    "from econml.metalearners import TLearner\n",
    "\n",
    "from econml.drlearner import LinearDRLearner\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from econml.dml import ForestDMLCateEstimator\n",
    "from dowhy import CausalModel\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import sem\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from econml.dml import LinearDMLCateEstimator\n",
    "from econml.inference import BootstrapInference\n",
    "from econml.dml import SparseLinearDMLCateEstimator\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV\n",
    "from mlens.ensemble import SuperLearner\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment = 't'\n",
    "outcome = 'yf'\n",
    "col =  [\"t\", \"yf\", \"ycf\", \"mu0\", \"mu1\" ]\n",
    "cov = [\"x\" + str(i) for i in range(1,26)]\n",
    "col = col + cov\n",
    "features = cov + [\"t\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, i_exp):\n",
    "    col =  [\"t\", \"yf\", \"ycf\", \"mu0\", \"mu1\" ]\n",
    "    cov = [\"x\" + str(i) for i in range(1,26)]\n",
    "    col = col + cov\n",
    "    features = cov + [\"t\"] \n",
    "    D = np.load(path)\n",
    "    df = pd.DataFrame(columns=col)\n",
    "\n",
    "    for i in range(1,26):\n",
    "        df['x' + str(i)]  = D['x'][:,i-1,i_exp-1]\n",
    "\n",
    "    df['t']  = D['t'][:,i_exp-1:i_exp]\n",
    "    df['yf'] = D['yf'][:,i_exp-1:i_exp]\n",
    "    df['ycf'] = D['ycf'][:,i_exp-1:i_exp]\n",
    "    df['mu0'] = D['mu0'][:,i_exp-1:i_exp]\n",
    "    df['mu1'] = D['mu1'][:,i_exp-1:i_exp]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame()\n",
    "df_result['true_effect'] = 0\n",
    "df_result['incremental'] = 0\n",
    "\n",
    "PATH_TRAIN = \"/home/dtd/Downloads/ihdp_npci_1-100.train.npz\"\n",
    "PATH_TEST = \"/home/dtd/Downloads/ihdp_npci_1-100.test.npz\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def influence_function(data, treatment, covariate, outcome, delta, model_y, model_t):\n",
    "\n",
    "    features = covariate.copy()\n",
    "    features.append(treatment)\n",
    "\n",
    "    data['p1'] = model_t.predict_proba(data[covariate])[:,1]\n",
    "    data['p0'] = 1 - data['p1']\n",
    "\n",
    "    ## Compute counterfactual outcome with no treatment\n",
    "    data_pos = data.copy()\n",
    "    data_pos[treatment] = 1\n",
    "    data['cf1'] = model_y.predict(data_pos[features])\n",
    "\n",
    "    ## Compute counterfactual outcome with treatment\n",
    "    data_neg = data.copy()\n",
    "    data_neg[treatment] = 0\n",
    "    data['cf0'] = model_y.predict(data_neg[features])\n",
    "\n",
    "    ## Compute incremental score\n",
    "    data['q1'] = (delta * data['p1']) / (delta * data['p1'] + data['p0'])\n",
    "    data['q0'] = 1 - data['q1']\n",
    "\n",
    "    #data['ips_weight'] = (data[treatment] / data['p1'] + \n",
    "                          #(1 - data[treatment]) / (1 - data['p1']))\n",
    "    \n",
    "    data['ips_weight'] = np.where((data['p0'] >= data['p1']), 1 / data['p0'], 1 / data['p1'])\n",
    "    \n",
    "\n",
    "    data['w0'] = data['ips_weight']*data[treatment]\n",
    "    data['w1'] = data['ips_weight']*(1 - data[treatment])\n",
    "\n",
    "    data['a0'] = data['q0']*data['w0']*(data['cf0'] - data[outcome])\n",
    "    data['a1'] = data['q1']*data['w1']*(data['cf1'] - data[outcome])\n",
    "\n",
    "    influence = data['a1'] - data['a0']\n",
    "    return influence\n",
    "\n",
    "def sampling(data, treatment, covariate, outcome, delta_seq, model_t, model_y):\n",
    "    features = covariate.copy()\n",
    "    features.append(treatment)\n",
    "\n",
    "    ## Compute propensity score\n",
    "    data['ps_1'] = model_t.predict_proba(data[covariate])[:,1]\n",
    "    data['ps_0'] = 1 - data['ps_1']\n",
    "\n",
    "    ## Fit outcome\n",
    "    data['predicted_y'] = model_y.predict(data[features])\n",
    "    ## Compute counterfactual outcome with no treatment\n",
    "    data_pos = data.copy()\n",
    "    data_pos[treatment] = 1\n",
    "    data['treated_cf_outcome'] = model_y.predict(data_pos[features])\n",
    "\n",
    "    ## Compute counterfactual outcome with treatment\n",
    "    data_neg = data.copy()\n",
    "    data_neg[treatment] = 0\n",
    "    data['control_cf_outcome'] = model_y.predict(data_neg[features])\n",
    "\n",
    "    effect = []\n",
    "    for delta in tqdm(delta_seq):\n",
    "        influence = influence_function(data, treatment, covariate, outcome, delta, model_y, model_t)\n",
    "        effect.append(influence)\n",
    "\n",
    "    return np.mean(effect, axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 38.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True effect 4.05634575318767\n",
      "Causal effect 1.7337842019142153\n",
      "Data 1, MAE 2.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "index_ = 1\n",
    "for index_ in range(1,2):\n",
    "    data = load_data(PATH_TRAIN, index_)\n",
    "    data_test = load_data(PATH_TEST, index_)\n",
    "\n",
    "    ## Fit treatment\n",
    "    model_t = LogisticRegression()\n",
    "    model_t.fit(data[cov], data[treatment])\n",
    "\n",
    "    ## Fit outcome\n",
    "    model_y = GradientBoostingRegressor(random_state=0, n_estimators = 5000)\n",
    "    model_y.fit(data[features], data[outcome])\n",
    "\n",
    "    num_of_delta = 5\n",
    "    delta_seq = np.linspace(0.5, 2, num_of_delta)\n",
    "\n",
    "    influence = sampling(data_test, treatment, cov, outcome, delta_seq, model_t, model_y)\n",
    "    means_incre, stds_incre = np.mean(influence, axis=0), sem(influence, axis=0)\n",
    "\n",
    "    true_effect = data_test['mu1'] - data_test['mu0']\n",
    "    means, stds = np.mean(true_effect, axis=0), sem(true_effect, axis=0)\n",
    "\n",
    "    print(\"True effect {}\".format(means))\n",
    "    print(\"Causal effect {}\".format(means_incre))\n",
    "\n",
    "    mae = abs(means - means_incre)\n",
    "    print(\"Data {}, MAE {}\".format(index_, round(mae,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.8229166666666666\n",
      "Causal effect not sampling 1.781767281996\n",
      "True effect 4.05634575318767\n",
      "Causal effect 1.781767281996\n",
      "Data 1, MAE 2.27\n"
     ]
    }
   ],
   "source": [
    "index_ = 1\n",
    "data = load_data(PATH_TRAIN, index_)\n",
    "data_test = load_data(PATH_TEST, index_)\n",
    "\n",
    "## Fit treatment\n",
    "model_t = LogisticRegression()\n",
    "model_t.fit(data[cov], data[treatment])\n",
    "\n",
    "print(\"Accuracy \", accuracy_score(model_t.predict(data[cov]), data[treatment]))\n",
    "\n",
    "\n",
    "## Fit outcome\n",
    "model_y = GradientBoostingRegressor(random_state=0, n_estimators = 5000)\n",
    "model_y.fit(data[features], data[outcome])\n",
    "\n",
    "# num_of_delta = 5\n",
    "# delta_seq = np.linspace(0.5, 0.9, num_of_delta)\n",
    "delta = 1.3562963\n",
    "\n",
    "\n",
    "influence = influence_function(data_test, treatment, cov, outcome, delta, model_y, model_t)\n",
    "means_incre, stds_incre = np.mean(influence, axis=0), sem(influence, axis=0)\n",
    "print(\"Causal effect not sampling {}\".format(means_incre))\n",
    "\n",
    "# influence = sampling(data_test, treatment, cov, outcome, delta_seq, model_t, model_y)\n",
    "# means_incre, stds_incre = np.mean(influence, axis=0), sem(influence, axis=0)\n",
    "\n",
    "# true_effect = data_test['mu1'] - data_test['mu0']\n",
    "# means, stds = np.mean(true_effect, axis=0), sem(true_effect, axis=0)\n",
    "\n",
    "print(\"True effect {}\".format(means))\n",
    "print(\"Causal effect {}\".format(means_incre))\n",
    "\n",
    "mae = abs(means - means_incre)\n",
    "print(\"Data {}, MAE {}\".format(index_, round(mae,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cf0</th>\n",
       "      <th>cf1</th>\n",
       "      <th>yf</th>\n",
       "      <th>ycf</th>\n",
       "      <th>t</th>\n",
       "      <th>p0</th>\n",
       "      <th>p1</th>\n",
       "      <th>ips_weight</th>\n",
       "      <th>w0</th>\n",
       "      <th>w1</th>\n",
       "      <th>a0</th>\n",
       "      <th>a1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.607898</td>\n",
       "      <td>6.128073</td>\n",
       "      <td>6.270642</td>\n",
       "      <td>6.849375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.925812</td>\n",
       "      <td>0.074188</td>\n",
       "      <td>1.080132</td>\n",
       "      <td>1.080132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.594173</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.870664</td>\n",
       "      <td>5.447727</td>\n",
       "      <td>-0.939083</td>\n",
       "      <td>5.608847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.884633</td>\n",
       "      <td>0.115367</td>\n",
       "      <td>1.130412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.130412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.085080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.701192</td>\n",
       "      <td>5.686691</td>\n",
       "      <td>1.989663</td>\n",
       "      <td>7.470624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.966231</td>\n",
       "      <td>0.033769</td>\n",
       "      <td>1.034949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.034949</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.173160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.221263</td>\n",
       "      <td>4.871234</td>\n",
       "      <td>6.417115</td>\n",
       "      <td>1.820103</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.816702</td>\n",
       "      <td>0.183298</td>\n",
       "      <td>1.224437</td>\n",
       "      <td>1.224437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.877321</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.592381</td>\n",
       "      <td>5.142579</td>\n",
       "      <td>3.533512</td>\n",
       "      <td>8.331172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.933051</td>\n",
       "      <td>0.066949</td>\n",
       "      <td>1.071752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.071752</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.152942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2.105555</td>\n",
       "      <td>6.666692</td>\n",
       "      <td>2.573101</td>\n",
       "      <td>6.320008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.934885</td>\n",
       "      <td>0.065115</td>\n",
       "      <td>1.069650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.069650</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.377939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1.627220</td>\n",
       "      <td>6.109582</td>\n",
       "      <td>4.974808</td>\n",
       "      <td>1.495454</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.784197</td>\n",
       "      <td>0.215803</td>\n",
       "      <td>1.275189</td>\n",
       "      <td>1.275189</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.108571</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2.606587</td>\n",
       "      <td>7.283729</td>\n",
       "      <td>1.235665</td>\n",
       "      <td>8.094804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.845052</td>\n",
       "      <td>0.154948</td>\n",
       "      <td>1.183359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.183359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.425399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2.797437</td>\n",
       "      <td>6.317274</td>\n",
       "      <td>2.632686</td>\n",
       "      <td>7.226212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.747791</td>\n",
       "      <td>0.252209</td>\n",
       "      <td>1.337273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.337273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.546513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1.361316</td>\n",
       "      <td>6.035494</td>\n",
       "      <td>7.417733</td>\n",
       "      <td>3.308214</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.707264</td>\n",
       "      <td>0.292736</td>\n",
       "      <td>1.413900</td>\n",
       "      <td>1.413900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.484390</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cf0       cf1        yf       ycf    t        p0        p1  \\\n",
       "0   3.607898  6.128073  6.270642  6.849375  1.0  0.925812  0.074188   \n",
       "1   1.870664  5.447727 -0.939083  5.608847  0.0  0.884633  0.115367   \n",
       "2   1.701192  5.686691  1.989663  7.470624  0.0  0.966231  0.033769   \n",
       "3   1.221263  4.871234  6.417115  1.820103  1.0  0.816702  0.183298   \n",
       "4   0.592381  5.142579  3.533512  8.331172  0.0  0.933051  0.066949   \n",
       "..       ...       ...       ...       ...  ...       ...       ...   \n",
       "70  2.105555  6.666692  2.573101  6.320008  0.0  0.934885  0.065115   \n",
       "71  1.627220  6.109582  4.974808  1.495454  1.0  0.784197  0.215803   \n",
       "72  2.606587  7.283729  1.235665  8.094804  0.0  0.845052  0.154948   \n",
       "73  2.797437  6.317274  2.632686  7.226212  0.0  0.747791  0.252209   \n",
       "74  1.361316  6.035494  7.417733  3.308214  1.0  0.707264  0.292736   \n",
       "\n",
       "    ips_weight        w0        w1        a0        a1  \n",
       "0     1.080132  1.080132  0.000000 -2.594173 -0.000000  \n",
       "1     1.130412  0.000000  1.130412  0.000000  1.085080  \n",
       "2     1.034949  0.000000  1.034949 -0.000000  0.173160  \n",
       "3     1.224437  1.224437  0.000000 -4.877321 -0.000000  \n",
       "4     1.071752  0.000000  1.071752 -0.000000  0.152942  \n",
       "..         ...       ...       ...       ...       ...  \n",
       "70    1.069650  0.000000  1.069650 -0.000000  0.377939  \n",
       "71    1.275189  1.275189  0.000000 -3.108571  0.000000  \n",
       "72    1.183359  0.000000  1.183359  0.000000  1.425399  \n",
       "73    1.337273  0.000000  1.337273  0.000000  1.546513  \n",
       "74    1.413900  1.413900  0.000000 -5.484390 -0.000000  \n",
       "\n",
       "[75 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test[['cf0', 'cf1', 'yf', 'ycf', 't', 'p0', 'p1', 'ips_weight', 'w0', 'w1', 'a0', 'a1']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-phd_env] *",
   "language": "python",
   "name": "conda-env-.conda-phd_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
