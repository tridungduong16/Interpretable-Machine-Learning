{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trduong/anaconda3/envs/phd_env/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/trduong/anaconda3/envs/phd_env/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "MAIN_PATH = \"/home/trduong/Data/interpretable_machine_learning/Source Code/my_work\"\n",
    "\n",
    "\n",
    "sys.path.insert(\n",
    "    1,\n",
    "    MAIN_PATH + '/lib'\n",
    ")\n",
    "\n",
    "sys.path.insert(\n",
    "    1,\n",
    "    MAIN_PATH + '/config'\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import dowhy.datasets\n",
    "import dowhy\n",
    "import incremental_ps_score_estimator as ipse\n",
    "import experiment_config as cf\n",
    "import math\n",
    "import timeit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import utils \n",
    "import experiment_config as cf\n",
    "\n",
    "from tempfile import TemporaryFile\n",
    "\n",
    "# save numpy array as npy file\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "\n",
    "from dowhy import CausalModel\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import sem\n",
    "from dowhy import CausalModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from econml.dml import LinearDMLCateEstimator\n",
    "from sklearn.linear_model import LassoCV\n",
    "from econml.inference import BootstrapInference\n",
    "from econml.dml import SparseLinearDMLCateEstimator\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "import logging\n",
    "import pygad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment = 't'\n",
    "outcome = 'yf'\n",
    "col =  [\"t\", \"yf\", \"ycf\", \"mu0\", \"mu1\" ]\n",
    "cov = [\"x\" + str(i) for i in range(1,26)]\n",
    "col = col + cov\n",
    "features = cov + [\"t\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization with Adam and original function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incre_ps(delta, data):\n",
    "    q1 = (delta * data['p1']) / (delta * data['p1'] + data['p0'])\n",
    "    q1 = tf.math.abs(q1)\n",
    "    a0 = (1-q1)*data['w0']*(data['cf0'] - data[outcome])\n",
    "    a1 = q1*data['w1']*(data['cf1'] - data[outcome])    \n",
    "    influence = a1 - a0\n",
    "    return tf.reduce_mean(influence)\n",
    "\n",
    "def optimization(data):\n",
    "    threhold = tf.constant([0.001])\n",
    "    delta = tf.Variable(100., trainable = True)\n",
    "    true_effect = np.mean(data['mu1'] - data['mu0'])\n",
    "    \n",
    "    for i in range(150000):\n",
    "        with tf.GradientTape() as tape:\n",
    "            influence = incre_ps(delta, data)\n",
    "            loss = tf.math.abs(true_effect - influence)\n",
    "            d_delta = tape.gradient(loss, delta)\n",
    "            opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "            opt.apply_gradients(zip([d_delta], [delta]))\n",
    "            ## early stopping\n",
    "            if tf.math.less(loss, threhold):\n",
    "                print(\"The performance reach MAE: 0.001. Cancelling the training at step {}\".format(i))\n",
    "                break\n",
    "    return delta, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize in train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 1. Delta 248.12\n",
      "MAE on traning 0.10\n",
      "MAE on testing 0.06\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 2. Delta 247.95\n",
      "MAE on traning 0.16\n",
      "MAE on testing 0.07\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 3. Delta 248.33\n",
      "MAE on traning 0.14\n",
      "MAE on testing 0.33\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 4. Delta 247.95\n",
      "MAE on traning 0.14\n",
      "MAE on testing 0.05\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 5. Delta 247.20\n",
      "MAE on traning 0.01\n",
      "MAE on testing 0.21\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "The performance reach MAE: 0.001. Cancelling the training at step 37578\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 6. Delta 62.63\n",
      "MAE on traning 0.00\n",
      "MAE on testing 0.04\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 7. Delta 247.64\n",
      "MAE on traning 0.26\n",
      "MAE on testing 0.22\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "The performance reach MAE: 0.001. Cancelling the training at step 75243\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 8. Delta 25.10\n",
      "MAE on traning 0.00\n",
      "MAE on testing 0.11\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "The performance reach MAE: 0.001. Cancelling the training at step 58338\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 9. Delta 158.08\n",
      "MAE on traning 0.00\n",
      "MAE on testing 2.37\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "The performance reach MAE: 0.001. Cancelling the training at step 72560\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 10. Delta 27.48\n",
      "MAE on traning 0.00\n",
      "MAE on testing 0.77\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "The performance reach MAE: 0.001. Cancelling the training at step 12704\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 11. Delta 112.60\n",
      "MAE on traning 0.00\n",
      "MAE on testing 0.36\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "The performance reach MAE: 0.001. Cancelling the training at step 32612\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 12. Delta 132.35\n",
      "MAE on traning 0.00\n",
      "MAE on testing 0.15\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "The performance reach MAE: 0.001. Cancelling the training at step 95029\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 13. Delta 5.01\n",
      "MAE on traning 0.00\n",
      "MAE on testing 2.90\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 14. Delta 248.15\n",
      "MAE on traning 0.05\n",
      "MAE on testing 0.12\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "The performance reach MAE: 0.001. Cancelling the training at step 51332\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 15. Delta 48.88\n",
      "MAE on traning 0.00\n",
      "MAE on testing 0.21\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 16. Delta 248.19\n",
      "MAE on traning 0.10\n",
      "MAE on testing 0.33\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "The performance reach MAE: 0.001. Cancelling the training at step 74495\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 17. Delta 25.54\n",
      "MAE on traning 0.00\n",
      "MAE on testing 0.12\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 18. Delta 246.41\n",
      "MAE on traning 0.19\n",
      "MAE on testing 0.12\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 19. Delta 248.18\n",
      "MAE on traning 0.11\n",
      "MAE on testing 0.48\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 20. Delta 248.28\n",
      "MAE on traning 0.16\n",
      "MAE on testing 0.26\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "The performance reach MAE: 0.001. Cancelling the training at step 85114\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 21. Delta 14.93\n",
      "MAE on traning 0.00\n",
      "MAE on testing 1.73\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 22. Delta 248.12\n",
      "MAE on traning 0.10\n",
      "MAE on testing 0.21\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "The performance reach MAE: 0.001. Cancelling the training at step 36796\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 23. Delta 63.22\n",
      "MAE on traning 0.00\n",
      "MAE on testing 0.24\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "The performance reach MAE: 0.001. Cancelling the training at step 32563\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 24. Delta 132.41\n",
      "MAE on traning 0.00\n",
      "MAE on testing 0.68\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 25. Delta 248.40\n",
      "MAE on traning 0.05\n",
      "MAE on testing 0.05\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 26. Delta 1.68\n",
      "MAE on traning 0.19\n",
      "MAE on testing 1.17\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "The performance reach MAE: 0.001. Cancelling the training at step 91062\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 27. Delta 9.15\n",
      "MAE on traning 0.00\n",
      "MAE on testing 0.50\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "The performance reach MAE: 0.001. Cancelling the training at step 92883\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 28. Delta 7.16\n",
      "MAE on traning 0.00\n",
      "MAE on testing 3.14\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "The performance reach MAE: 0.001. Cancelling the training at step 48204\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 29. Delta 51.82\n",
      "MAE on traning 0.00\n",
      "MAE on testing 0.27\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 30. Delta 248.99\n",
      "MAE on traning 0.05\n",
      "MAE on testing 0.01\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 31. Delta 248.61\n",
      "MAE on traning 0.01\n",
      "MAE on testing 0.05\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 32. Delta 247.73\n",
      "MAE on traning 0.05\n",
      "MAE on testing 0.16\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "The performance reach MAE: 0.001. Cancelling the training at step 61296\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 33. Delta 38.75\n",
      "MAE on traning 0.00\n",
      "MAE on testing 0.72\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "The performance reach MAE: 0.001. Cancelling the training at step 99497\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 34. Delta 0.55\n",
      "MAE on traning 0.00\n",
      "MAE on testing 7.64\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 35. Delta 245.21\n",
      "MAE on traning 0.10\n",
      "MAE on testing 0.05\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "The performance reach MAE: 0.001. Cancelling the training at step 55681\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 36. Delta 44.35\n",
      "MAE on traning 0.00\n",
      "MAE on testing 0.16\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "The performance reach MAE: 0.001. Cancelling the training at step 16273\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 37. Delta 83.73\n",
      "MAE on traning 0.00\n",
      "MAE on testing 0.43\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "The performance reach MAE: 0.001. Cancelling the training at step 62886\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 38. Delta 37.17\n",
      "MAE on traning 0.00\n",
      "MAE on testing 0.08\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "The performance reach MAE: 0.001. Cancelling the training at step 69156\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 39. Delta 168.81\n",
      "MAE on traning 0.00\n",
      "MAE on testing 0.61\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 40. Delta 248.99\n",
      "MAE on traning 0.01\n",
      "MAE on testing 0.07\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 41. Delta 248.74\n",
      "MAE on traning 0.01\n",
      "MAE on testing 0.10\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "The performance reach MAE: 0.001. Cancelling the training at step 53349\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 42. Delta 46.68\n",
      "MAE on traning 0.00\n",
      "MAE on testing 0.48\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "The performance reach MAE: 0.001. Cancelling the training at step 50858\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 43. Delta 150.66\n",
      "MAE on traning 0.00\n",
      "MAE on testing 0.21\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "The performance reach MAE: 0.001. Cancelling the training at step 91271\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 44. Delta 9.08\n",
      "MAE on traning 0.00\n",
      "MAE on testing 0.32\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "The performance reach MAE: 0.001. Cancelling the training at step 97620\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 45. Delta 2.52\n",
      "MAE on traning 0.00\n",
      "MAE on testing 1.77\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "The performance reach MAE: 0.001. Cancelling the training at step 45589\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 46. Delta 145.43\n",
      "MAE on traning 0.00\n",
      "MAE on testing 0.30\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "The performance reach MAE: 0.001. Cancelling the training at step 8574\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 47. Delta 108.57\n",
      "MAE on traning 0.00\n",
      "MAE on testing 0.13\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 48. Delta 248.81\n",
      "MAE on traning 0.02\n",
      "MAE on testing 0.41\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "The performance reach MAE: 0.001. Cancelling the training at step 138393\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 49. Delta 237.48\n",
      "MAE on traning 0.00\n",
      "MAE on testing 0.23\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 50. Delta 246.03\n",
      "MAE on traning 0.07\n",
      "MAE on testing 0.22\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "The performance reach MAE: 0.001. Cancelling the training at step 9045\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 51. Delta 90.96\n",
      "MAE on traning 0.00\n",
      "MAE on testing 0.19\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n"
     ]
    }
   ],
   "source": [
    "delta_seq = []\n",
    "losses = []\n",
    "losses_test = []\n",
    "for index_ in (range(1, 101)):\n",
    "    data = utils.load_data(cf.IHDP_TRAIN, index_)\n",
    "    data_test = utils.load_data(cf.IHDP_TEST, index_)\n",
    "    data_whole = pd.concat([data, data_test], sort=False)\n",
    "    #data, data_test = train_test_split(data_whole, test_size=0.1)\n",
    "    data = data.reset_index()\n",
    "    data_test = data_test.reset_index()\n",
    "    #oversample = SMOTE()\n",
    "    #X_train_oversampled, y_train_oversampled = oversample.fit_sample(data_whole[cov].values, data_whole[treatment].values)\n",
    "\n",
    "    ## Fit treatment\n",
    "    print(\"Fit treament\")\n",
    "\n",
    "    model_t = LogisticRegression()\n",
    "    model_t.fit(data_whole[cov], data_whole[treatment])\n",
    "\n",
    "    ## Fit outcome\n",
    "    print(\"Fit outcome\")\n",
    "\n",
    "    model_y = GradientBoostingRegressor(random_state=0, n_estimators=2000)\n",
    "    model_y.fit(data_whole[features], data_whole[outcome])\n",
    "\n",
    "    data['p1'] = model_t.predict_proba(data[cov])[:, 1]\n",
    "    data['p0'] = 1 - data['p1']\n",
    "\n",
    "    ## Compute counterfactual outcome with no treatment\n",
    "    print(\"Compute counterfactual outcome\")\n",
    "\n",
    "    data_pos = data.copy()\n",
    "    data_pos[treatment] = 1\n",
    "    data['cf1'] = model_y.predict(data_pos[features])\n",
    "\n",
    "    ## Compute counterfactual outcome with treatment\n",
    "    data_neg = data.copy()\n",
    "    data_neg[treatment] = 0\n",
    "    data['cf0'] = model_y.predict(data_neg[features])\n",
    "\n",
    "    data['ips_weight'] = (data[treatment] / data['p1'] +\n",
    "                          (1 - data[treatment]) / (1 - data['p1']))\n",
    "\n",
    "    data['w0'] = data['ips_weight'] * data[treatment]\n",
    "    data['w1'] = data['ips_weight'] * (1 - data[treatment])\n",
    "\n",
    "    print(\"Optimization\")\n",
    "\n",
    "    delta, loss = optimization(data)\n",
    "    delta_r = delta.numpy()\n",
    "    delta_seq.append(delta_r)\n",
    "    losses.append(loss.numpy())\n",
    "\n",
    "    influence = ipse.influence_function(data_test, treatment, cov, outcome,\n",
    "                                        features, delta_r, model_y, model_t)\n",
    "    means_incre_test, stds_incre = np.mean(influence, axis=0), sem(influence,\n",
    "                                                                   axis=0)\n",
    "    \n",
    "    print(\"Calculate ATE in the testing set\")\n",
    "    true_effect = data['mu1'] - data['mu0']\n",
    "    means_train, stds = np.mean(true_effect, axis=0), sem(true_effect, axis=0)\n",
    "\n",
    "    true_effect = data_test['mu1'] - data_test['mu0']\n",
    "    means_test, stds = np.mean(true_effect, axis=0), sem(true_effect, axis=0)\n",
    "\n",
    "    mae_test = utils.abs_ate(means_test, means_incre_test)\n",
    "    losses_test.append(mae_test)\n",
    "    print(\"\\n\")\n",
    "    print(\"Data index {}. Delta {:.2f}\".format(index_, delta_r))\n",
    "    print(\"MAE on traning {:.2f}\".format(loss.numpy()))\n",
    "    print(\"MAE on testing {:.2f}\".format(mae_test))\n",
    "    print(\"*\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE Training {:.4f}\".format(np.mean(losses)))\n",
    "print(\"MAE Testing {:.4f}\".format(np.mean(losses_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE Training 0.1605\n",
    "# MAE Testing 0.5021\n",
    "\n",
    "### optimize train-test together\n",
    "# MAE Training 0.0933\n",
    "# MAE Testing 0.6035\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = asarray(delta_seq)\n",
    "save('delta_.npy', delta_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRAIN = \"/home/dtd/Documents/data/idhp/ihdp_npci_1-100.train.npz\"\n",
    "PATH_TEST = \"/home/dtd/Documents/data/idhp/ihdp_npci_1-100.test.npz\"\n",
    "\n",
    "delta_seq = []\n",
    "losses = []\n",
    "losses_test = []\n",
    "for index_ in tqdm(range(1, 101)): \n",
    "    data = utils.load_data(PATH_TRAIN, index_)\n",
    "    data_test = utils.load_data(PATH_TEST, index_)\n",
    "    data_whole = pd.concat([data, data_test], sort=False)\n",
    "    \n",
    "    #oversample = SMOTE()\n",
    "    #X_train_oversampled, y_train_oversampled = oversample.fit_sample(data_whole[cov].values, data_whole[treatment].values)\n",
    "    \n",
    "    ## Fit treatment\n",
    "    model_t = LogisticRegression()\n",
    "    #model_t.fit(X_train_oversampled, y_train_oversampled)\n",
    "\n",
    "    ## Fit outcome\n",
    "    model_y = GradientBoostingRegressor(random_state=0, n_estimators = 500)\n",
    "    model_y.fit(data_whole[features], data_whole[outcome])\n",
    "\n",
    "    data['p1'] = model_t.predict_proba(data[cov])[:,1]\n",
    "    data['p0'] = 1 - data['p1']\n",
    "\n",
    "    ## Compute counterfactual outcome with no treatment\n",
    "    data_pos = data.copy()\n",
    "    data_pos[treatment] = 1\n",
    "    data['cf1'] = model_y.predict(data_pos[features])\n",
    "\n",
    "    ## Compute counterfactual outcome with treatment\n",
    "    data_neg = data.copy()\n",
    "    data_neg[treatment] = 0\n",
    "    data['cf0'] = model_y.predict(data_neg[features])\n",
    "\n",
    "    data['ips_weight'] = (data[treatment] / data['p1'] + (1 - data[treatment]) /\n",
    "                          (1 - data['p1']))\n",
    "    \n",
    "    data['w0'] = data['ips_weight']*data[treatment]\n",
    "    data['w1'] = data['ips_weight']*(1 - data[treatment])\n",
    "    \n",
    "    delta, loss = optimization(data)\n",
    "    delta_r = delta.numpy()\n",
    "    delta_seq.append(delta_r)\n",
    "    losses.append(loss.numpy())\n",
    "    \n",
    "    \n",
    "    influence = ipse.influence_function(data_test, treatment, cov, outcome, features, delta_r, model_y, model_t)\n",
    "    means_incre_test, stds_incre = np.mean(influence, axis=0), sem(influence, axis=0)\n",
    "\n",
    "    true_effect = data['mu1'] - data['mu0']\n",
    "    means_train, stds = np.mean(true_effect, axis=0), sem(true_effect, axis=0)\n",
    "    \n",
    "    true_effect = data_test['mu1'] - data_test['mu0']\n",
    "    means_test, stds = np.mean(true_effect, axis=0), sem(true_effect, axis=0)\n",
    "\n",
    "    mae_test = utils.abs_ate(means_test, means_incre_test)\n",
    "    losses_test.append(mae_test)\n",
    "    print(\"\\n\")\n",
    "    print(\"Data index {}. Delta {:.2f}\".format(index_, delta_r))\n",
    "    print(\"MAE on traning {:.2f}\".format(loss.numpy()))\n",
    "    print(\"MAE on testing {:.2f}\".format(mae_test))\n",
    "    print(\"*\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization with list of delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incre_ps(delta, data):\n",
    "    q1 = (delta * data['p1']) / (delta * data['p1'] + data['p0'])\n",
    "    q1 = tf.math.abs(q1)\n",
    "    a0 = (1-q1)*data['w0']*(data['cf0'] - data[outcome])\n",
    "    a1 = q1*data['w1']*(data['cf1'] - data[outcome])    \n",
    "    influence = a1 - a0\n",
    "    return tf.reduce_mean(influence)\n",
    "\n",
    "def optimization(data, variation):\n",
    "    threhold = tf.constant([0.001])\n",
    "    '''\n",
    "    delta = tf.Variable(\n",
    "        tf.random.uniform([data.shape[0],], \n",
    "                          minval=1, \n",
    "                          maxval=100, \n",
    "                          dtype=tf.dtypes.float32), \n",
    "                          trainable = True)\n",
    "    '''\n",
    "    delta = tf.Variable(tf.random.normal(\n",
    "        [data.shape[0],], \n",
    "        mean=0.0, \n",
    "        stddev=variation, \n",
    "        dtype=tf.dtypes.float32, \n",
    "        seed=1, \n",
    "        name='delta'\n",
    "    ), trainable = True)\n",
    "    \n",
    "    true_effect = np.mean(data['mu1'] - data['mu0'])\n",
    "    \n",
    "    for i in range(30000):\n",
    "        with tf.GradientTape() as tape:\n",
    "            influence = incre_ps(delta, data)\n",
    "            loss = tf.math.abs(true_effect - influence)\n",
    "            d_delta = tape.gradient(loss, delta)\n",
    "            opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "            opt.apply_gradients(zip([d_delta], [delta]))\n",
    "            ## early stopping\n",
    "            if tf.math.less(loss, threhold):\n",
    "                print(\"The performance reach MAE: 0.001. Cancelling the training at step {}\".format(i))\n",
    "                break\n",
    "    return delta, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize in train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variaton  1\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 1. Loss training 0.04 and testing 0.34\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 2. Loss training 0.01 and testing 0.28\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 3. Loss training 0.02 and testing 0.71\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 4. Loss training 0.03 and testing 0.31\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 5. Loss training 0.00 and testing 0.00\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 6. Loss training 0.01 and testing 0.81\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 7. Loss training 0.04 and testing 62.15\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 8. Loss training 0.01 and testing 1.52\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 9. Loss training 0.21 and testing 68.92\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 10. Loss training 0.00 and testing 1.80\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "The performance reach MAE: 0.001. Cancelling the training at step 39\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 11. Loss training 0.00 and testing 1.44\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 12. Loss training 0.02 and testing 2974.25\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 13. Loss training 0.00 and testing 5.94\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n"
     ]
    }
   ],
   "source": [
    "delta_seq = []\n",
    "losses = []\n",
    "losses_test = []\n",
    "\n",
    "seq_result = pd.DataFrame()\n",
    "seq_result['train'] = 0\n",
    "seq_result['test'] = 0\n",
    "\n",
    "for count in range(1,100):\n",
    "    #variation = np.random.randint(low=1, high=100, size=1)\n",
    "    print(\"Variaton \", count)\n",
    "    for index_ in range(1, 101): \n",
    "        data = utils.load_data(cf.IHDP_TRAIN, index_)\n",
    "        data_test = utils.load_data(cf.IHDP_TEST, index_)\n",
    "        data_whole = pd.concat([data, data_test], sort=False)\n",
    "        ## Fit treatment\n",
    "        print(\"Fit treament\")\n",
    "        model_t = LogisticRegression()\n",
    "        model_t.fit(data_whole[cov], data_whole[treatment])\n",
    "\n",
    "        ## Fit outcome\n",
    "        print(\"Fit outcome\")\n",
    "        model_y = GradientBoostingRegressor(random_state=0, n_estimators = 1000)\n",
    "        model_y.fit(data_whole[features], data_whole[outcome])\n",
    "\n",
    "        data['p1'] = model_t.predict_proba(data[cov])[:,1]\n",
    "        data_test['p1'] = model_t.predict_proba(data_test[cov])[:,1]\n",
    "\n",
    "        data['p0'] = 1 - data['p1']\n",
    "\n",
    "        ## Compute counterfactual outcome with no treatment\n",
    "        print(\"Compute counterfactual outcome\")\n",
    "        data_pos = data.copy()\n",
    "        data_pos[treatment] = 1\n",
    "        data['cf1'] = model_y.predict(data_pos[features])\n",
    "\n",
    "        ## Compute counterfactual outcome with treatment\n",
    "        data_neg = data.copy()\n",
    "        data_neg[treatment] = 0\n",
    "        data['cf0'] = model_y.predict(data_neg[features])\n",
    "\n",
    "        data['ips_weight'] = (data[treatment] / data['p1'] + (1 - data[treatment]) /\n",
    "                              (1 - data['p1']))\n",
    "\n",
    "        data['w0'] = data['ips_weight']*data[treatment]\n",
    "        data['w1'] = data['ips_weight']*(1 - data[treatment])\n",
    "        \n",
    "        print(\"Optimization\")\n",
    "        delta, loss = optimization(data, count)\n",
    "        delta_r = delta.numpy()\n",
    "        delta_seq.append(delta_r)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        treated_neighbors = (\n",
    "                NearestNeighbors(n_neighbors=1, algorithm='ball_tree')\n",
    "                .fit(data['p1'].values.reshape(-1, 1))\n",
    "        )\n",
    "        distances, indices = treated_neighbors.kneighbors(data_test['p1'].values.reshape(-1, 1))\n",
    "\n",
    "        delta_test = delta_r[indices.reshape(-1)]\n",
    "        \n",
    "        print(\"Calculate ATE in the testing set\")\n",
    "    \n",
    "        influence = ipse.influence_function(data_test, \n",
    "                                            treatment, \n",
    "                                            cov, \n",
    "                                            outcome, \n",
    "                                            features,\n",
    "                                            delta_test, \n",
    "                                            model_y, \n",
    "                                            model_t)\n",
    "\n",
    "        means_incre_test, stds_incre = np.mean(influence, axis=0), sem(influence, axis=0)\n",
    "\n",
    "        ## True effect   \n",
    "        \n",
    "        true_effect = data_test['mu1'] - data_test['mu0']\n",
    "        means_test, stds = np.mean(true_effect, axis=0), sem(true_effect, axis=0)\n",
    "        \n",
    "        print(\"Calculate mean absolute error\")\n",
    "        mae_test = utils.abs_ate(means_test, means_incre_test)\n",
    "        losses_test.append(mae_test)\n",
    "\n",
    "        print(\"Data index {}. Loss training {:.2f} and testing {:.2f}\".format(index_, loss.numpy(), mae_test))\n",
    "\n",
    "        seq_result.loc[index_ - 1, 'train'] = loss.numpy()\n",
    "        seq_result.loc[index_ - 1, 'test'] = mae_test\n",
    "        print(\"*\"*100)\n",
    "    print(\"Export to csv\")\n",
    "    print(\"-\"*100)\n",
    "    \n",
    "    save(cf.RESULT_PATH + \"/\" + \"list_delta_\" + str(index_) + \".npy\", delta_seq)\n",
    "    seq_result.to_csv(cf.RESULT_PATH + \"/\" + str(count) + \"_ps_con.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Optimization for individual treatment effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incre_ps(delta, data):\n",
    "    q1 = (delta * data['p1']) / (delta * data['p1'] + data['p0'])\n",
    "    q1 = tf.math.abs(q1)\n",
    "    a0 = (1-q1)*data['w0']*(data['cf0'] - data[outcome])\n",
    "    a1 = q1*data['w1']*(data['cf1'] - data[outcome])    \n",
    "    influence = a1 - a0\n",
    "    return influence\n",
    "\n",
    "def optimization(data):\n",
    "    threhold = tf.constant([0.01])\n",
    "    '''\n",
    "    delta = tf.Variable(\n",
    "        tf.random.uniform([data.shape[0],], \n",
    "                          minval=1, \n",
    "                          maxval=100, \n",
    "                          dtype=tf.dtypes.float32), \n",
    "                          trainable = True)\n",
    "    '''\n",
    "    delta = tf.Variable(tf.random.normal(\n",
    "        [data.shape[0],], \n",
    "        mean=0, \n",
    "        stddev=10, \n",
    "        dtype=tf.dtypes.float32, \n",
    "        seed=1, \n",
    "        name='delta'\n",
    "    ), trainable = True)\n",
    "    \n",
    "    true_effect = data['mu1'] - data['mu0']\n",
    "    \n",
    "    for i in range(100000):\n",
    "        with tf.GradientTape() as tape:\n",
    "            influence = incre_ps(delta, data)\n",
    "            loss = tf.keras.losses.MAE(true_effect, influence)\n",
    "            d_delta = tape.gradient(loss, delta)\n",
    "            opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "            opt.apply_gradients(zip([d_delta], [delta]))\n",
    "            if i % 1000 == 0:\n",
    "                print(\"Epoch {}. Loss {:.5f}\".format(i, loss.numpy()))\n",
    "            if tf.math.less(loss, threhold):\n",
    "                print(\"The performance reach MAE: 0.001. Cancelling the training at step {}\".format(i))\n",
    "                break\n",
    "    return delta, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRAIN = \"/home/dtd/Documents/interpretable_machine_learning/Source Code/data/ihdp_npci_1-100.train.npz\"\n",
    "PATH_TEST = \"/home/dtd/Documents/interpretable_machine_learning/Source Code/data/ihdp_npci_1-100.test.npz\"\n",
    "\n",
    "delta_seq = []\n",
    "for index_ in tqdm(range(13, 14)): \n",
    "    data = utils.load_data(PATH_TRAIN, index_)\n",
    "    ## Fit treatment\n",
    "    model_t = LogisticRegression()\n",
    "    model_t.fit(data[cov], data[treatment])\n",
    "\n",
    "    ## Fit outcome\n",
    "    model_y = GradientBoostingRegressor(random_state=0, n_estimators = 5000)\n",
    "    model_y.fit(data[features], data[outcome])\n",
    "\n",
    "    data['p1'] = model_t.predict_proba(data[cov])[:,1]\n",
    "    data['p0'] = 1 - data['p1']\n",
    "\n",
    "    ## Compute counterfactual outcome with no treatment\n",
    "    data_pos = data.copy()\n",
    "    data_pos[treatment] = 1\n",
    "    data['cf1'] = model_y.predict(data_pos[features])\n",
    "\n",
    "    ## Compute counterfactual outcome with treatment\n",
    "    data_neg = data.copy()\n",
    "    data_neg[treatment] = 0\n",
    "    data['cf0'] = model_y.predict(data_neg[features])\n",
    "\n",
    "    data['ips_weight'] = (data[treatment] / data['p1'] + (1 - data[treatment]) /\n",
    "                          (1 - data['p1']))\n",
    "    \n",
    "    data['w0'] = data['ips_weight']*data[treatment]\n",
    "    data['w1'] = data['ips_weight']*(1 - data[treatment])\n",
    "    \n",
    "    delta, loss = optimization(data)\n",
    "    delta_r = delta.numpy()\n",
    "    delta_seq.append(delta_r)\n",
    "    print(\"Data index {}. Loss {:.2f}\".format(index_, loss.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save('individual_list_delta_.npy', delta_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization for individual treatment effects using genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incre_ps(delta, data):\n",
    "    q1 = (delta * data['p1']) / (delta * data['p1'] + data['p0'])\n",
    "    q1 = abs(q1)\n",
    "    a0 = (1-q1)*data['w0']*(data['cf0'] - data[outcome])\n",
    "    a1 = q1*data['w1']*(data['cf1'] - data[outcome])    \n",
    "    influence = a1 - a0\n",
    "    return influence\n",
    "\n",
    "\n",
    "def fitness_function(delta, solution_idx):\n",
    "    influence = incre_ps(delta, data)\n",
    "    mae = -np.sqrt(np.mean((true_effect - influence)**2))\n",
    "    return np.mean(mae)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRAIN = \"/home/dtd/Documents/interpretable_machine_learning/Source Code/data/ihdp_npci_1-100.train.npz\"\n",
    "data = utils.load_data(PATH_TRAIN, 1)\n",
    "\n",
    "## Fit treatment\n",
    "model_t = LogisticRegression()\n",
    "model_t.fit(data[cov], data[treatment])\n",
    "\n",
    "## Fit outcome\n",
    "model_y = GradientBoostingRegressor(random_state=0, n_estimators = 5000)\n",
    "model_y.fit(data[features], data[outcome])\n",
    "\n",
    "data['p1'] = model_t.predict_proba(data[cov])[:,1]\n",
    "data['p0'] = 1 - data['p1']\n",
    "\n",
    "## Compute counterfactual outcome with no treatment\n",
    "data_pos = data.copy()\n",
    "data_pos[treatment] = 1\n",
    "data['cf1'] = model_y.predict(data_pos[features])\n",
    "\n",
    "## Compute counterfactual outcome with treatment\n",
    "data_neg = data.copy()\n",
    "data_neg[treatment] = 0\n",
    "data['cf0'] = model_y.predict(data_neg[features])\n",
    "\n",
    "data['ips_weight'] = (data[treatment] / data['p1'] + (1 - data[treatment]) /\n",
    "                      (1 - data['p1']))\n",
    "\n",
    "data['w0'] = data['ips_weight']*data[treatment]\n",
    "data['w1'] = data['ips_weight']*(1 - data[treatment])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_effect = data['mu1'] - data['mu0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Given the following function:\n",
    "    y = f(w1:w6) = w1x1 + w2x2 + w3x3 + w4x4 + w5x5 + 6wx6\n",
    "    where (x1,x2,x3,x4,x5,x6)=(4,-2,3.5,5,-11,-4.7) and y=44\n",
    "What are the best values for the 6 weights (w1 to w6)? We are going to use the genetic algorithm to optimize this function.\n",
    "\"\"\"\n",
    "\n",
    "#function_inputs = [4,-2,3.5,5,-11,-4.7] # Function inputs.\n",
    "#desired_output = 44 # Function output.\n",
    "\n",
    "function_inputs = np.random.rand(data.shape[0]) # Function inputs.\n",
    "\n",
    "num_generations = 5000 # Number of generations.\n",
    "num_parents_mating = 100 # Number of solutions to be selected as parents in the mating pool.\n",
    "\n",
    "# To prepare the initial population, there are 2 ways:\n",
    "# 1) Prepare it yourself and pass it to the initial_population parameter. This way is useful when the user wants to start the genetic algorithm with a custom initial population.\n",
    "# 2) Assign valid integer values to the sol_per_pop and num_genes parameters. If the initial_population parameter exists, then the sol_per_pop and num_genes parameters are useless.\n",
    "sol_per_pop = 2500 # Number of solutions in the population.\n",
    "num_genes = len(function_inputs)\n",
    "\n",
    "init_range_low = -100\n",
    "init_range_high = 100\n",
    "\n",
    "parent_selection_type = \"sss\" # Type of parent selection.\n",
    "keep_parents = -1 # Number of parents to keep in the next population. -1 means keep all parents and 0 means keep nothing.\n",
    "\n",
    "crossover_type = \"single_point\" # Type of the crossover operator.\n",
    "\n",
    "# Parameters of the mutation operation.\n",
    "mutation_type = \"random\" # Type of the mutation operator.\n",
    "mutation_percent_genes = 10 # Percentage of genes to mutate. This parameter has no action if the parameter mutation_num_genes exists or when mutation_type is None.\n",
    "\n",
    "last_fitness = 0\n",
    "def callback_generation(ga_instance):\n",
    "    global last_fitness\n",
    "    print(\"Generation = {generation}\".format(generation=ga_instance.generations_completed))\n",
    "    print(\"Fitness    = {fitness}\".format(fitness=ga_instance.best_solution()[1]))\n",
    "    print(\"Change     = {change}\".format(change=ga_instance.best_solution()[1] - last_fitness))\n",
    "    print(\"\\n\")\n",
    "    last_fitness = ga_instance.best_solution()[1]\n",
    "\n",
    "# Creating an instance of the GA class inside the ga module. Some parameters are initialized within the constructor.\n",
    "ga_instance = pygad.GA(num_generations=num_generations,\n",
    "                       num_parents_mating=num_parents_mating, \n",
    "                       fitness_func=fitness_function,\n",
    "                       sol_per_pop=sol_per_pop, \n",
    "                       num_genes=num_genes,\n",
    "                       init_range_low=init_range_low,\n",
    "                       init_range_high=init_range_high,\n",
    "                       parent_selection_type=parent_selection_type,\n",
    "                       keep_parents=keep_parents,\n",
    "                       crossover_type=crossover_type,\n",
    "                       mutation_type=mutation_type,\n",
    "                       mutation_percent_genes=mutation_percent_genes,\n",
    "                       callback_generation=callback_generation)\n",
    "\n",
    "# Running the GA to optimize the parameters of the function.\n",
    "ga_instance.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization ATE using genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incre_ps(delta, data):\n",
    "    q1 = (delta * data['p1']) / (delta * data['p1'] + data['p0'])\n",
    "    q1 = abs(q1)\n",
    "    a0 = (1-q1)*data['w0']*(data['cf0'] - data[outcome])\n",
    "    a1 = q1*data['w1']*(data['cf1'] - data[outcome])    \n",
    "    influence = a1 - a0\n",
    "    return influence\n",
    "\n",
    "\n",
    "def fitness_function(delta, solution_idx):\n",
    "    influence = incre_ps(delta, data)\n",
    "    mae = -np.sqrt(np.mean((true_effect - influence)**2))\n",
    "    return np.mean(mae)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_ = 1\n",
    "\n",
    "data = utils.load_data(cf.IHDP_TRAIN, index_)\n",
    "data_test = utils.load_data(cf.IHDP_TEST, index_)\n",
    "data_whole = pd.concat([data, data_test], sort=False)\n",
    "## Fit treatment\n",
    "model_t = LogisticRegression()\n",
    "model_t.fit(data_whole[cov], data_whole[treatment])\n",
    "\n",
    "## Fit outcome\n",
    "model_y = GradientBoostingRegressor(random_state=0, n_estimators = 5000)\n",
    "model_y.fit(data_whole[features], data_whole[outcome])\n",
    "\n",
    "data['p1'] = model_t.predict_proba(data[cov])[:,1]\n",
    "data['p0'] = 1 - data['p1']\n",
    "\n",
    "## Compute counterfactual outcome with no treatment\n",
    "data_pos = data.copy()\n",
    "data_pos[treatment] = 1\n",
    "data['cf1'] = model_y.predict(data_pos[features])\n",
    "\n",
    "## Compute counterfactual outcome with treatment\n",
    "data_neg = data.copy()\n",
    "data_neg[treatment] = 0\n",
    "data['cf0'] = model_y.predict(data_neg[features])\n",
    "\n",
    "data['ips_weight'] = (data[treatment] / data['p1'] + (1 - data[treatment]) /\n",
    "                      (1 - data['p1']))\n",
    "\n",
    "data['w0'] = data['ips_weight']*data[treatment]\n",
    "data['w1'] = data['ips_weight']*(1 - data[treatment])\n",
    "\n",
    "true_effect = data['mu1'] - data['mu0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_inputs = np.random.rand(data.shape[0]) # Function inputs.\n",
    "\n",
    "num_generations = 2000 # Number of generations.\n",
    "num_parents_mating = 100 # Number of solutions to be selected as parents in the mating pool.\n",
    "\n",
    "sol_per_pop = 2500 # Number of solutions in the population.\n",
    "num_genes = len(function_inputs)\n",
    "\n",
    "init_range_low = -100\n",
    "init_range_high = 100\n",
    "\n",
    "parent_selection_type = \"sss\" # Type of parent selection.\n",
    "keep_parents = -1 # Number of parents to keep in the next population. -1 means keep all parents and 0 means keep nothing.\n",
    "\n",
    "crossover_type = \"single_point\" # Type of the crossover operator.\n",
    "\n",
    "mutation_type = \"random\" # Type of the mutation operator.\n",
    "mutation_percent_genes = 10 # Percentage of genes to mutate. This parameter has no action if the parameter mutation_num_genes exists or when mutation_type is None.\n",
    "last_fitness = 0\n",
    "def callback_generation(ga_instance):\n",
    "    global last_fitness\n",
    "    print(\"Generation = {generation}\".format(generation=ga_instance.generations_completed))\n",
    "    print(\"Fitness    = {fitness}\".format(fitness=ga_instance.best_solution()[1]))\n",
    "    print(\"Change     = {change}\".format(change=ga_instance.best_solution()[1] - last_fitness))\n",
    "    print(\"\\n\")\n",
    "    last_fitness = ga_instance.best_solution()[1]\n",
    "    if last_fitness <=  0.001:\n",
    "        break \n",
    "\n",
    "# Creating an instance of the GA class inside the ga module. Some parameters are initialized within the constructor.\n",
    "ga_instance = pygad.GA(num_generations=num_generations,\n",
    "                       num_parents_mating=num_parents_mating, \n",
    "                       fitness_func=fitness_function,\n",
    "                       sol_per_pop=sol_per_pop, \n",
    "                       num_genes=num_genes,\n",
    "                       init_range_low=init_range_low,\n",
    "                       init_range_high=init_range_high,\n",
    "                       parent_selection_type=parent_selection_type,\n",
    "                       keep_parents=keep_parents,\n",
    "                       crossover_type=crossover_type,\n",
    "                       mutation_type=mutation_type,\n",
    "                       mutation_percent_genes=mutation_percent_genes,\n",
    "                       callback_generation=callback_generation)\n",
    "\n",
    "# Running the GA to optimize the parameters of the function.\n",
    "ga_instance.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phd_env] *",
   "language": "python",
   "name": "conda-env-phd_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "247.333px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
