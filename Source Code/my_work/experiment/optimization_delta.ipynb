{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "[MLENS] backend: threading\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(\n",
    "    1,\n",
    "    '/home/dtd/Documents/interpretable_machine_learning/Source Code/my_work/lib'\n",
    ")\n",
    "\n",
    "import data_load\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import dowhy.datasets\n",
    "import dowhy\n",
    "import propensity_score_estimator as pse\n",
    "import incremental_ps_score_estimator as ipse\n",
    "import math\n",
    "import timeit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import utils \n",
    "from tempfile import TemporaryFile\n",
    "\n",
    "# save numpy array as npy file\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "\n",
    "from dowhy import CausalModel\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import sem\n",
    "from dowhy import CausalModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from econml.dml import LinearDMLCateEstimator\n",
    "from sklearn.linear_model import LassoCV\n",
    "from econml.inference import BootstrapInference\n",
    "from econml.dml import SparseLinearDMLCateEstimator\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from mlens.ensemble import SuperLearner\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment = 't'\n",
    "outcome = 'yf'\n",
    "col =  [\"t\", \"yf\", \"ycf\", \"mu0\", \"mu1\" ]\n",
    "cov = [\"x\" + str(i) for i in range(1,26)]\n",
    "col = col + cov\n",
    "features = cov + [\"t\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization with Adam and original function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incre_ps(delta, data):\n",
    "    q1 = (delta * data['p1']) / (delta * data['p1'] + data['p0'])\n",
    "    q1 = tf.math.abs(q1)\n",
    "    a0 = (1-q1)*data['w0']*(data['cf0'] - data[outcome])\n",
    "    a1 = q1*data['w1']*(data['cf1'] - data[outcome])    \n",
    "    influence = a1 - a0\n",
    "    return tf.reduce_mean(influence)\n",
    "\n",
    "def optimization(data):\n",
    "    threhold = tf.constant([0.001])\n",
    "    delta = tf.Variable(100., trainable = True)\n",
    "    true_effect = np.mean(data['mu1'] - data['mu0'])\n",
    "    \n",
    "    for i in range(80000):\n",
    "        with tf.GradientTape() as tape:\n",
    "            influence = incre_ps(delta, data)\n",
    "            loss = tf.math.abs(true_effect - influence)\n",
    "            d_delta = tape.gradient(loss, delta)\n",
    "            opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "            opt.apply_gradients(zip([d_delta], [delta]))\n",
    "            ## early stopping\n",
    "            if tf.math.less(loss, threhold):\n",
    "                print(\"The performance reach MAE: 0.001. Cancelling the training at step {}\".format(i))\n",
    "                break\n",
    "    return delta, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize in train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:13<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-057649cb41e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'w1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ips_weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtreatment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mdelta_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mdelta_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-9988f9fdf64b>\u001b[0m in \u001b[0;36moptimization\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m80000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0minfluence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mincre_ps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_effect\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minfluence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0md_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-9988f9fdf64b>\u001b[0m in \u001b[0;36mincre_ps\u001b[0;34m(delta, data)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'w1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cf1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutcome\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0minfluence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ma0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfluence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0moptimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/phd_env/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/phd_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mreduce_mean\u001b[0;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[1;32m   2063\u001b[0m       \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2064\u001b[0m       gen_math_ops.mean(\n\u001b[0;32m-> 2065\u001b[0;31m           \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ReductionDims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2066\u001b[0m           name=name))\n\u001b[1;32m   2067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/phd_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_ReductionDims\u001b[0;34m(x, axis, reduction_indices)\u001b[0m\n\u001b[1;32m   1616\u001b[0m     \u001b[0;31m# Fast path: avoid creating Rank and Range ops if ndims is known.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1618\u001b[0;31m       \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1620\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/phd_env/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=access-member-before-definition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "PATH_TRAIN = \"/home/dtd/Documents/interpretable_machine_learning/Source Code/data/ihdp_npci_1-100.train.npz\"\n",
    "PATH_TEST = \"/home/dtd/Documents/interpretable_machine_learning/Source Code/data/ihdp_npci_1-100.test.npz\"\n",
    "\n",
    "delta_seq = []\n",
    "losses = []\n",
    "for index_ in tqdm(range(1, 101)): \n",
    "    data = utils.load_data(PATH_TRAIN, index_)\n",
    "    ## Fit treatment\n",
    "    model_t = LogisticRegression()\n",
    "    model_t.fit(data[cov], data[treatment])\n",
    "\n",
    "    ## Fit outcome\n",
    "    model_y = GradientBoostingRegressor(random_state=0, n_estimators = 5000)\n",
    "    model_y.fit(data[features], data[outcome])\n",
    "\n",
    "    data['p1'] = model_t.predict_proba(data[cov])[:,1]\n",
    "    data['p0'] = 1 - data['p1']\n",
    "\n",
    "    ## Compute counterfactual outcome with no treatment\n",
    "    data_pos = data.copy()\n",
    "    data_pos[treatment] = 1\n",
    "    data['cf1'] = model_y.predict(data_pos[features])\n",
    "\n",
    "    ## Compute counterfactual outcome with treatment\n",
    "    data_neg = data.copy()\n",
    "    data_neg[treatment] = 0\n",
    "    data['cf0'] = model_y.predict(data_neg[features])\n",
    "\n",
    "    data['ips_weight'] = (data[treatment] / data['p1'] + (1 - data[treatment]) /\n",
    "                          (1 - data['p1']))\n",
    "    \n",
    "    data['w0'] = data['ips_weight']*data[treatment]\n",
    "    data['w1'] = data['ips_weight']*(1 - data[treatment])\n",
    "    \n",
    "    delta, loss = optimization(data)\n",
    "    delta_r = delta.numpy()\n",
    "    delta_seq.append(delta_r)\n",
    "    losses.append(loss.numpy())\n",
    "    print(\"Data index {}. Delta {:.2f}. Loss {:.2f}\".format(index_, delta_r, loss.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = asarray(delta_seq)\n",
    "save('delta.npy', delta_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization with list of delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incre_ps(delta, data):\n",
    "    q1 = (delta * data['p1']) / (delta * data['p1'] + data['p0'])\n",
    "    q1 = tf.math.abs(q1)\n",
    "    a0 = (1-q1)*data['w0']*(data['cf0'] - data[outcome])\n",
    "    a1 = q1*data['w1']*(data['cf1'] - data[outcome])    \n",
    "    influence = a1 - a0\n",
    "    return tf.reduce_mean(influence)\n",
    "\n",
    "def optimization(data):\n",
    "    threhold = tf.constant([0.001])\n",
    "    '''\n",
    "    delta = tf.Variable(\n",
    "        tf.random.uniform([data.shape[0],], \n",
    "                          minval=1, \n",
    "                          maxval=100, \n",
    "                          dtype=tf.dtypes.float32), \n",
    "                          trainable = True)\n",
    "    '''\n",
    "    delta = tf.Variable(tf.random.normal(\n",
    "        [data.shape[0],], \n",
    "        mean=0.0, \n",
    "        stddev=1.0, \n",
    "        dtype=tf.dtypes.float32, \n",
    "        seed=1, \n",
    "        name='delta'\n",
    "    ), trainable = True)\n",
    "    \n",
    "    true_effect = np.mean(data['mu1'] - data['mu0'])\n",
    "    \n",
    "    for i in range(50000):\n",
    "        with tf.GradientTape() as tape:\n",
    "            influence = incre_ps(delta, data)\n",
    "            loss = tf.math.abs(true_effect - influence)\n",
    "            d_delta = tape.gradient(loss, delta)\n",
    "            opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "            opt.apply_gradients(zip([d_delta], [delta]))\n",
    "            ## early stopping\n",
    "            if tf.math.less(loss, threhold):\n",
    "                print(\"The performance reach MAE: 0.001. Cancelling the training at step {}\".format(i))\n",
    "                break\n",
    "    return delta, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize in train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1/9 [04:49<38:39, 289.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(672,)\n",
      "Data index 1. Loss 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 2/9 [04:54<23:50, 204.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The performance reach MAE: 0.001. Cancelling the training at step 31\n",
      "(672,)\n",
      "Data index 2. Loss 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 3/9 [09:35<22:43, 227.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(672,)\n",
      "Data index 3. Loss 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 4/9 [14:23<20:27, 245.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(672,)\n",
      "Data index 4. Loss 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 5/9 [19:06<17:06, 256.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(672,)\n",
      "Data index 5. Loss 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 6/9 [23:53<13:17, 265.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(672,)\n",
      "Data index 6. Loss 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 7/9 [28:45<09:07, 273.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(672,)\n",
      "Data index 7. Loss 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 8/9 [33:31<04:37, 277.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(672,)\n",
      "Data index 8. Loss 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [38:27<00:00, 256.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(672,)\n",
      "Data index 9. Loss 0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "PATH_TRAIN = \"/home/dtd/Documents/interpretable_machine_learning/Source Code/data/ihdp_npci_1-100.train.npz\"\n",
    "PATH_TEST = \"/home/dtd/Documents/interpretable_machine_learning/Source Code/data/ihdp_npci_1-100.test.npz\"\n",
    "\n",
    "delta_seq = []\n",
    "for index_ in tqdm(range(1, 10)): \n",
    "    data = utils.load_data(PATH_TRAIN, index_)\n",
    "    ## Fit treatment\n",
    "    model_t = LogisticRegression()\n",
    "    model_t.fit(data[cov], data[treatment])\n",
    "\n",
    "    ## Fit outcome\n",
    "    model_y = GradientBoostingRegressor(random_state=0, n_estimators = 5000)\n",
    "    model_y.fit(data[features], data[outcome])\n",
    "\n",
    "    data['p1'] = model_t.predict_proba(data[cov])[:,1]\n",
    "    data['p0'] = 1 - data['p1']\n",
    "\n",
    "    ## Compute counterfactual outcome with no treatment\n",
    "    data_pos = data.copy()\n",
    "    data_pos[treatment] = 1\n",
    "    data['cf1'] = model_y.predict(data_pos[features])\n",
    "\n",
    "    ## Compute counterfactual outcome with treatment\n",
    "    data_neg = data.copy()\n",
    "    data_neg[treatment] = 0\n",
    "    data['cf0'] = model_y.predict(data_neg[features])\n",
    "\n",
    "    data['ips_weight'] = (data[treatment] / data['p1'] + (1 - data[treatment]) /\n",
    "                          (1 - data['p1']))\n",
    "    \n",
    "    data['w0'] = data['ips_weight']*data[treatment]\n",
    "    data['w1'] = data['ips_weight']*(1 - data[treatment])\n",
    "    \n",
    "    delta, loss = optimization(data)\n",
    "    delta_r = delta.numpy()\n",
    "    print(delta_r.shape)\n",
    "    delta_seq.append(delta_r)\n",
    "    print(\"Data index {}. Loss {:.2f}\".format(index_, loss.numpy()))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAAVCAYAAADYb8kIAAAABHNCSVQICAgIfAhkiAAABJZJREFUWIXt2Hus13MYB/BXNzrLJXKd7QxDC1mYhilFaRgTMjOpodjkMpbblh0ZhSls5rJstdnKOCpRYjTJIqw2psIUSpZbuVQk+eP5fDvf8z3f3zm/00nL5b399vn+nufzeT7P5/k+t8+3XV1dnf+x49C+An0K1qLLTtTln4QTsRVXFxllBj0JQzEev+bo7TAC7+KXxHsf11aQs6NxJqbjG/yGrzEX5+TmDBcHbe63pSC3mzDMdHyGjViPBbhK+dk+wAzcgz3yjI4lk+/FT3i8QH8GlwnPnYoNGJjmnYorSmTtKDyA0ViFF/Ed9hee0g+z07wluLuCjD44A3MK9CHiDGswD1/iQFyISTg7zdlaWDdOONcNuC8jFg16FAYkQRtz9MHCmCvQOx0IdkO98OgZeKHCYdqCEcKYUzASvxf4nXLPS9KvDAvT+FSB/gnOx8v4M0e/E4twkTBufWHdIizDNSKa/6SpO18pQvvZAn1wGh/SYEzicGPS86gKB2kLdhcR86VyY8LmKuT0xMlYLQyXxxuYpbExidTyRHruV0HuNNSKSEVTDx0gcsw7BfpBafy8RGhG6yM8tuzQ24uBIrQfFgc+F8dik/CQhZWXNsLIND6taQ5tDtnL+qMC/+2cnnNpbNAu6IWlGhcjGrzysBKhh6exY3peVr2+LeKkNG7CYmHMPObjYnzbjIwaXC4MOakVe3fUUBdeqTDnvTT2zQj5kD8EHURyLiILk5uxb47eSeMisE+VylaLA9I4WhSFPtgTx+FVcZDnWpBxCboKo3zVir3Hixc4W/K+EqwXL7s2I+Q9tFsafyxZOE0UnkH4GDOToAE4WOS4Wk3zUFuRvfA/ROFYmf5/KPL6cpyOU1QO/yzcn2zFvjfgFhFtQ1uY+4PoChopTENV71yyaAvOw+0ivIal36eiZfo5zVvbCqWrwbo0LtZgzAwbNHhO7wrrjxH6rdLQWrWEUXhEOE5/YbDmUCPXEeU9NDNGN+XYjPvTL4/OOFLk2RVVqVw9lqdxXQV+Fk01FfitLUY3YSI+EheJlhykvUgnK/KEDGuE93WvYuM8LhXVfWor11WD10XuPFr5jSUrUmUvsrMI1y3CoC3hNmHMJcIzq4m27qLN3Nb75pXcKqrmfjiiZPFeJbReeFB4yvgS/uQkd3gVypXhC9Ej1uLGAu8skdPXKa/CQ0SRnKPlYjRG6P+B8Mzvmp++DSencV5GKPah9eJmMEjca/N4TeSKj0TO7CH6wo0iv35dsmG+qGwvrsPxmJD2WyzatwuE910tqm0RWbgXb0ZFDMPYJOstUZCKWCmco4iz0rqZGaHMoGtF//VYgfe8CO/LRc5anZQdJ5J+GXoK4xdvJ63BKnFnv0tU+r7iW8OstPeikjU9cJrqilHWW3cQObQMb2pq0L3FS31JLgLalXwPvUNc9k8Q3rC96IrvxXX11jbI2VVxPR4VvfGCjFiW6CeKvnJsGzfsIzqDCW2UsyuiRjhevZwxKf98t0lUx/7iOlq8hlaLWcp72n8DDhXpbnKRUWZQotrP//v0+cdjKerKGDvjS/t/Cn8BLr4Qk8k4r0QAAAAASUVORK5CYII=\n",
      "text/latex": [
       "$\\displaystyle \\left( 9, \\  672\\right)$"
      ],
      "text/plain": [
       "(9, 672)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(delta_seq).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "save('list_delta_.npy', delta_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Optimization for individual treatment effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incre_ps(delta, data):\n",
    "    q1 = (delta * data['p1']) / (delta * data['p1'] + data['p0'])\n",
    "    q1 = tf.math.abs(q1)\n",
    "    a0 = (1-q1)*data['w0']*(data['cf0'] - data[outcome])\n",
    "    a1 = q1*data['w1']*(data['cf1'] - data[outcome])    \n",
    "    influence = a1 - a0\n",
    "    return influence\n",
    "\n",
    "def optimization(data):\n",
    "    threhold = tf.constant([0.01])\n",
    "    '''\n",
    "    delta = tf.Variable(\n",
    "        tf.random.uniform([data.shape[0],], \n",
    "                          minval=1, \n",
    "                          maxval=100, \n",
    "                          dtype=tf.dtypes.float32), \n",
    "                          trainable = True)\n",
    "    '''\n",
    "    delta = tf.Variable(tf.random.normal(\n",
    "        [data.shape[0],], \n",
    "        mean=0, \n",
    "        stddev=10, \n",
    "        dtype=tf.dtypes.float32, \n",
    "        seed=1, \n",
    "        name='delta'\n",
    "    ), trainable = True)\n",
    "    \n",
    "    true_effect = data['mu1'] - data['mu0']\n",
    "    \n",
    "    for i in range(100000):\n",
    "        with tf.GradientTape() as tape:\n",
    "            influence = incre_ps(delta, data)\n",
    "            loss = tf.keras.losses.MAE(true_effect, influence)\n",
    "            d_delta = tape.gradient(loss, delta)\n",
    "            opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "            opt.apply_gradients(zip([d_delta], [delta]))\n",
    "            if i % 1000 == 0:\n",
    "                print(\"Epoch {}. Loss {:.5f}\".format(i, loss.numpy()))\n",
    "            if tf.math.less(loss, threhold):\n",
    "                print(\"The performance reach MAE: 0.001. Cancelling the training at step {}\".format(i))\n",
    "                break\n",
    "    return delta, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Loss 128.21106\n",
      "Epoch 1000. Loss 35.25104\n",
      "Epoch 2000. Loss 26.33487\n",
      "Epoch 3000. Loss 22.03906\n",
      "Epoch 4000. Loss 19.51452\n",
      "Epoch 5000. Loss 17.79730\n",
      "Epoch 6000. Loss 16.47934\n",
      "Epoch 7000. Loss 15.40867\n",
      "Epoch 8000. Loss 14.58724\n",
      "Epoch 9000. Loss 13.90437\n",
      "Epoch 10000. Loss 13.29880\n",
      "Epoch 11000. Loss 12.75287\n",
      "Epoch 12000. Loss 12.24901\n",
      "Epoch 13000. Loss 11.83835\n",
      "Epoch 14000. Loss 11.50295\n",
      "Epoch 15000. Loss 11.18480\n",
      "Epoch 16000. Loss 10.90050\n",
      "Epoch 17000. Loss 10.66358\n",
      "Epoch 18000. Loss 10.45095\n",
      "Epoch 19000. Loss 10.25655\n",
      "Epoch 20000. Loss 10.07695\n",
      "Epoch 21000. Loss 9.91892\n",
      "Epoch 22000. Loss 9.77304\n",
      "Epoch 23000. Loss 9.63611\n",
      "Epoch 24000. Loss 9.50814\n",
      "Epoch 25000. Loss 9.38981\n",
      "Epoch 26000. Loss 9.27811\n",
      "Epoch 27000. Loss 9.17255\n",
      "Epoch 28000. Loss 9.07324\n",
      "Epoch 29000. Loss 8.97934\n",
      "Epoch 30000. Loss 8.89013\n",
      "Epoch 31000. Loss 8.80546\n",
      "Epoch 32000. Loss 8.72501\n",
      "Epoch 33000. Loss 8.64893\n",
      "Epoch 34000. Loss 8.57677\n",
      "Epoch 35000. Loss 8.50806\n",
      "Epoch 36000. Loss 8.44242\n",
      "Epoch 37000. Loss 8.37966\n",
      "Epoch 38000. Loss 8.31963\n",
      "Epoch 39000. Loss 8.26250\n",
      "Epoch 40000. Loss 8.20809\n",
      "Epoch 41000. Loss 8.15584\n",
      "Epoch 42000. Loss 8.10573\n",
      "Epoch 43000. Loss 8.05758\n",
      "Epoch 44000. Loss 8.01163\n",
      "Epoch 45000. Loss 7.96834\n",
      "Epoch 46000. Loss 7.92674\n",
      "Epoch 47000. Loss 7.88663\n",
      "Epoch 48000. Loss 7.84795\n",
      "Epoch 49000. Loss 7.81053\n",
      "Epoch 50000. Loss 7.77444\n",
      "Epoch 51000. Loss 7.73965\n",
      "Epoch 52000. Loss 7.70595\n",
      "Epoch 53000. Loss 7.67409\n",
      "Epoch 54000. Loss 7.64323\n",
      "Epoch 55000. Loss 7.61338\n",
      "Epoch 56000. Loss 7.58440\n",
      "Epoch 57000. Loss 7.55627\n",
      "Epoch 58000. Loss 7.52914\n",
      "Epoch 59000. Loss 7.50283\n",
      "Epoch 60000. Loss 7.47723\n",
      "Epoch 61000. Loss 7.45239\n",
      "Epoch 62000. Loss 7.42889\n",
      "Epoch 63000. Loss 7.40609\n",
      "Epoch 64000. Loss 7.38403\n",
      "Epoch 65000. Loss 7.36268\n",
      "Epoch 66000. Loss 7.34194\n",
      "Epoch 67000. Loss 7.32175\n",
      "Epoch 68000. Loss 7.30209\n",
      "Epoch 69000. Loss 7.28293\n",
      "Epoch 70000. Loss 7.26449\n",
      "Epoch 71000. Loss 7.24649\n",
      "Epoch 72000. Loss 7.22891\n",
      "Epoch 73000. Loss 7.21174\n",
      "Epoch 74000. Loss 7.19496\n",
      "Epoch 75000. Loss 7.17856\n",
      "Epoch 76000. Loss 7.16253\n",
      "Epoch 77000. Loss 7.14686\n",
      "Epoch 78000. Loss 7.13159\n",
      "Epoch 79000. Loss 7.11670\n",
      "Epoch 80000. Loss 7.10213\n",
      "Epoch 81000. Loss 7.08787\n",
      "Epoch 82000. Loss 7.07391\n",
      "Epoch 83000. Loss 7.06024\n",
      "Epoch 84000. Loss 7.04697\n",
      "Epoch 85000. Loss 7.03399\n",
      "Epoch 86000. Loss 7.02127\n",
      "Epoch 87000. Loss 7.00881\n",
      "Epoch 88000. Loss 6.99659\n",
      "Epoch 89000. Loss 6.98461\n",
      "Epoch 90000. Loss 6.97286\n",
      "Epoch 91000. Loss 6.96134\n",
      "Epoch 92000. Loss 6.95009\n",
      "Epoch 93000. Loss 6.93910\n",
      "Epoch 94000. Loss 6.92838\n",
      "Epoch 95000. Loss 6.91798\n",
      "Epoch 96000. Loss 6.90786\n",
      "Epoch 97000. Loss 6.89798\n",
      "Epoch 98000. Loss 6.88830\n",
      "Epoch 99000. Loss 6.87881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [09:38<00:00, 578.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data index 13. Loss 6.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "PATH_TRAIN = \"/home/dtd/Documents/interpretable_machine_learning/Source Code/data/ihdp_npci_1-100.train.npz\"\n",
    "PATH_TEST = \"/home/dtd/Documents/interpretable_machine_learning/Source Code/data/ihdp_npci_1-100.test.npz\"\n",
    "\n",
    "delta_seq = []\n",
    "for index_ in tqdm(range(13, 14)): \n",
    "    data = utils.load_data(PATH_TRAIN, index_)\n",
    "    ## Fit treatment\n",
    "    model_t = LogisticRegression()\n",
    "    model_t.fit(data[cov], data[treatment])\n",
    "\n",
    "    ## Fit outcome\n",
    "    model_y = GradientBoostingRegressor(random_state=0, n_estimators = 5000)\n",
    "    model_y.fit(data[features], data[outcome])\n",
    "\n",
    "    data['p1'] = model_t.predict_proba(data[cov])[:,1]\n",
    "    data['p0'] = 1 - data['p1']\n",
    "\n",
    "    ## Compute counterfactual outcome with no treatment\n",
    "    data_pos = data.copy()\n",
    "    data_pos[treatment] = 1\n",
    "    data['cf1'] = model_y.predict(data_pos[features])\n",
    "\n",
    "    ## Compute counterfactual outcome with treatment\n",
    "    data_neg = data.copy()\n",
    "    data_neg[treatment] = 0\n",
    "    data['cf0'] = model_y.predict(data_neg[features])\n",
    "\n",
    "    data['ips_weight'] = (data[treatment] / data['p1'] + (1 - data[treatment]) /\n",
    "                          (1 - data['p1']))\n",
    "    \n",
    "    data['w0'] = data['ips_weight']*data[treatment]\n",
    "    data['w1'] = data['ips_weight']*(1 - data[treatment])\n",
    "    \n",
    "    delta, loss = optimization(data)\n",
    "    delta_r = delta.numpy()\n",
    "    delta_seq.append(delta_r)\n",
    "    print(\"Data index {}. Loss {:.2f}\".format(index_, loss.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save('individual_list_delta_.npy', delta_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRAIN = \"/home/dtd/Documents/interpretable_machine_learning/Source Code/data/ihdp_npci_1-100.train.npz\"\n",
    "PATH_TEST = \"/home/dtd/Documents/interpretable_machine_learning/Source Code/data/ihdp_npci_1-100.test.npz\"\n",
    "\n",
    "\n",
    "index_ = 10\n",
    "data = utils.load_data(PATH_TRAIN, index_)\n",
    "data_test = utils.load_data(PATH_TEST, index_)\n",
    "\n",
    "## Fit treatment\n",
    "model_t = LogisticRegression()\n",
    "model_t.fit(data[cov], data[treatment])\n",
    "\n",
    "## Fit outcome\n",
    "model_y = GradientBoostingRegressor(random_state=0, n_estimators = 5000)\n",
    "model_y.fit(data[features], data[outcome])\n",
    "\n",
    "data['p1'] = model_t.predict_proba(data[cov])[:,1]\n",
    "data['p0'] = 1 - data['p1']\n",
    "\n",
    "## Compute counterfactual outcome with no treatment\n",
    "data_pos = data.copy()\n",
    "data_pos[treatment] = 1\n",
    "data['cf1'] = model_y.predict(data_pos[features])\n",
    "\n",
    "## Compute counterfactual outcome with treatment\n",
    "data_neg = data.copy()\n",
    "data_neg[treatment] = 0\n",
    "data['cf0'] = model_y.predict(data_neg[features])\n",
    "\n",
    "data['ips_weight'] = (data[treatment] / data['p1'] + (1 - data[treatment]) /\n",
    "                      (1 - data['p1']))\n",
    "\n",
    "data['w0'] = data['ips_weight']*data[treatment]\n",
    "data['w1'] = data['ips_weight']*(1 - data[treatment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_effect = data['mu1'] - data['mu0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the initial population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_deltas = []\n",
    "# initial_delta = np.random.randint(0, high=100, size=[100,data.shape[0]])\n",
    "# initial_deltas.append(initial_delta)\n",
    "initial_delta = np.random.rand(1000,data.shape[0])\n",
    "# initial_deltas.append(initial_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_deltas = np.array(initial_deltas)\n",
    "# initial_deltas = initial_deltas.reshape(200,672)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitness function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incre_ps(delta, data):\n",
    "    q1 = (delta * data['p1']) / (delta * data['p1'] + data['p0'])\n",
    "    q1 = abs(q1)\n",
    "    a0 = (1-q1)*data['w0']*(data['cf0'] - data[outcome])\n",
    "    a1 = q1*data['w1']*(data['cf1'] - data[outcome])    \n",
    "    influence = a1 - a0\n",
    "    return influence\n",
    "\n",
    "def fitness_function(influence, true_effect):\n",
    "    return 1 / np.mean(utils.abs_ate(influence, true_effect))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "individuals = []\n",
    "fitnesses = []\n",
    "for delta in initial_delta:\n",
    "    individual = incre_ps(delta, data)\n",
    "    fitness = fitness_function(individual, true_effect)\n",
    "    fitnesses.append(fitness)\n",
    "fitnesses = np.array(fitnesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_mating_pool(number_parents, population, fitnesses):\n",
    "    \"\"\"\n",
    "    Select number of individual with the highest fitness\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    indices = (-fitnesses).argsort()[:number_parents]\n",
    "    parents = population[indices, :]\n",
    "    return parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_individuals = select_mating_pool(300, initial_delta, fitnesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAG0AAAAVCAYAAABMiWD6AAAABHNCSVQICAgIfAhkiAAABUVJREFUaIHt2nvMl2MYB/BPCSX2ZtLBIYeoOW1ECYWil5Xz6S/RUDMRpjSMiiGGHGbUYuEfhzkv1KQ5n5YME8k6iEgih4SSP67nWc/veZ/f7/297y8V67u1+911P9d9X7/7uu7r+t7XajF27Fib8d9CyzLyh7AUbTegLZtRioOxFhfkJ4qc1hODMR6/ZeS3YAa+wu9YjtkYgx0qbL4LHsQ3+AMLcCe2X8866wPH4Gl8m+z7DaZhYO67IeJAK/1bk9PZQTjgacwTZ7gCb+B8DX0xC8/gBmybnWhRkB6noxc6Jwun+BMf4FPrbmFvHJL8uN7CoVl0xVvogGfxWbJ2P3yOI/DDetBZH7gVo7AYL2IZdhQR/zKuzHx7IE4ps05f9MdUnJCRX4j7sAQzsQgdcRrq8CTOFA5P0Qvv4hrclArzTusmDmkyhuWMaY1VBUbeiKsTgy7KzU1DPUbgnoz8DlyOicmPqVWnVgzFJFEWhokAzWJL/FXlWm+LAD4Zz2Xk/UWgT8XfGXknvIddcYZwXhZzsA32SPXyV/I8tMBjBcYUOQweT8a9c/Ku4vAX4N7c3BiRegcrrZvN0akVW4vAW6TYYVTvsAOEw74WzsniFTyv1GFEKr4/+fvogjUfRRcMSAV5px0rcvE7VRoJJybjRzl5v2ScXmDoL3hTRFDvGnVqxQCRBp9K9hyE0bgUhzVxrTQ7PaBhTauENChWF8y9mbETtMpMthW5eo5SApLHSFEY60Q96yMcNj73XfdknFtmnS/EreomCE5zdWpFz2RcJYjV/rn510Ta+r6RddrgbOGsyU3YvxXOSf5+qWD+/WQ8MquQYmdsIQplJYwUBTTFS4JN5X9UXTKuKLNOKm9Xo06t6JCMowTJ6osPRQ25TQTJE4pTVxZnJXZN1ZCQVcJ4ESgviHqexwoRUF1SQTY9prT9x0Y26STqXifBfPYUEdqjCYZuSkjPYDVOEhT8V3yMUwWbPErjqTJNjRObsPcIXCHI3+AK3y1H+7zBrKP3ravc8Dvx5qgXDn84N5/eijrFSOU/1ahTK9K1ZgsClMVK66K/V4U19sPhwsEvVLnvxbhL3O5+wjHl0Ebm+ZV12tJkrPRQLsLCZOP9ZKJBvKmI+lOElG1m61dzdGpFume5QEgzT5sKazSVgFwmnjOfCId9W+HbliLtLs0KUiwRdam7pmOnZMwaPDMZ6zVkqduJR/JKpUy1OTq1YoZ40O5bsCfriMn8MvqtRWpbI5zWGEZjgqib/WScUQbdRTn6MBVkjVwrmFJ77JVT7KY4ZbUUb5wOoouRrYdfCuq+O4bn9MYJtvqIUqbaHJ0pie1DCuyrBgvF+6mLoPlZ1OM4cQuLmB3RxdhedFEaIyDXCuIxS7TMllVhX/q8SQO6hD0Sr/HTE0PnZeQDcbMo0vNFG6mjKNB7ius9tGDDi4Qz706MnINDRYTNFe2ZWnWyRKK5GI6DRNdlkKhve4hW1RrRMyzHaNPUOKmRPc7F9cl6rwsSkscCEYRZ1Cc6z6aCfBtrKxEtC8RBpdhftI76iGZuOxHtcwXFvVv5QrprYuzxol4uEQRmnPJMtSk6s0UnZbcK61WDHXGdYJCd8bM43JtFm6kI+4h6vlhkh0r1bKzo6lTCq0qfFnXiQkyT6XUWNYyvEs3JHuJANmW0E7f+dqUN3f8LLhEXoq/IciguvBNEH+76DWNXTegrWkB3bGxD/gW0ERfoSRmH0bCmEa/vwaKGtFW5pbWx8bzq35X/Newu6uSU/ESR0wgW+dq/Z89mVIE5og42QLn/brAZmzD+AaN4Xhk52JciAAAAAElFTkSuQmCC\n",
      "text/latex": [
       "$\\displaystyle \\left( 300, \\  672\\right)$"
      ],
      "text/plain": [
       "(300, 672)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_individuals.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossover\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_over(parents, number_of_offspring, crossover_point):\n",
    "    new_population = []\n",
    "    \n",
    "    for i in parents:\n",
    "        new_population.append(i)\n",
    "    \n",
    "    offspring = np.zeros((number_of_offspring, 672))\n",
    "    for i in range(number_of_offspring):\n",
    "        parent1_idx = i % parents.shape[0]\n",
    "        parent2_idx = (i+1)% parents.shape[0]\n",
    "        offspring[i, 0:crossover_point] = parents[parent1_idx, 0:crossover_point]\n",
    "        offspring[i, crossover_point:] = parents[parent2_idx, crossover_point:]\n",
    "        new_population.append(offspring[i])\n",
    "    new_population = np.array(new_population)\n",
    "    return new_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIcAAAAVCAYAAABsSf1CAAAABHNCSVQICAgIfAhkiAAABRpJREFUaIHt2mmsHmMUB/Bf7bWkpBRBEfu+xZ7SWlo0EfsnRSwlliK22G+JJRJ7rCnR8IFIbaVUglBrRdqEKC1RVCu11r5VfTjPuNO5M+9737m3b0nuP7l53pxn+Z+ZOfM8/3Pm9uvo6NCHPpRhmQr7eMzHKm30pQ9LB7tgEU4udpQFx64Yhevxc85+FG7HFPyQFnyoG+Tr437Mxe+YjVuwRsX4OjytctSd01vYH4/jy8Q9F5NxSG7MCeLaG/0tLKw7UDzkx/ERfsUCvIqTlD/vd/AErsaq+Y7lSgZfIx7KXQX7ZdgBP2EOtiyZW8QmeB2D8CQ+wG44Gwdhb3zTQ546HHXm9BZuwAXi2p7C11hLvMFDMSmNm46xFWsMwX54tmA/Wjy3eXgJn2FtHIFxODiNWVSYdx3ewhhcmxmLwbE5DkgL/VroOzdd0EfYN5E3w53iAYwRu0GGm9J61+C0HvLU4agzpzdwigiM8RiNPwr9y+d+T09/ZXgjtfcW7DNxKJ7B3zn7JZiKI0WgTCjMmypekFPFifE3XbeZE9EPj5Q49BJm6Rp1VdgEw8V2fUeh70pxZI3SVde0wlOHo65fPcWKIug+Ux4Y8Gc31tkOe+ALEQR5vIiJFg8M4vi6O/0eWrHuwxiMAzNDMTgOEOfYm91wshmGpfZ5XZ39Ea9hZXGh7eRoh19lOFAcH48l3pG4SBxle7awzujU3qer5miELPD+quh/LecnFg+OVbAjZlhciNbFFqmdWdE/K7Wbt5mjHX6VYdfU/oZpeFps4bcI/fOyCJ5G6I9jRVCMa4F7ORyXfj9XMebt1O6TGfLBsR6WFWKmNzAgtQsq+jP76m3maIdfZRiU2gvEkTkEq2F7sYvtg0ebrHFM8us5fN4C9/XYVojdyRVjFojAHZwZ8sExMLXftUDah+4ju9d/CdH4qsjI3sXhQoTvq/ERkx0p97TAOwbnCcE5qsnYb7Fm0WE6s5OVWiBuhOwNHFDRn9m/bzNHO/wqQ7beNCGG8/hF5xu9W8X8bbCXCKJJFWOKOBO34n2htb5tMr6/XJaaD475qR2od/BhaqvO7s1SW3X2LymOdvhVhoy3KuiyHbt/RX+rQvQckaa/JwLjyybjlxFH1vy8IcM8fKVTsPUUWX1iuK5Z0Wqi0PSLnmVGdTja4VcZXhBaY+sSXkITwCclfSuJI2GhCI5muAg3izrJMLkH3gBbiDLGv7WVvJOL8Io4czbtxmLN8LEQWhvhjELfWJEdPahnmVEdjrp+PSDu0Qk1ff1U1CAGi/Q1j+EYIXaVsmziaFHWf1ZzIXq5EKDviDL91930L0vd/y06FiukE0QVbYSoUOZxWPqDdVK7p7hpkhPnF+acLtK025KjM7C7iOaZuLTEyVZ56nDUmZMXlHVxBnYSldiRQn9sLK53ofguUpZFZUdKsSJaxPG4Kq01RYjRImbrvJd5DE/znswM/Qqf7FcQkTlb3Kw8OkQFsQqfirexiA2SwwcJPTNPfBgaqzwzqsPTKkedOdNEdXXDBmt2B2vhCpGxrCu+Y00R3zemlozfSgjKOeK6G+mNDo3vHVFPGVqwDRCaZLLOF7NLcMDF4uPLzuKG9CGE2je4ERcuZV+WBM4Su+gQkWKjXBjdLOr/V7XHr/8Fhojy801L25ElgP5iQ5ggFxiUf7L/TSjjYUKc9UYp/f+OiXqv/vNfw0ZCyzxQ7CgLDiJreWXJ+dOH/xBmCK3SBVX/JtiHPvgHXUyAtK3iWMEAAAAASUVORK5CYII=\n",
      "text/latex": [
       "$\\displaystyle \\left( 10100, \\  672\\right)$"
      ],
      "text/plain": [
       "(10100, 672)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossed_individuals = cross_over(selected_individuals, 100, 5)\n",
    "crossed_individuals.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(new_population, mutation = 1):\n",
    "    mutations_counter = 4\n",
    "    for idx in range(new_population.shape[0]):\n",
    "        gene_idx = mutations_counter - 1\n",
    "        for mutation_num in range(mutation):\n",
    "            random_value = np.random.uniform(-1.0, 1.0, 1)\n",
    "            new_population[idx, gene_idx] = new_population[idx, gene_idx] + random_value\n",
    "            gene_idx = gene_idx + mutations_counter\n",
    "    return new_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02163649, 0.41709053, 0.38759095, ..., 0.50348067, 0.56017379,\n",
       "        0.46745206],\n",
       "       [0.16155893, 0.10382068, 0.71079089, ..., 0.47409612, 0.11246884,\n",
       "        0.36487311],\n",
       "       [0.3956946 , 0.31068936, 0.36501449, ..., 0.66218478, 0.7951693 ,\n",
       "        0.82734737],\n",
       "       ...,\n",
       "       [0.76924952, 0.62774442, 0.10211664, ..., 0.10015515, 0.35607988,\n",
       "        0.67855872],\n",
       "       [0.16168693, 0.97146778, 0.85237895, ..., 0.29754531, 0.92246113,\n",
       "        0.75778193],\n",
       "       [0.28043303, 0.63806029, 0.95452839, ..., 0.92652488, 0.05667425,\n",
       "        0.66161083]])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutation(crossed_individuals, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4000 [00:21<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta [  57.23956449  141.30936606  -11.08463045  107.98597612   15.74858385\n",
      "  233.26481807    3.82821719   87.86111005  144.11097709  232.08846546\n",
      "   58.26774022  150.54181873   47.06793608  -19.20697981  -35.7736785\n",
      "  -75.20597203  150.06343887   -8.20634594   32.4385488    18.34709729\n",
      "   95.42798426   47.44837237   -7.27754578   54.90606598 -180.98282809\n",
      "    7.8573297    90.50896769  222.40828552  110.16190544  222.01395063\n",
      "  -41.13301755   93.24354849  -71.84827207  -48.55910364   29.11759921\n",
      "   37.43560053   69.32095812   24.51802602  -64.00103178  147.4551809\n",
      "  -15.96248628   75.93573831  -68.96986285 -144.19889484   93.98654668\n",
      "  -99.33473061  146.42953531  112.98603435  244.18231905  -43.10014568\n",
      "   32.76676187   -6.59659284  189.88503787   97.6834094   131.15025428\n",
      "  110.71763846  -27.28637672  127.88540728  117.18068539  211.95299317\n",
      "  -84.68895189  -10.29458456   45.19496731   68.49823361   61.97464751\n",
      "  191.96077873   45.36208284  -99.36486098  -40.82507088  250.19477593\n",
      "  -38.17632161  186.37813938   57.26265825   73.63652761  121.16684644\n",
      "  -19.57888552  -45.9606447    -3.96753139   23.33358128  172.49536889\n",
      "   63.04943889  -77.32425723   48.0817527     9.11080065  156.54392207\n",
      "   94.25486189  106.89958044   -2.83000403  -29.65930672  -59.92993999\n",
      "  120.70856075   81.32316317   26.50868218   17.57295058  -93.96017573\n",
      " -112.47854129   65.55306776   75.28539815  -25.34089426   70.03879664\n",
      "  102.93882507   34.85063633   63.18425477 -107.33323152  137.10902527\n",
      "   35.94408108  -67.7000983   191.27621985   54.60376697   37.72095596\n",
      "   28.91608722  230.82466839  237.00467637 -133.9791057   119.44147154\n",
      "   27.81173698  114.82107108  -43.59112066  169.99611562   10.86464111\n",
      "  -93.01394525  174.11884995    0.52039186   44.39683928   23.57974857\n",
      "  230.37190286  130.28465959  -55.19129866   62.44291877  -34.43628797\n",
      "   23.31275902   11.47777142 -140.69625401 -103.81313266  -25.0057125\n",
      "  173.02595839  166.76326953  -64.19071399  -82.33354887   14.98362723\n",
      "   -7.85353057  -28.33248094   13.6543022    72.03852141   78.66755532\n",
      "   20.81638892  205.95742638   27.40731922  120.36574544  127.56542778\n",
      "  168.6100956   105.05420591 -134.95598112   86.69561363  178.63877163\n",
      "  154.65724219 -151.41826112   95.79480092   70.71506718 -309.57266921\n",
      "   81.67085825   71.95795656   71.58685035   68.10773325   -6.35474261\n",
      "   94.29431919  136.90884956 -104.14350288   78.80275644   56.62496548\n",
      "  177.1928197   213.79573044  -83.0815619   214.83898687   17.16863205\n",
      "  140.34239957   94.24043869  211.82467826  173.77787244 -241.51295701\n",
      "  241.03240757  -22.45182064  -88.82638231  118.29468278  -32.52900741\n",
      "   87.10574371  109.04124288   -3.03561219  129.69344736  -35.99314648\n",
      "   22.46199362   91.79537106   72.42129881  244.74679597  -70.93498619\n",
      "  146.1033799   149.06988206  155.23609158  -64.61882685  -65.59820079\n",
      "   27.57116746   36.58850863   31.85855284  157.59641888  -55.00511032\n",
      "  -90.3117897   237.62586105   67.97413027 -121.72430966   89.93266026\n",
      "   64.14420291  121.32514158   -4.43577421   33.19044146  -32.35361063\n",
      "   21.68567404   88.73426093  199.84308854  -22.20178481   35.77196935\n",
      "  142.0417394    64.46519267  183.84581346  -23.07433476    3.78773972\n",
      "  228.38015841  -39.18118388   42.31869451  128.11265469  156.51983814\n",
      "   59.06240188  125.41338471   38.8119539    82.92954464  194.6265482\n",
      "  -50.40359285   63.18487852  -53.81166237  -24.48346951   57.76121688\n",
      "    1.49619998  -31.78489003  112.89833619  281.44042632   92.88730034\n",
      "   15.35434402  154.09022535   60.15788979  144.31806832   15.76672154\n",
      "   59.81113678  118.92358909  153.5789646   112.5055659    41.69857148\n",
      "   92.68853997  100.15179513   63.63483597   38.18488695  306.00450314\n",
      "   40.62233634  212.79348764   99.01910226 -250.3688492   126.36500298\n",
      "  -16.49834317    7.87282054  -67.21986627   45.8409131    71.20290783\n",
      "   81.51911259 -151.13923292  109.58792129  -71.18635809   49.26623174\n",
      "   87.36129242  150.42223006  129.62726203  181.70863007   82.79239961\n",
      "  -78.37455761  -59.87373534    2.34050378  -75.20555295   30.39396817\n",
      " -136.93282221   24.94344723  -62.91938443  -73.62975845  175.82578931\n",
      "  -29.95506638  -32.17206123 -172.6863884    -3.86476387  -15.18164898\n",
      "  -34.81038448   27.53293242  136.75322689  130.84316685   87.53705278\n",
      " -144.35586244  201.00274166   98.77129047   13.27488092   82.88729177\n",
      "   77.69092879    9.62321402  192.3231739    27.56338065   41.4361209\n",
      "  -98.15251361   10.13851491  202.14979801  184.39061807   24.45092629\n",
      "  -15.30532173  -32.94039776  146.03968861  -28.49171929   14.21660745\n",
      "  -13.14405564  -95.91651693   39.30694852   80.6329886     7.20493045\n",
      "   82.55278774  111.55312552  -72.8863647   146.45247131  -31.2095109\n",
      "  116.84970387  -45.93343395  194.81016172   44.51706225   87.33577664\n",
      "   37.92170542  154.23273882    7.38537305   58.35799313   69.07408498\n",
      "  -61.26292599  165.7402405    41.55328915  -36.63369777   94.35314871\n",
      "  143.9903437   -92.01701404   12.16929711   84.80595303   -0.98538781\n",
      " -103.9960446    60.30970668  152.22413755   91.90117077  254.05459858\n",
      "  -68.20000693  167.01901823   98.95022223 -100.37913241   -7.5866497\n",
      "   20.2326764    67.17618228  133.48596191  229.0579057   -53.12065912\n",
      "  136.6047762    69.58717524  -66.67264342  -67.68725002  -32.15186333\n",
      "  -84.04628669   52.83628536  -47.67767088   13.88758883  180.16005384\n",
      "  -10.21102965   72.96098668    4.21810319  104.86981774  124.73470866\n",
      "  212.07766371  -69.05547032  107.6542297    57.71135923  -63.2606139\n",
      "  -59.29905256  123.89699418  134.36357987  -53.28139233  128.75070686\n",
      "   23.59751873  -16.72916985   82.27711161  -39.94282321  218.76430169\n",
      "  -11.29011456   68.84955341   37.64422607    0.63199148  185.63062133\n",
      "  143.07987448   16.64617388  104.84231282   -0.35610154   49.83214707\n",
      "  -95.4930251  -118.60859826   40.80785974  -11.20033602  172.5168465\n",
      "  -82.63493159   39.13466722   71.5637077    83.62818536   49.72473165\n",
      " -195.99490547  181.95757445    9.00764814  -31.36344258 -114.37352871\n",
      " -185.52105736 -203.0327271   -73.66555924    1.71370484  -19.06695992\n",
      "  150.85924939  176.85109657  103.30665245  -51.59087451  153.28448202\n",
      " -173.69000955  142.82774704  -42.25218876  -60.49221545  -69.53603968\n",
      "  172.35299199  317.77858295   21.10338778   71.74800848  -78.76240575\n",
      " -114.74668933  -12.26565052   42.50264333  -40.50380991  -41.79647317\n",
      "   97.87304159  -44.34777721  137.60640735   13.6986115    44.51133604\n",
      "    6.99004676   49.56151369  -47.57291537   61.67051605  198.24605218\n",
      "   56.36517334  -77.79213682   62.57895315  -98.22998955  -83.33934192\n",
      "  142.51642839   62.32477238  283.50095867  268.74349544  204.12479144\n",
      "  -87.66127029   -8.61041345  163.31701342   -1.2143821   -34.12756816\n",
      " -102.45937999  141.73100743   77.68205459 -106.03791565   87.36887398\n",
      "  -36.74674911  -53.47634944   53.964713    -27.76103248  181.32457928\n",
      "   10.8347924   101.32938493   24.86858542  138.97552931   70.94865494\n",
      "   71.89222049  156.90521756   68.59254344 -163.19404187   82.15356095\n",
      "  -93.33301816  105.14751852   57.88675077   62.1171015   129.45981094\n",
      "   28.12589655   69.4520536    34.60916399  139.5111734    89.37551137\n",
      " -106.9801097   158.05283108  176.57552263  111.24843991   16.15972846\n",
      "  153.79353766  -55.98378506  -36.26956212  103.74770052   61.39797768\n",
      " -219.20922326  306.4357107    33.85865387  259.71790098    3.76258616\n",
      "   53.60923789   69.96633666   85.42043054  -47.2713944   -77.82868803\n",
      "  -22.80654731  161.95544412   47.53933867   93.65072681 -127.33439999\n",
      " -125.85570209   96.8215814    97.53938815   12.98081001   41.03605668\n",
      "   52.934636    -61.32854985  111.78558764   71.69152542   -1.64396406\n",
      "  139.92311273  158.64623997   42.93088916  -47.71799219  109.13239141\n",
      "   38.69128725   82.3355913    85.72215792  101.87650014  -22.8029051\n",
      "   90.61720054   94.53563502  -64.27541883   33.33670577  258.94731277\n",
      " -299.05423061  209.64462663  -29.08184856   -3.60571921  -56.70040366\n",
      "   60.35510932   29.78863128   77.67940368   68.89587383  -21.74697236\n",
      "   42.78590521  -27.40040281   57.26914298 -115.19254991   13.71903626\n",
      "   32.46311122  172.27160424   30.31370353   -7.71546394   26.41027383\n",
      "  253.15761515   72.95096031   -2.28744414    4.54297518  165.24050208\n",
      "  235.00422581   49.62016804  200.13877433  209.03907744   85.04863175\n",
      "   76.01303791  143.9573323    25.48749006   62.65880241  -40.20984772\n",
      " -134.16152899 -108.05033118    5.74491818   69.07508346   78.27612895\n",
      "  133.30224073 -105.37722332   -0.3226677    78.99389728   92.00641594\n",
      "  -68.22607817  -66.75710156  -84.8038425    46.7048925    28.51782447\n",
      "  240.19630689  131.21012306   70.67248477  -66.78774547   -2.59623358\n",
      "   62.36534439   78.3184833   -36.453761     50.86053952    3.74329973\n",
      "   55.53767065  135.16500358  234.14060979   95.08390657  234.01400086\n",
      "   83.58060672   70.31111963  -91.00423717  200.15123996   88.4995319\n",
      "  239.71986874  171.84601903   73.17473661  147.95654964  139.49489524\n",
      "   45.57664651  -83.26594557  157.52532713  -54.73042052  314.96413188\n",
      "   65.12763611  -22.61859965 -114.54936132 -168.89142764  -43.1967065\n",
      "  145.45702066   72.59542933  132.73036766  173.16123692  -64.68078912\n",
      " -126.51952394   99.50206479    3.93369894   32.61053991 -100.60448856\n",
      "  -49.72248904    1.81879594  195.77133802   44.26605429   92.3598045\n",
      "  -67.20109645  -63.7790966    89.47988209  -23.17697355  -98.44112521\n",
      "   37.05135827  -13.1227829    30.30189443   33.87871731  148.38285032\n",
      "  -90.47657556 -133.87638546  108.37466417  -37.56310246 -188.24699595\n",
      "   51.1693672    97.41027368   54.27835196  -73.52298889  -44.68701395\n",
      "   78.65613279   42.11714223]\n",
      "Generation 0. MAE 3.9340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'initial_population' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-214-5fba893b4981>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mselected_individuals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_mating_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitnesses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mnumber_of_offspring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_population\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mselected_individuals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of selected individuals {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_individuals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'initial_population' is not defined"
     ]
    }
   ],
   "source": [
    "### fully programming\n",
    "m1, m2 = 10000, 10000\n",
    "a = np.random.rand(m1,data.shape[0])\n",
    "# b = np.random.randint(low = 0, high=100, size=[m2,data.shape[0]])\n",
    "initial_delta = np.array([a,b]).reshape((m1 + m2, data.shape[0]))\n",
    "\n",
    "initial_delta = np.random.normal(50, 100, (10000,data.shape[0]))\n",
    "\n",
    "\n",
    "\n",
    "number_of_generation = 4000\n",
    "for i in tqdm(range(number_of_generation)):\n",
    "    individuals = []\n",
    "    fitnesses = []\n",
    "    mae = []\n",
    "    for delta in initial_delta:\n",
    "        individual = incre_ps(delta, data)\n",
    "        fitness = fitness_function(individual, true_effect)\n",
    "        fitnesses.append(fitness)\n",
    "        mae.append(np.mean(utils.abs_ate(individual, true_effect)))\n",
    "    \n",
    "    print(\"Delta {}\".format(initial_delta[np.argmin(mae, axis=0)]))\n",
    "    print(\"Generation {}. MAE {:.4f}\".format(i, min(mae)))\n",
    "    fitnesses = np.array(fitnesses)\n",
    "    selected_individuals = select_mating_pool(5000, initial_delta, fitnesses)\n",
    "    \n",
    "    number_of_offspring = initial_population.shape[0] - selected_individuals\n",
    "    \n",
    "    print(\"Number of selected individuals {}\".format(selected_individuals.shape))\n",
    "    crossed_individuals = cross_over(selected_individuals, number_of_offspring, 5)\n",
    "    print(\"Number of crossed individuals {}\".format(crossed_individuals.shape))\n",
    "    initial_delta = mutation(crossed_individuals, 2)  \n",
    "    print(\"Number of mutated individuals {}\".format(initial_delta.shape))\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 10.8392\n",
      "MAE 10.8329\n",
      "MAE 10.8415\n",
      "MAE 10.8465\n",
      "MAE 10.8447\n",
      "MAE 10.8555\n",
      "MAE 10.8501\n",
      "MAE 10.8496\n",
      "MAE 10.8577\n",
      "MAE 10.8586\n",
      "MAE 10.8625\n",
      "MAE 10.8600\n",
      "MAE 10.8643\n",
      "MAE 10.9111\n",
      "MAE 10.8729\n",
      "MAE 10.8730\n",
      "MAE 10.8733\n",
      "MAE 10.8756\n",
      "MAE 10.8722\n",
      "MAE 10.8805\n",
      "MAE 10.8766\n",
      "MAE 10.8765\n",
      "MAE 10.8787\n",
      "MAE 10.8812\n",
      "MAE 10.8797\n",
      "MAE 10.8785\n",
      "MAE 10.8824\n",
      "MAE 10.8819\n",
      "MAE 10.8814\n",
      "MAE 10.8814\n",
      "MAE 10.8819\n",
      "MAE 10.8816\n",
      "MAE 10.8832\n",
      "MAE 10.8831\n",
      "MAE 10.8836\n",
      "MAE 10.8689\n",
      "MAE 10.9929\n",
      "MAE 10.8844\n",
      "MAE 10.8845\n",
      "MAE 10.8884\n",
      "MAE 10.8881\n",
      "MAE 10.8877\n",
      "MAE 10.8873\n",
      "MAE 10.8878\n",
      "MAE 10.8888\n",
      "MAE 10.8886\n",
      "MAE 10.8891\n",
      "MAE 10.8895\n",
      "MAE 10.8905\n",
      "MAE 10.8909\n",
      "MAE 10.8909\n",
      "MAE 10.8916\n",
      "MAE 10.8919\n",
      "MAE 10.8927\n",
      "MAE 10.8932\n",
      "MAE 10.8928\n",
      "MAE 10.8931\n",
      "MAE 10.8940\n",
      "MAE 10.8903\n",
      "MAE 10.8969\n",
      "MAE 10.8944\n",
      "MAE 10.9160\n",
      "MAE 10.8944\n",
      "MAE 10.8962\n",
      "MAE 10.8954\n",
      "MAE 10.8944\n",
      "MAE 10.8950\n",
      "MAE 10.8959\n",
      "MAE 10.8954\n",
      "MAE 10.8967\n",
      "MAE 10.8962\n",
      "MAE 10.8926\n",
      "MAE 10.8983\n",
      "MAE 10.8963\n",
      "MAE 10.9007\n",
      "MAE 10.8998\n",
      "MAE 10.8990\n",
      "MAE 10.8988\n",
      "MAE 10.9009\n",
      "MAE 10.9003\n",
      "MAE 10.8996\n",
      "MAE 10.8887\n",
      "MAE 10.8980\n",
      "MAE 10.9442\n",
      "MAE 10.8997\n",
      "MAE 10.9011\n",
      "MAE 10.9053\n",
      "MAE 10.9052\n",
      "MAE 10.9052\n",
      "MAE 10.9016\n",
      "MAE 10.9002\n",
      "MAE 10.9056\n",
      "MAE 11.0501\n",
      "MAE 11.2068\n",
      "MAE 11.0770\n",
      "MAE 10.9341\n",
      "MAE 14.0483\n",
      "MAE 10.8584\n",
      "MAE 10.9237\n",
      "MAE 10.8227\n"
     ]
    }
   ],
   "source": [
    "for delta in initial_delta:\n",
    "    individual = incre_ps(delta, data)\n",
    "    mae = np.mean(utils.abs_ate(individual, true_effect))\n",
    "    print(\"MAE {:.4f}\".format(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.25904245],\n",
       "       [ 1.55772193],\n",
       "       [ 1.44380754],\n",
       "       ...,\n",
       "       [-0.51596899],\n",
       "       [ 0.38491367],\n",
       "       [ 0.55890001]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.normal(0, 0.9, (3000,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-phd_env] *",
   "language": "python",
   "name": "conda-env-.conda-phd_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "247.333px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
