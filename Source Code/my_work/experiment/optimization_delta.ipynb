{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trduong/anaconda3/envs/phd_env/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/trduong/anaconda3/envs/phd_env/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "MAIN_PATH = \"/home/trduong/Data/interpretable_machine_learning/Source Code/my_work\"\n",
    "\n",
    "\n",
    "sys.path.insert(\n",
    "    1,\n",
    "    MAIN_PATH + '/lib'\n",
    ")\n",
    "\n",
    "sys.path.insert(\n",
    "    1,\n",
    "    MAIN_PATH + '/config'\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import dowhy.datasets\n",
    "import dowhy\n",
    "import incremental_ps_score_estimator as ipse\n",
    "import experiment_config as cf\n",
    "import math\n",
    "import timeit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import utils \n",
    "import experiment_config as cf\n",
    "\n",
    "from tempfile import TemporaryFile\n",
    "\n",
    "# save numpy array as npy file\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "\n",
    "from dowhy import CausalModel\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import sem\n",
    "from dowhy import CausalModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from econml.dml import LinearDMLCateEstimator\n",
    "from sklearn.linear_model import LassoCV\n",
    "from econml.inference import BootstrapInference\n",
    "from econml.dml import SparseLinearDMLCateEstimator\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "import logging\n",
    "import pygad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment = 't'\n",
    "outcome = 'yf'\n",
    "col =  [\"t\", \"yf\", \"ycf\", \"mu0\", \"mu1\" ]\n",
    "cov = [\"x\" + str(i) for i in range(1,26)]\n",
    "col = col + cov\n",
    "features = cov + [\"t\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization with Adam and original function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incre_ps(delta, data):\n",
    "    q1 = (delta * data['p1']) / (delta * data['p1'] + data['p0'])\n",
    "    q1 = tf.math.abs(q1)\n",
    "    a0 = (1-q1)*data['w0']*(data['cf0'] - data[outcome])\n",
    "    a1 = q1*data['w1']*(data['cf1'] - data[outcome])    \n",
    "    influence = a1 - a0\n",
    "    return tf.reduce_mean(influence)\n",
    "\n",
    "def optimization(data):\n",
    "    threhold = tf.constant([0.005])\n",
    "    delta = tf.Variable(20., trainable = True)\n",
    "    true_effect = np.mean(data['mu1'] - data['mu0'])\n",
    "    \n",
    "    for i in range(5000):\n",
    "        with tf.GradientTape() as tape:\n",
    "            influence = incre_ps(delta, data)\n",
    "            loss = tf.math.abs(true_effect - influence)\n",
    "            d_delta = tape.gradient(loss, delta)\n",
    "            opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "            opt.apply_gradients(zip([d_delta], [delta]))\n",
    "            ## early stopping\n",
    "            if tf.math.less(loss, threhold):\n",
    "                print(\"The performance reach MAE: 0.001. Cancelling the training at step {}\".format(i))\n",
    "                break\n",
    "    return delta, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize in train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 13. Delta 15.00\n",
      "MAE on traning 0.28\n",
      "MAE on testing 7.29\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 14. Delta 25.00\n",
      "MAE on traning 0.18\n",
      "MAE on testing 0.31\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 15. Delta 25.00\n",
      "MAE on traning 0.04\n",
      "MAE on testing 0.12\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 16. Delta 25.00\n",
      "MAE on traning 0.22\n",
      "MAE on testing 0.62\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "The performance reach MAE: 0.001. Cancelling the training at step 4692\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 17. Delta 15.31\n",
      "MAE on traning 0.00\n",
      "MAE on testing 0.47\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 18. Delta 25.00\n",
      "MAE on traning 0.48\n",
      "MAE on testing 1.53\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 19. Delta 25.00\n",
      "MAE on traning 0.24\n",
      "MAE on testing 0.00\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 20. Delta 25.00\n",
      "MAE on traning 0.39\n",
      "MAE on testing 0.35\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 21. Delta 25.00\n",
      "MAE on traning 0.07\n",
      "MAE on testing 0.10\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 22. Delta 25.00\n",
      "MAE on traning 0.27\n",
      "MAE on testing 0.34\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 23. Delta 25.00\n",
      "MAE on traning 0.10\n",
      "MAE on testing 0.12\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 24. Delta 25.00\n",
      "MAE on traning 0.11\n",
      "MAE on testing 0.39\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 25. Delta 25.00\n",
      "MAE on traning 0.27\n",
      "MAE on testing 0.07\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 26. Delta 15.00\n",
      "MAE on traning 0.72\n",
      "MAE on testing 0.51\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 27. Delta 25.00\n",
      "MAE on traning 0.02\n",
      "MAE on testing 0.63\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 28. Delta 15.00\n",
      "MAE on traning 1.01\n",
      "MAE on testing 0.51\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 29. Delta 25.00\n",
      "MAE on traning 0.17\n",
      "MAE on testing 0.27\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 30. Delta 25.00\n",
      "MAE on traning 0.22\n",
      "MAE on testing 0.71\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 31. Delta 25.00\n",
      "MAE on traning 0.14\n",
      "MAE on testing 0.77\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 32. Delta 25.00\n",
      "MAE on traning 0.25\n",
      "MAE on testing 0.46\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 33. Delta 25.00\n",
      "MAE on traning 0.10\n",
      "MAE on testing 0.43\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 34. Delta 15.00\n",
      "MAE on traning 1.69\n",
      "MAE on testing 2.20\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 35. Delta 15.05\n",
      "MAE on traning 0.09\n",
      "MAE on testing 0.67\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 36. Delta 25.00\n",
      "MAE on traning 0.03\n",
      "MAE on testing 0.80\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 37. Delta 25.00\n",
      "MAE on traning 0.30\n",
      "MAE on testing 0.85\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 38. Delta 25.00\n",
      "MAE on traning 0.09\n",
      "MAE on testing 0.26\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 39. Delta 25.00\n",
      "MAE on traning 0.34\n",
      "MAE on testing 1.72\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 40. Delta 25.00\n",
      "MAE on traning 0.38\n",
      "MAE on testing 0.45\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 41. Delta 25.00\n",
      "MAE on traning 0.21\n",
      "MAE on testing 0.27\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 42. Delta 25.00\n",
      "MAE on traning 0.02\n",
      "MAE on testing 0.05\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 43. Delta 25.00\n",
      "MAE on traning 0.18\n",
      "MAE on testing 0.66\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 44. Delta 15.00\n",
      "MAE on traning 0.06\n",
      "MAE on testing 0.48\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 45. Delta 15.00\n",
      "MAE on traning 0.04\n",
      "MAE on testing 0.34\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 46. Delta 25.00\n",
      "MAE on traning 0.25\n",
      "MAE on testing 0.11\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 47. Delta 25.00\n",
      "MAE on traning 0.23\n",
      "MAE on testing 0.83\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 48. Delta 25.00\n",
      "MAE on traning 0.20\n",
      "MAE on testing 0.33\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 49. Delta 25.00\n",
      "MAE on traning 0.24\n",
      "MAE on testing 1.03\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 50. Delta 25.00\n",
      "MAE on traning 0.25\n",
      "MAE on testing 0.25\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 51. Delta 25.00\n",
      "MAE on traning 0.14\n",
      "MAE on testing 0.29\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 52. Delta 25.00\n",
      "MAE on traning 0.16\n",
      "MAE on testing 0.14\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "\n",
      "\n",
      "Data index 53. Delta 15.00\n",
      "MAE on traning 0.01\n",
      "MAE on testing 1.22\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-f94bbe42882b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Optimization\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mdelta_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mdelta_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-f3ae05cafc9e>\u001b[0m in \u001b[0;36moptimization\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0minfluence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mincre_ps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_effect\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minfluence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0md_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md_delta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_env/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_env/lib/python3.7/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/phd_env/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gradient_tape/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_env/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MeanGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_MeanGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m   \u001b[0;34m\"\"\"Gradient for Mean.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m   \u001b[0msum_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SumGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m   \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m   \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_env/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_SumGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m           \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_0_shape\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# The shape and reduction indices are statically known, so we use a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_env/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mtile\u001b[0;34m(input, multiples, name)\u001b[0m\n\u001b[1;32m  10986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10988\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_dispatch_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10989\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mtf_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tile'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tile'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'manip.tile'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10990\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdeprecated_endpoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'manip.tile'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "delta_seq = []\n",
    "losses = []\n",
    "losses_test = []\n",
    "\n",
    "df_result = pd.DataFrame()\n",
    "df_result['train_mae'] = 0\n",
    "df_result['test_mae'] = 0\n",
    "\n",
    "for index_ in (range(13, 101)):\n",
    "    data = utils.load_data(cf.IHDP_TRAIN, index_)\n",
    "    data_test = utils.load_data(cf.IHDP_TEST, index_)\n",
    "    data_whole = pd.concat([data, data_test], sort=False)\n",
    "    data, data_test = train_test_split(data_whole, test_size=0.1, random_state = 0)\n",
    "    data = data.reset_index()\n",
    "    data_test = data_test.reset_index()\n",
    "\n",
    "    ## Fit treatment\n",
    "    print(\"Fit treament\")\n",
    "\n",
    "    model_t = LogisticRegression()\n",
    "    model_t.fit(data_whole[cov], data_whole[treatment])\n",
    "\n",
    "    ## Fit outcome\n",
    "    print(\"Fit outcome\")\n",
    "\n",
    "    model_y = GradientBoostingRegressor(random_state=0, n_estimators=2000)\n",
    "    model_y.fit(data_whole[features], data_whole[outcome])\n",
    "\n",
    "    data['p1'] = model_t.predict_proba(data[cov])[:, 1]\n",
    "    data['p0'] = 1 - data['p1']\n",
    "\n",
    "    ## Compute counterfactual outcome with no treatment\n",
    "    print(\"Compute counterfactual outcome\")\n",
    "\n",
    "    data_pos = data.copy()\n",
    "    data_pos[treatment] = 1\n",
    "    data['cf1'] = model_y.predict(data_pos[features])\n",
    "\n",
    "    ## Compute counterfactual outcome with treatment\n",
    "    data_neg = data.copy()\n",
    "    data_neg[treatment] = 0\n",
    "    data['cf0'] = model_y.predict(data_neg[features])\n",
    "\n",
    "    data['ips_weight'] = (data[treatment] / data['p1'] +\n",
    "                          (1 - data[treatment]) / (1 - data['p1']))\n",
    "\n",
    "    data['w0'] = data['ips_weight'] * data[treatment]\n",
    "    data['w1'] = data['ips_weight'] * (1 - data[treatment])\n",
    "\n",
    "    print(\"Optimization\")\n",
    "\n",
    "    delta, loss = optimization(data)\n",
    "    delta_r = delta.numpy()\n",
    "    delta_seq.append(delta_r)\n",
    "    losses.append(loss.numpy())\n",
    "\n",
    "    influence = ipse.influence_function(data_test, treatment, cov, outcome,\n",
    "                                        features, delta_r, model_y, model_t)\n",
    "    means_incre_test, stds_incre = np.mean(influence, axis=0), sem(influence,\n",
    "                                                                   axis=0)\n",
    "    \n",
    "    print(\"Calculate ATE in the testing set\")\n",
    "    true_effect = data['mu1'] - data['mu0']\n",
    "    means_train, stds = np.mean(true_effect, axis=0), sem(true_effect, axis=0)\n",
    "\n",
    "    true_effect = data_test['mu1'] - data_test['mu0']\n",
    "    means_test, stds = np.mean(true_effect, axis=0), sem(true_effect, axis=0)\n",
    "\n",
    "    mae_test = utils.abs_ate(means_test, means_incre_test)\n",
    "    losses_test.append(mae_test)\n",
    "    print(\"\\n\")\n",
    "    print(\"Data index {}. Delta {:.2f}\".format(index_, delta_r))\n",
    "    print(\"MAE on traning {:.2f}\".format(loss.numpy()))\n",
    "    print(\"MAE on testing {:.2f}\".format(mae_test))\n",
    "    print(\"*\" * 100)\n",
    "    \n",
    "    df_result.loc[index_,'train_mae'] = loss.numpy()\n",
    "    df_result.loc[index_,'test_mae'] = mae_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/latex": [
       "$\\displaystyle \\left( 2.326894998550415, \\  7.285364645376849\\right)$"
      ],
      "text/plain": [
       "(2.326894998550415, 7.285364645376849)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.head()\n",
    "df_result.train_mae.max(), df_result.test_mae.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv(cf.RESULT_PATH + \"/result_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Training 0.3078\n",
      "MAE Testing 0.6603\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE Training {:.4f}\".format(np.mean(losses)))\n",
    "print(\"MAE Testing {:.4f}\".format(np.mean(losses_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE Training 0.1605\n",
    "# MAE Testing 0.5021\n",
    "\n",
    "### optimize train-test together\n",
    "# MAE Training 0.0933\n",
    "# MAE Testing 0.6035\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = asarray(delta_seq)\n",
    "save('delta_1.npy', delta_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRAIN = \"/home/dtd/Documents/data/idhp/ihdp_npci_1-100.train.npz\"\n",
    "PATH_TEST = \"/home/dtd/Documents/data/idhp/ihdp_npci_1-100.test.npz\"\n",
    "\n",
    "delta_seq = []\n",
    "losses = []\n",
    "losses_test = []\n",
    "for index_ in tqdm(range(1, 101)): \n",
    "    data = utils.load_data(PATH_TRAIN, index_)\n",
    "    data_test = utils.load_data(PATH_TEST, index_)\n",
    "    data_whole = pd.concat([data, data_test], sort=False)\n",
    "    \n",
    "    #oversample = SMOTE()\n",
    "    #X_train_oversampled, y_train_oversampled = oversample.fit_sample(data_whole[cov].values, data_whole[treatment].values)\n",
    "    \n",
    "    ## Fit treatment\n",
    "    model_t = LogisticRegression()\n",
    "    #model_t.fit(X_train_oversampled, y_train_oversampled)\n",
    "\n",
    "    ## Fit outcome\n",
    "    model_y = GradientBoostingRegressor(random_state=0, n_estimators = 500)\n",
    "    model_y.fit(data_whole[features], data_whole[outcome])\n",
    "\n",
    "    data['p1'] = model_t.predict_proba(data[cov])[:,1]\n",
    "    data['p0'] = 1 - data['p1']\n",
    "\n",
    "    ## Compute counterfactual outcome with no treatment\n",
    "    data_pos = data.copy()\n",
    "    data_pos[treatment] = 1\n",
    "    data['cf1'] = model_y.predict(data_pos[features])\n",
    "\n",
    "    ## Compute counterfactual outcome with treatment\n",
    "    data_neg = data.copy()\n",
    "    data_neg[treatment] = 0\n",
    "    data['cf0'] = model_y.predict(data_neg[features])\n",
    "\n",
    "    data['ips_weight'] = (data[treatment] / data['p1'] + (1 - data[treatment]) /\n",
    "                          (1 - data['p1']))\n",
    "    \n",
    "    data['w0'] = data['ips_weight']*data[treatment]\n",
    "    data['w1'] = data['ips_weight']*(1 - data[treatment])\n",
    "    \n",
    "    delta, loss = optimization(data)\n",
    "    delta_r = delta.numpy()\n",
    "    delta_seq.append(delta_r)\n",
    "    losses.append(loss.numpy())\n",
    "    \n",
    "    \n",
    "    influence = ipse.influence_function(data_test, treatment, cov, outcome, features, delta_r, model_y, model_t)\n",
    "    means_incre_test, stds_incre = np.mean(influence, axis=0), sem(influence, axis=0)\n",
    "\n",
    "    true_effect = data['mu1'] - data['mu0']\n",
    "    means_train, stds = np.mean(true_effect, axis=0), sem(true_effect, axis=0)\n",
    "    \n",
    "    true_effect = data_test['mu1'] - data_test['mu0']\n",
    "    means_test, stds = np.mean(true_effect, axis=0), sem(true_effect, axis=0)\n",
    "\n",
    "    mae_test = utils.abs_ate(means_test, means_incre_test)\n",
    "    losses_test.append(mae_test)\n",
    "    print(\"\\n\")\n",
    "    print(\"Data index {}. Delta {:.2f}\".format(index_, delta_r))\n",
    "    print(\"MAE on traning {:.2f}\".format(loss.numpy()))\n",
    "    print(\"MAE on testing {:.2f}\".format(mae_test))\n",
    "    print(\"*\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization with list of delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incre_ps(delta, data):\n",
    "    q1 = (delta * data['p1']) / (delta * data['p1'] + data['p0'])\n",
    "    q1 = tf.math.abs(q1)\n",
    "    a0 = (1-q1)*data['w0']*(data['cf0'] - data[outcome])\n",
    "    a1 = q1*data['w1']*(data['cf1'] - data[outcome])    \n",
    "    influence = a1 - a0\n",
    "    return tf.reduce_mean(influence)\n",
    "\n",
    "def optimization(data, variation):\n",
    "    threhold = tf.constant([0.001])\n",
    "    '''\n",
    "    delta = tf.Variable(\n",
    "        tf.random.uniform([data.shape[0],], \n",
    "                          minval=1, \n",
    "                          maxval=100, \n",
    "                          dtype=tf.dtypes.float32), \n",
    "                          trainable = True)\n",
    "    '''\n",
    "    delta = tf.Variable(tf.random.normal(\n",
    "        [data.shape[0],], \n",
    "        mean=0.0, \n",
    "        stddev=variation, \n",
    "        dtype=tf.dtypes.float32, \n",
    "        seed=1, \n",
    "        name='delta'\n",
    "    ), trainable = True)\n",
    "    \n",
    "    true_effect = np.mean(data['mu1'] - data['mu0'])\n",
    "    \n",
    "    for i in range(30000):\n",
    "        with tf.GradientTape() as tape:\n",
    "            influence = incre_ps(delta, data)\n",
    "            loss = tf.math.abs(true_effect - influence)\n",
    "            d_delta = tape.gradient(loss, delta)\n",
    "            opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "            opt.apply_gradients(zip([d_delta], [delta]))\n",
    "            ## early stopping\n",
    "            if tf.math.less(loss, threhold):\n",
    "                print(\"The performance reach MAE: 0.001. Cancelling the training at step {}\".format(i))\n",
    "                break\n",
    "    return delta, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize in train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variaton  12\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 1. Loss training 0.07 and testing 4.38\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 2. Loss training 0.10 and testing 8.03\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "The performance reach MAE: 0.001. Cancelling the training at step 277\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 3. Loss training 0.00 and testing 3.79\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 4. Loss training 0.01 and testing 1.25\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 5. Loss training 0.03 and testing 1.98\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 6. Loss training 0.04 and testing 1.49\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 7. Loss training 0.41 and testing 0.41\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 8. Loss training 0.01 and testing 2.63\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 9. Loss training 0.03 and testing 4.57\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 10. Loss training 1.21 and testing 0.18\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 11. Loss training 0.06 and testing 0.37\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 12. Loss training 1.61 and testing 8.09\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 13. Loss training 1.08 and testing 23.32\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 14. Loss training 0.33 and testing 11.41\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 15. Loss training 0.51 and testing 1.78\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 16. Loss training 0.01 and testing 6.17\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 17. Loss training 0.06 and testing 12.41\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 18. Loss training 0.09 and testing 48.97\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 19. Loss training 0.01 and testing 0.76\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 20. Loss training 0.03 and testing 1.71\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 21. Loss training 0.90 and testing 7.56\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 22. Loss training 25.16 and testing 0.81\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 23. Loss training 0.31 and testing 4.78\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 24. Loss training 0.11 and testing 7.19\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 25. Loss training 0.25 and testing 2.53\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 26. Loss training 0.05 and testing 0.41\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 27. Loss training 0.03 and testing 0.56\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 28. Loss training 1.86 and testing 240.23\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 29. Loss training 0.49 and testing 2.83\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 30. Loss training 0.16 and testing 3.38\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 31. Loss training 0.42 and testing 7.04\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n",
      "Calculate ATE in the testing set\n",
      "Calculate mean absolute error\n",
      "Data index 32. Loss training 0.01 and testing 1.21\n",
      "****************************************************************************************************\n",
      "Fit treament\n",
      "Fit outcome\n",
      "Compute counterfactual outcome\n",
      "Optimization\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ae77c4c6500f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Optimization\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mdelta_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mdelta_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-c866ce545d7f>\u001b[0m in \u001b[0;36moptimization\u001b[0;34m(data, variation)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0md_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md_delta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0;31m## early stopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mless\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthrehold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_env/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    476\u001b[0m       \u001b[0;31m# Create iteration if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_all_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_env/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_create_all_weights\u001b[0;34m(self, var_list)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_hypers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_slots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_env/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_create_hypers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m             aggregation=tf_variables.VariableAggregation.ONLY_FIRST_REPLICA)\n\u001b[0m\u001b[1;32m    782\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hypers_created\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_env/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, trainable, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 997\u001b[0;31m         aggregation=aggregation)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_env/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    139\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m       \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m       shape=variable_shape if variable_shape else None)\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_env/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_env/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m   def _variable_v2_call(cls,\n",
      "\u001b[0;32m~/anaconda3/envs/phd_env/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m                         shape=None):\n\u001b[1;32m    197\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_env/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2596\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2597\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2598\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m   2599\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2600\u001b[0m     return variables.RefVariable(\n",
      "\u001b[0;32m~/anaconda3/envs/phd_env/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_env/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1432\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1434\u001b[0;31m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[1;32m   1435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m   def _init_from_args(self,\n",
      "\u001b[0;32m~/anaconda3/envs/phd_env/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1543\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m           \u001b[0;34m\"Variable\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1545\u001b[0;31m           skip_on_eager=False) as name:\n\u001b[0m\u001b[1;32m   1546\u001b[0m         \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1547\u001b[0m         \u001b[0mhandle_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_from_scope_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_env/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   6433\u001b[0m     \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6435\u001b[0;31m       \u001b[0mscope_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_scope_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menter_eager_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6436\u001b[0m       self._exit_fns.append(\n\u001b[1;32m   6437\u001b[0m           lambda *a: setattr(ctx, \"scope_name\", old_scope_name))\n",
      "\u001b[0;32m~/anaconda3/envs/phd_env/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36menter_eager_name_scope\u001b[0;34m(ctx, name)\u001b[0m\n\u001b[1;32m   6364\u001b[0m     \u001b[0mscope_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6365\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6366\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6367\u001b[0m       \u001b[0;31m# A trailing slash breaks out of nested name scopes, indicating a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6368\u001b[0m       \u001b[0;31m# fully specified scope name, for compatibility with Graph.name_scope.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "delta_seq = []\n",
    "losses = []\n",
    "losses_test = []\n",
    "\n",
    "seq_result = pd.DataFrame()\n",
    "seq_result['train'] = 0\n",
    "seq_result['test'] = 0\n",
    "\n",
    "for count in range(12,13):\n",
    "    #variation = np.random.randint(low=1, high=100, size=1)\n",
    "    print(\"Variaton \", count)\n",
    "    for index_ in range(1, 101): \n",
    "        data = utils.load_data(cf.IHDP_TRAIN, index_)\n",
    "        data_test = utils.load_data(cf.IHDP_TEST, index_)\n",
    "        data_whole = pd.concat([data, data_test], sort=False)\n",
    "        ## Fit treatment\n",
    "        print(\"Fit treament\")\n",
    "        model_t = LogisticRegression()\n",
    "        model_t.fit(data_whole[cov], data_whole[treatment])\n",
    "\n",
    "        ## Fit outcome\n",
    "        print(\"Fit outcome\")\n",
    "        model_y = GradientBoostingRegressor(random_state=0, n_estimators = 1000)\n",
    "        model_y.fit(data_whole[features], data_whole[outcome])\n",
    "\n",
    "        data['p1'] = model_t.predict_proba(data[cov])[:,1]\n",
    "        data_test['p1'] = model_t.predict_proba(data_test[cov])[:,1]\n",
    "\n",
    "        data['p0'] = 1 - data['p1']\n",
    "\n",
    "        ## Compute counterfactual outcome with no treatment\n",
    "        print(\"Compute counterfactual outcome\")\n",
    "        data_pos = data.copy()\n",
    "        data_pos[treatment] = 1\n",
    "        data['cf1'] = model_y.predict(data_pos[features])\n",
    "\n",
    "        ## Compute counterfactual outcome with treatment\n",
    "        data_neg = data.copy()\n",
    "        data_neg[treatment] = 0\n",
    "        data['cf0'] = model_y.predict(data_neg[features])\n",
    "\n",
    "        data['ips_weight'] = (data[treatment] / data['p1'] + (1 - data[treatment]) /\n",
    "                              (1 - data['p1']))\n",
    "\n",
    "        data['w0'] = data['ips_weight']*data[treatment]\n",
    "        data['w1'] = data['ips_weight']*(1 - data[treatment])\n",
    "        \n",
    "        print(\"Optimization\")\n",
    "        delta, loss = optimization(data, count)\n",
    "        delta_r = delta.numpy()\n",
    "        delta_seq.append(delta_r)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        treated_neighbors = (\n",
    "                NearestNeighbors(n_neighbors=1, algorithm='ball_tree')\n",
    "                .fit(data['p1'].values.reshape(-1, 1))\n",
    "        )\n",
    "        distances, indices = treated_neighbors.kneighbors(data_test['p1'].values.reshape(-1, 1))\n",
    "\n",
    "        delta_test = delta_r[indices.reshape(-1)]\n",
    "        \n",
    "        print(\"Calculate ATE in the testing set\")\n",
    "    \n",
    "        influence = ipse.influence_function(data_test, \n",
    "                                            treatment, \n",
    "                                            cov, \n",
    "                                            outcome, \n",
    "                                            features,\n",
    "                                            delta_test, \n",
    "                                            model_y, \n",
    "                                            model_t)\n",
    "\n",
    "        means_incre_test, stds_incre = np.mean(influence, axis=0), sem(influence, axis=0)\n",
    "\n",
    "        ## True effect   \n",
    "        \n",
    "        true_effect = data_test['mu1'] - data_test['mu0']\n",
    "        means_test, stds = np.mean(true_effect, axis=0), sem(true_effect, axis=0)\n",
    "        \n",
    "        print(\"Calculate mean absolute error\")\n",
    "        mae_test = utils.abs_ate(means_test, means_incre_test)\n",
    "        losses_test.append(mae_test)\n",
    "\n",
    "        print(\"Data index {}. Loss training {:.2f} and testing {:.2f}\".format(index_, loss.numpy(), mae_test))\n",
    "\n",
    "        seq_result.loc[index_ - 1, 'train'] = loss.numpy()\n",
    "        seq_result.loc[index_ - 1, 'test'] = mae_test\n",
    "        print(\"*\"*100)\n",
    "    print(\"Export to csv\")\n",
    "    print(\"-\"*100)\n",
    "    \n",
    "    save(cf.RESULT_PATH + \"/\" + \"list_delta_\" + str(index_) + \".npy\", delta_seq)\n",
    "    seq_result.to_csv(cf.RESULT_PATH + \"/\" + str(count) + \"_ps_con.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Optimization for individual treatment effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incre_ps(delta, data):\n",
    "    q1 = (delta * data['p1']) / (delta * data['p1'] + data['p0'])\n",
    "    q1 = tf.math.abs(q1)\n",
    "    a0 = (1-q1)*data['w0']*(data['cf0'] - data[outcome])\n",
    "    a1 = q1*data['w1']*(data['cf1'] - data[outcome])    \n",
    "    influence = a1 - a0\n",
    "    return influence\n",
    "\n",
    "def optimization(data):\n",
    "    threhold = tf.constant([0.01])\n",
    "    '''\n",
    "    delta = tf.Variable(\n",
    "        tf.random.uniform([data.shape[0],], \n",
    "                          minval=1, \n",
    "                          maxval=100, \n",
    "                          dtype=tf.dtypes.float32), \n",
    "                          trainable = True)\n",
    "    '''\n",
    "    delta = tf.Variable(tf.random.normal(\n",
    "        [data.shape[0],], \n",
    "        mean=0, \n",
    "        stddev=10, \n",
    "        dtype=tf.dtypes.float32, \n",
    "        seed=1, \n",
    "        name='delta'\n",
    "    ), trainable = True)\n",
    "    \n",
    "    true_effect = data['mu1'] - data['mu0']\n",
    "    \n",
    "    for i in range(100000):\n",
    "        with tf.GradientTape() as tape:\n",
    "            influence = incre_ps(delta, data)\n",
    "            loss = tf.keras.losses.MAE(true_effect, influence)\n",
    "            d_delta = tape.gradient(loss, delta)\n",
    "            opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "            opt.apply_gradients(zip([d_delta], [delta]))\n",
    "            if i % 1000 == 0:\n",
    "                print(\"Epoch {}. Loss {:.5f}\".format(i, loss.numpy()))\n",
    "            if tf.math.less(loss, threhold):\n",
    "                print(\"The performance reach MAE: 0.001. Cancelling the training at step {}\".format(i))\n",
    "                break\n",
    "    return delta, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRAIN = \"/home/dtd/Documents/interpretable_machine_learning/Source Code/data/ihdp_npci_1-100.train.npz\"\n",
    "PATH_TEST = \"/home/dtd/Documents/interpretable_machine_learning/Source Code/data/ihdp_npci_1-100.test.npz\"\n",
    "\n",
    "delta_seq = []\n",
    "for index_ in tqdm(range(13, 14)): \n",
    "    data = utils.load_data(PATH_TRAIN, index_)\n",
    "    ## Fit treatment\n",
    "    model_t = LogisticRegression()\n",
    "    model_t.fit(data[cov], data[treatment])\n",
    "\n",
    "    ## Fit outcome\n",
    "    model_y = GradientBoostingRegressor(random_state=0, n_estimators = 5000)\n",
    "    model_y.fit(data[features], data[outcome])\n",
    "\n",
    "    data['p1'] = model_t.predict_proba(data[cov])[:,1]\n",
    "    data['p0'] = 1 - data['p1']\n",
    "\n",
    "    ## Compute counterfactual outcome with no treatment\n",
    "    data_pos = data.copy()\n",
    "    data_pos[treatment] = 1\n",
    "    data['cf1'] = model_y.predict(data_pos[features])\n",
    "\n",
    "    ## Compute counterfactual outcome with treatment\n",
    "    data_neg = data.copy()\n",
    "    data_neg[treatment] = 0\n",
    "    data['cf0'] = model_y.predict(data_neg[features])\n",
    "\n",
    "    data['ips_weight'] = (data[treatment] / data['p1'] + (1 - data[treatment]) /\n",
    "                          (1 - data['p1']))\n",
    "    \n",
    "    data['w0'] = data['ips_weight']*data[treatment]\n",
    "    data['w1'] = data['ips_weight']*(1 - data[treatment])\n",
    "    \n",
    "    delta, loss = optimization(data)\n",
    "    delta_r = delta.numpy()\n",
    "    delta_seq.append(delta_r)\n",
    "    print(\"Data index {}. Loss {:.2f}\".format(index_, loss.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save('individual_list_delta_.npy', delta_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization for individual treatment effects using genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incre_ps(delta, data):\n",
    "    q1 = (delta * data['p1']) / (delta * data['p1'] + data['p0'])\n",
    "    q1 = abs(q1)\n",
    "    a0 = (1-q1)*data['w0']*(data['cf0'] - data[outcome])\n",
    "    a1 = q1*data['w1']*(data['cf1'] - data[outcome])    \n",
    "    influence = a1 - a0\n",
    "    return influence\n",
    "\n",
    "\n",
    "def fitness_function(delta, solution_idx):\n",
    "    influence = incre_ps(delta, data)\n",
    "    mae = -np.sqrt(np.mean((true_effect - influence)**2))\n",
    "    return np.mean(mae)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRAIN = \"/home/dtd/Documents/interpretable_machine_learning/Source Code/data/ihdp_npci_1-100.train.npz\"\n",
    "data = utils.load_data(PATH_TRAIN, 1)\n",
    "\n",
    "## Fit treatment\n",
    "model_t = LogisticRegression()\n",
    "model_t.fit(data[cov], data[treatment])\n",
    "\n",
    "## Fit outcome\n",
    "model_y = GradientBoostingRegressor(random_state=0, n_estimators = 5000)\n",
    "model_y.fit(data[features], data[outcome])\n",
    "\n",
    "data['p1'] = model_t.predict_proba(data[cov])[:,1]\n",
    "data['p0'] = 1 - data['p1']\n",
    "\n",
    "## Compute counterfactual outcome with no treatment\n",
    "data_pos = data.copy()\n",
    "data_pos[treatment] = 1\n",
    "data['cf1'] = model_y.predict(data_pos[features])\n",
    "\n",
    "## Compute counterfactual outcome with treatment\n",
    "data_neg = data.copy()\n",
    "data_neg[treatment] = 0\n",
    "data['cf0'] = model_y.predict(data_neg[features])\n",
    "\n",
    "data['ips_weight'] = (data[treatment] / data['p1'] + (1 - data[treatment]) /\n",
    "                      (1 - data['p1']))\n",
    "\n",
    "data['w0'] = data['ips_weight']*data[treatment]\n",
    "data['w1'] = data['ips_weight']*(1 - data[treatment])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_effect = data['mu1'] - data['mu0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Given the following function:\n",
    "    y = f(w1:w6) = w1x1 + w2x2 + w3x3 + w4x4 + w5x5 + 6wx6\n",
    "    where (x1,x2,x3,x4,x5,x6)=(4,-2,3.5,5,-11,-4.7) and y=44\n",
    "What are the best values for the 6 weights (w1 to w6)? We are going to use the genetic algorithm to optimize this function.\n",
    "\"\"\"\n",
    "\n",
    "#function_inputs = [4,-2,3.5,5,-11,-4.7] # Function inputs.\n",
    "#desired_output = 44 # Function output.\n",
    "\n",
    "function_inputs = np.random.rand(data.shape[0]) # Function inputs.\n",
    "\n",
    "num_generations = 5000 # Number of generations.\n",
    "num_parents_mating = 100 # Number of solutions to be selected as parents in the mating pool.\n",
    "\n",
    "# To prepare the initial population, there are 2 ways:\n",
    "# 1) Prepare it yourself and pass it to the initial_population parameter. This way is useful when the user wants to start the genetic algorithm with a custom initial population.\n",
    "# 2) Assign valid integer values to the sol_per_pop and num_genes parameters. If the initial_population parameter exists, then the sol_per_pop and num_genes parameters are useless.\n",
    "sol_per_pop = 2500 # Number of solutions in the population.\n",
    "num_genes = len(function_inputs)\n",
    "\n",
    "init_range_low = -100\n",
    "init_range_high = 100\n",
    "\n",
    "parent_selection_type = \"sss\" # Type of parent selection.\n",
    "keep_parents = -1 # Number of parents to keep in the next population. -1 means keep all parents and 0 means keep nothing.\n",
    "\n",
    "crossover_type = \"single_point\" # Type of the crossover operator.\n",
    "\n",
    "# Parameters of the mutation operation.\n",
    "mutation_type = \"random\" # Type of the mutation operator.\n",
    "mutation_percent_genes = 10 # Percentage of genes to mutate. This parameter has no action if the parameter mutation_num_genes exists or when mutation_type is None.\n",
    "\n",
    "last_fitness = 0\n",
    "def callback_generation(ga_instance):\n",
    "    global last_fitness\n",
    "    print(\"Generation = {generation}\".format(generation=ga_instance.generations_completed))\n",
    "    print(\"Fitness    = {fitness}\".format(fitness=ga_instance.best_solution()[1]))\n",
    "    print(\"Change     = {change}\".format(change=ga_instance.best_solution()[1] - last_fitness))\n",
    "    print(\"\\n\")\n",
    "    last_fitness = ga_instance.best_solution()[1]\n",
    "\n",
    "# Creating an instance of the GA class inside the ga module. Some parameters are initialized within the constructor.\n",
    "ga_instance = pygad.GA(num_generations=num_generations,\n",
    "                       num_parents_mating=num_parents_mating, \n",
    "                       fitness_func=fitness_function,\n",
    "                       sol_per_pop=sol_per_pop, \n",
    "                       num_genes=num_genes,\n",
    "                       init_range_low=init_range_low,\n",
    "                       init_range_high=init_range_high,\n",
    "                       parent_selection_type=parent_selection_type,\n",
    "                       keep_parents=keep_parents,\n",
    "                       crossover_type=crossover_type,\n",
    "                       mutation_type=mutation_type,\n",
    "                       mutation_percent_genes=mutation_percent_genes,\n",
    "                       callback_generation=callback_generation)\n",
    "\n",
    "# Running the GA to optimize the parameters of the function.\n",
    "ga_instance.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization ATE using genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incre_ps(delta, data):\n",
    "    q1 = (delta * data['p1']) / (delta * data['p1'] + data['p0'])\n",
    "    q1 = abs(q1)\n",
    "    a0 = (1-q1)*data['w0']*(data['cf0'] - data[outcome])\n",
    "    a1 = q1*data['w1']*(data['cf1'] - data[outcome])    \n",
    "    influence = a1 - a0\n",
    "    return influence\n",
    "\n",
    "\n",
    "def fitness_function(delta, solution_idx):\n",
    "    influence = incre_ps(delta, data)\n",
    "    mae = -np.sqrt(np.mean((true_effect - influence)**2))\n",
    "    return np.mean(mae)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_ = 1\n",
    "\n",
    "data = utils.load_data(cf.IHDP_TRAIN, index_)\n",
    "data_test = utils.load_data(cf.IHDP_TEST, index_)\n",
    "data_whole = pd.concat([data, data_test], sort=False)\n",
    "## Fit treatment\n",
    "model_t = LogisticRegression()\n",
    "model_t.fit(data_whole[cov], data_whole[treatment])\n",
    "\n",
    "## Fit outcome\n",
    "model_y = GradientBoostingRegressor(random_state=0, n_estimators = 5000)\n",
    "model_y.fit(data_whole[features], data_whole[outcome])\n",
    "\n",
    "data['p1'] = model_t.predict_proba(data[cov])[:,1]\n",
    "data['p0'] = 1 - data['p1']\n",
    "\n",
    "## Compute counterfactual outcome with no treatment\n",
    "data_pos = data.copy()\n",
    "data_pos[treatment] = 1\n",
    "data['cf1'] = model_y.predict(data_pos[features])\n",
    "\n",
    "## Compute counterfactual outcome with treatment\n",
    "data_neg = data.copy()\n",
    "data_neg[treatment] = 0\n",
    "data['cf0'] = model_y.predict(data_neg[features])\n",
    "\n",
    "data['ips_weight'] = (data[treatment] / data['p1'] + (1 - data[treatment]) /\n",
    "                      (1 - data['p1']))\n",
    "\n",
    "data['w0'] = data['ips_weight']*data[treatment]\n",
    "data['w1'] = data['ips_weight']*(1 - data[treatment])\n",
    "\n",
    "true_effect = data['mu1'] - data['mu0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_inputs = np.random.rand(data.shape[0]) # Function inputs.\n",
    "\n",
    "num_generations = 2000 # Number of generations.\n",
    "num_parents_mating = 100 # Number of solutions to be selected as parents in the mating pool.\n",
    "\n",
    "sol_per_pop = 2500 # Number of solutions in the population.\n",
    "num_genes = len(function_inputs)\n",
    "\n",
    "init_range_low = -100\n",
    "init_range_high = 100\n",
    "\n",
    "parent_selection_type = \"sss\" # Type of parent selection.\n",
    "keep_parents = -1 # Number of parents to keep in the next population. -1 means keep all parents and 0 means keep nothing.\n",
    "\n",
    "crossover_type = \"single_point\" # Type of the crossover operator.\n",
    "\n",
    "mutation_type = \"random\" # Type of the mutation operator.\n",
    "mutation_percent_genes = 10 # Percentage of genes to mutate. This parameter has no action if the parameter mutation_num_genes exists or when mutation_type is None.\n",
    "last_fitness = 0\n",
    "def callback_generation(ga_instance):\n",
    "    global last_fitness\n",
    "    print(\"Generation = {generation}\".format(generation=ga_instance.generations_completed))\n",
    "    print(\"Fitness    = {fitness}\".format(fitness=ga_instance.best_solution()[1]))\n",
    "    print(\"Change     = {change}\".format(change=ga_instance.best_solution()[1] - last_fitness))\n",
    "    print(\"\\n\")\n",
    "    last_fitness = ga_instance.best_solution()[1]\n",
    "    if last_fitness <=  0.001:\n",
    "        break \n",
    "\n",
    "# Creating an instance of the GA class inside the ga module. Some parameters are initialized within the constructor.\n",
    "ga_instance = pygad.GA(num_generations=num_generations,\n",
    "                       num_parents_mating=num_parents_mating, \n",
    "                       fitness_func=fitness_function,\n",
    "                       sol_per_pop=sol_per_pop, \n",
    "                       num_genes=num_genes,\n",
    "                       init_range_low=init_range_low,\n",
    "                       init_range_high=init_range_high,\n",
    "                       parent_selection_type=parent_selection_type,\n",
    "                       keep_parents=keep_parents,\n",
    "                       crossover_type=crossover_type,\n",
    "                       mutation_type=mutation_type,\n",
    "                       mutation_percent_genes=mutation_percent_genes,\n",
    "                       callback_generation=callback_generation)\n",
    "\n",
    "# Running the GA to optimize the parameters of the function.\n",
    "ga_instance.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phd_env] *",
   "language": "python",
   "name": "conda-env-phd_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "247.333px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
